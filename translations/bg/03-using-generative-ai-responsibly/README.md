<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "13084c6321a2092841b9a081b29497ba",
  "translation_date": "2025-05-19T14:51:11+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "bg"
}
-->
# Отговорно използване на генеративен AI

> _Кликнете върху изображението по-горе, за да гледате видеото на този урок_

Лесно е да бъдете запленени от AI и по-специално от генеративния AI, но трябва да се замислите как да го използвате отговорно. Трябва да обмислите неща като как да гарантирате, че резултатите са справедливи, безопасни и още. Тази глава има за цел да ви предостави споменатия контекст, какво да обмислите и как да предприемете активни стъпки за подобряване на използването на AI.

## Въведение

Този урок ще обхване:

- Защо трябва да приоритизирате Отговорния AI при създаването на приложения с генеративен AI.
- Основни принципи на Отговорния AI и как те се отнасят към генеративния AI.
- Как да приложите тези принципи на Отговорния AI на практика чрез стратегия и инструменти.

## Учебни цели

След завършване на този урок ще знаете:

- Значението на Отговорния AI при създаването на приложения с генеративен AI.
- Кога да мислите и прилагате основните принципи на Отговорния AI при създаването на приложения с генеративен AI.
- Какви инструменти и стратегии са на разположение, за да приложите концепцията за Отговорния AI на практика.

## Принципи на Отговорния AI

Вълнението от генеративния AI никога не е било по-голямо. Това вълнение привлече много нови разработчици, внимание и финансиране в тази област. Докато това е много позитивно за всеки, който търси да създава продукти и компании с генеративен AI, е важно да продължим отговорно.

През този курс се фокусираме върху изграждането на нашия стартъп и нашия AI образователен продукт. Ще използваме принципите на Отговорния AI: Справедливост, Включване, Надеждност/Безопасност, Сигурност и Поверителност, Прозрачност и Отговорност. С тези принципи ще изследваме как те се отнасят към използването ни на генеративен AI в нашите продукти.

## Защо трябва да приоритизирате Отговорния AI

При създаването на продукт, приемането на подход, ориентиран към човека, като се държи най-добрият интерес на потребителя, води до най-добри резултати.

Уникалността на генеративния AI е неговата сила да създава полезни отговори, информация, насоки и съдържание за потребителите. Това може да бъде направено без много ръчни стъпки, което може да доведе до много впечатляващи резултати. Без правилно планиране и стратегии, това също може да доведе до някои вредни резултати за вашите потребители, вашия продукт и обществото като цяло.

Нека разгледаме някои (но не всички) от тези потенциално вредни резултати:

### Халюцинации

Халюцинациите са термин, използван за описване, когато LLM създава съдържание, което е или напълно безсмислено, или нещо, което знаем, че е фактически неправилно въз основа на други източници на информация.

Да вземем за пример, че изграждаме функция за нашия стартъп, която позволява на студентите да задават исторически въпроси на модел. Един студент задава въпроса `Who was the sole survivor of Titanic?`

Моделът създава отговор като този по-долу:

Това е много уверен и подробен отговор. За съжаление, той е неправилен. Дори с минимално количество изследвания, човек би открил, че имаше повече от един оцелял от катастрофата на Титаник. За студент, който тепърва започва да изследва тази тема, този отговор може да бъде достатъчно убедителен, за да не бъде поставен под въпрос и да бъде третиран като факт. Последиците от това могат да доведат до това, че AI системата е ненадеждна и негативно влияе върху репутацията на нашия стартъп.

С всяка итерация на даден LLM, сме видели подобрения в производителността по отношение на минимизирането на халюцинациите. Дори с това подобрение, ние като разработчици на приложения и потребители все още трябва да останем наясно с тези ограничения.

### Вредно съдържание

В предишния раздел разгледахме, когато LLM създава неправилни или безсмислени отговори. Друг риск, който трябва да сме наясно, е когато моделът отговаря с вредно съдържание.

Вредното съдържание може да бъде определено като:

- Предоставяне на инструкции или насърчаване на самонараняване или вреда на определени групи.
- Омразно или унизително съдържание.
- Насочване на планиране на всякакъв вид атака или насилствени действия.
- Предоставяне на инструкции за намиране на незаконно съдържание или извършване на незаконни действия.
- Показване на сексуално открито съдържание.

За нашия стартъп искаме да се уверим, че имаме правилните инструменти и стратегии, за да предотвратим този тип съдържание да бъде видяно от студентите.

### Липса на справедливост

Справедливостта се определя като „гарантиране, че AI системата е свободна от пристрастия и дискриминация и че третира всички справедливо и равноправно.“ В света на генеративния AI, искаме да гарантираме, че изключващите светогледи на маргинализирани групи не се усилват от резултатите на модела.

Тези типове резултати не само разрушават изграждането на положителни продуктови преживявания за нашите потребители, но също така причиняват допълнителна социална вреда. Като разработчици на приложения, винаги трябва да държим широка и разнообразна потребителска база в ума си, когато изграждаме решения с генеративен AI.

## Как да използваме генеративния AI отговорно

Сега, когато сме идентифицирали значението на Отговорния генеративен AI, нека разгледаме 4 стъпки, които можем да предприемем, за да изградим нашите AI решения отговорно:

### Измерване на потенциални вреди

В софтуерното тестване тестваме очакваните действия на потребителя върху приложението. По подобен начин, тестването на разнообразен набор от промпти, които потребителите най-вероятно ще използват, е добър начин за измерване на потенциалната вреда.

Тъй като нашият стартъп изгражда образователен продукт, би било добре да подготвим списък с образователни промпти. Това може да бъде за покриване на определен предмет, исторически факти и промпти за студентския живот.

### Смекчаване на потенциални вреди

Сега е време да намерим начини, чрез които можем да предотвратим или ограничим потенциалната вреда, причинена от модела и неговите отговори. Можем да разгледаме това в 4 различни слоя:

- **Модел**. Избор на правилния модел за правилния случай на употреба. По-големи и по-сложни модели като GPT-4 могат да причинят повече риск от вредно съдържание, когато се прилагат към по-малки и по-специфични случаи на употреба. Използването на вашите обучителни данни за фина настройка също намалява риска от вредно съдържание.

- **Система за безопасност**. Система за безопасност е набор от инструменти и конфигурации на платформата, която обслужва модела, които помагат за смекчаване на вредата. Пример за това е системата за филтриране на съдържание на услугата Azure OpenAI. Системите трябва също така да откриват атаки на jailbreak и нежелана активност като заявки от ботове.

- **Метапромпт**. Метапромпти и заземяване са начини, по които можем да насочим или ограничим модела въз основа на определени поведения и информация. Това може да бъде използване на системни входове за определяне на определени граници на модела. В допълнение, предоставяне на резултати, които са по-релевантни за обхвата или домейна на системата.

Може също така да се използват техники като Retrieval Augmented Generation (RAG), за да може моделът да извлича информация само от селекция от доверени източници. Има урок по-късно в този курс за [изграждане на приложения за търсене](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Потребителски опит**. Последният слой е там, където потребителят взаимодейства директно с модела чрез интерфейса на нашето приложение по някакъв начин. По този начин можем да проектираме UI/UX, за да ограничим потребителя върху типовете входове, които могат да изпращат към модела, както и текста или изображенията, показвани на потребителя. При разгръщането на AI приложението, също така трябва да бъдем прозрачни за това какво нашето генеративно AI приложение може и не може да прави.

Имаме цял урок, посветен на [Проектиране на UX за AI приложения](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Оценка на модела**. Работата с LLMs може да бъде предизвикателна, защото не винаги имаме контрол върху данните, на които моделът е обучен. Независимо от това, трябва винаги да оценяваме производителността и резултатите на модела. Все още е важно да измерваме точността, сходството, заземеността и релевантността на резултата. Това помага за предоставяне на прозрачност и доверие на заинтересованите страни и потребителите.

### Опериране на отговорно генеративно AI решение

Изграждането на оперативна практика около вашите AI приложения е финалният етап. Това включва партньорство с други части на нашия стартъп като юридическия и сигурността, за да се гарантира, че сме в съответствие с всички регулаторни политики. Преди стартиране, също така искаме да изградим планове около доставка, обработка на инциденти и връщане назад, за да предотвратим всяка вреда на нашите потребители от растежа.

## Инструменти

Докато работата по разработване на решения за Отговорния AI може да изглежда много, тя е работа, която си струва усилието. С нарастването на областта на генеративния AI, повече инструменти за помощ на разработчиците за ефективно интегриране на отговорността в техните работни процеси ще узреят. Например, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) може да помогне за откриване на вредно съдържание и изображения чрез API заявка.

## Проверка на знанията

Какви са някои от нещата, за които трябва да се грижите, за да гарантирате отговорното използване на AI?

1. Че отговорът е правилен.
2. Вредна употреба, че AI не се използва за престъпни цели.
3. Гарантиране, че AI е свободен от пристрастия и дискриминация.

A: 2 и 3 са правилни. Отговорният AI ви помага да обмислите как да смекчите вредните ефекти и пристрастия и още.

## 🚀 Предизвикателство

Прочетете за [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) и вижте какво можете да възприемете за вашето използване.

## Отлична работа, продължете вашето обучение

След завършване на този урок, разгледайте нашата [Колекция за обучение с генеративен AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), за да продължите да развивате знанията си за генеративен AI!

Преминете към Урок 4, където ще разгледаме [Основи на инженерството на промпти](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетния източник. За критична информация се препоръчва професионален човешки превод. Не носим отговорност за каквито и да било недоразумения или погрешни тълкувания, произтичащи от използването на този превод.