<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a45c318dc6ebc2604f35b8b829f93af2",
  "translation_date": "2025-05-19T16:21:32+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "bg"
}
-->
# Основи на инженерството на подканите

## Въведение
Този модул обхваща основни концепции и техники за създаване на ефективни подканки в генеративните AI модели. Начинът, по който пишете вашата подканка към LLM, също е важен. Внимателно изработената подканка може да постигне по-добро качество на отговора. Но какво точно означават термини като _подканка_ и _инженерство на подканите_? И как мога да подобря входа на подканката, който изпращам към LLM? Това са въпросите, които ще се опитаме да отговорим в тази глава и следващата.

_Генеративният AI_ е способен да създава ново съдържание (например текст, изображения, аудио, код и др.) в отговор на потребителски заявки. Това се постига с помощта на _Големи езикови модели_ като серията GPT ("Generative Pre-trained Transformer") на OpenAI, които са обучени за използване на естествен език и код.

Потребителите могат да взаимодействат с тези модели, използвайки познати парадигми като чат, без да е необходимо да имат технически познания или обучение. Моделите са _базирани на подканки_ - потребителите изпращат текстов вход (подканка) и получават обратно отговор от AI (завършване). Те могат след това да "чатят с AI" итеративно, в многоходови разговори, като усъвършенстват своята подканка, докато отговорът съответства на техните очаквания.

"Подканките" сега се превръщат в основния _програмен интерфейс_ за приложенията на генеративния AI, казвайки на моделите какво да правят и влияейки на качеството на върнатите отговори. "Инженерството на подканите" е бързо развиваща се област на изучаване, която се фокусира върху _проектирането и оптимизацията_ на подканките за предоставяне на последователни и качествени отговори в голям мащаб.

## Учебни цели

В този урок ще научим какво е инженерството на подканите, защо е важно и как можем да създаваме по-ефективни подканки за даден модел и цел на приложението. Ще разберем основните концепции и най-добрите практики за инженерство на подканите - и ще научим за интерактивна среда "sandbox" на Jupyter Notebooks, където можем да видим тези концепции, приложени към реални примери.

До края на този урок ще можем:

1. Да обясним какво е инженерството на подканите и защо е важно.
2. Да опишем компонентите на подканка и как се използват.
3. Да научим най-добрите практики и техники за инженерство на подканите.
4. Да приложим научените техники към реални примери, използвайки OpenAI endpoint.

## Основни термини

Инженерство на подканите: Практиката на проектиране и усъвършенстване на входовете, за да насочват AI моделите към създаване на желаните изходи.
Токенизация: Процесът на преобразуване на текста в по-малки единици, наречени токени, които моделът може да разбере и обработи.
LLM, настроени с инструкции: Големи езикови модели (LLM), които са фино настроени със специфични инструкции за подобряване на точността и релевантността на отговорите им.

## Учебен Sandbox

Инженерството на подканите в момента е повече изкуство, отколкото наука. Най-добрият начин да подобрим интуицията си за него е да _практикуваме повече_ и да приемем подхода на проби и грешки, който комбинира експертиза в областта на приложението с препоръчани техники и оптимизации, специфични за модела.

Jupyter Notebook, който съпътства този урок, предоставя среда "sandbox", където можете да изпробвате това, което научавате - докато напредвате или като част от предизвикателството с код в края. За да изпълните упражненията, ще ви е необходимо:

1. **Ключ за Azure OpenAI API** - endpoint на услугата за разположен LLM.
2. **Python Runtime** - в който Notebook може да бъде изпълнен.
3. **Локални променливи на средата** - _завършете стъпките [SETUP](./../00-course-setup/SETUP.md?WT.mc_id=academic-105485-koreyst) сега, за да се подготвите_.

Notebook идва със _стартови_ упражнения - но ви насърчаваме да добавите свои собствени секции _Markdown_ (описание) и _Code_ (заявки за подканки), за да изпробвате повече примери или идеи - и да изградите интуиция за проектиране на подканки.

## Илюстрирано ръководство

Искате ли да получите обща представа за това, което обхваща този урок, преди да се потопите? Разгледайте това илюстрирано ръководство, което ви дава усещане за основните теми, обхванати и ключовите изводи, за които да мислите във всяка от тях. Пътната карта на урока ви отвежда от разбирането на основните концепции и предизвикателства до тяхното адресиране с подходящи техники за инженерство на подканите и най-добрите практики. Обърнете внимание, че разделът "Разширени техники" в това ръководство се отнася до съдържание, обхванато в _следващата_ глава от тази учебна програма.

## Нашият стартъп

Сега, нека поговорим за това как _тази тема_ се отнася към нашата стартъп мисия да [донесем AI иновации в образованието](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Искаме да изградим AI-задвижвани приложения за _персонализирано обучение_ - така че да помислим как различни потребители на нашето приложение може да "проектират" подканки:

- **Администраторите** може да поискат от AI да _анализира данни от учебния план, за да идентифицира пропуски в покритието_. AI може да обобщи резултатите или да ги визуализира с код.
- **Преподавателите** може да поискат от AI да _генерира план на урок за целева аудитория и тема_. AI може да изгради персонализирания план в определен формат.
- **Учениците** може да поискат от AI да _ги обучава по труден предмет_. AI може да насочва учениците с уроци, подсказки и примери, съобразени с тяхното ниво.

Това е само върхът на айсберга. Разгледайте [Подканки за образование](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - библиотека с подканки с отворен код, курирана от образователни експерти - за да получите по-широко усещане за възможностите! _Опитайте да изпълните някои от тези подканки в sandbox или използвайте OpenAI Playground, за да видите какво се случва!_

## Какво е инженерство на подканите?

Започнахме този урок, като дефинирахме **инженерството на подканите** като процес на _проектиране и оптимизация_ на текстовите входове (подканки), за да се предоставят последователни и качествени отговори (завършвания) за дадена цел на приложението и модел. Можем да мислим за това като за процес в 2 стъпки:

- _проектиране_ на първоначалната подканка за даден модел и цел
- _усъвършенстване_ на подканката итеративно, за да се подобри качеството на отговора

Това е непременно процес на проби и грешки, който изисква потребителска интуиция и усилия, за да се постигнат оптимални резултати. Защо е важно? За да отговорим на този въпрос, първо трябва да разберем три концепции:

- _Токенизация_ = как моделът "вижда" подканката
- _Основни LLM_ = как основният модел "обработва" подканката
- _LLM, настроени с инструкции_ = как моделът може сега да вижда "задачи"

### Токенизация

Един LLM вижда подканките като _последователност от токени_, където различни модели (или версии на модел) могат да токенизират една и съща подканка по различни начини. Тъй като LLM са обучени на токени (а не на суров текст), начинът, по който подканките се токенизират, има пряк ефект върху качеството на генерирания отговор.

За да получите интуиция за това как работи токенизацията, опитайте инструменти като [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst), показан по-долу. Копирайте вашата подканка - и вижте как тя се преобразува в токени, обръщайки внимание на това как се обработват знаците за интервал и препинателните знаци. Обърнете внимание, че този пример показва по-стар LLM (GPT-3) - така че опитването на това с по-нов модел може да доведе до различен резултат.

### Концепция: Основни модели

След като подканката е токенизирана, основната функция на ["Основния LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (или Основен модел) е да предскаже токена в тази последователност. Тъй като LLM са обучени на огромни текстови набори от данни, те имат добро усещане за статистическите връзки между токените и могат да направят това предсказание с известна увереност. Обърнете внимание, че те не разбират _значението_ на думите в подканката или токена; те просто виждат модел, който могат да "завършат" с тяхното следващо предсказание. Те могат да продължат да предсказват последователността, докато не бъдат прекъснати от потребителска намеса или някакво предварително установено условие.

Искате ли да видите как работи завършването, базирано на подканки? Въведете горната подканка в [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) на Azure OpenAI Studio с настройките по подразбиране. Системата е конфигурирана да третира подканките като заявки за информация - така че трябва да видите завършване, което удовлетворява този контекст.

Но какво ако потребителят иска да види нещо конкретно, което отговаря на някои критерии или цел на задачата? Тук влизат в картината _LLM, настроени с инструкции_.

### Концепция: LLM, настроени с инструкции

[LLM, настроен с инструкции](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) започва с основния модел и го фино настройва с примери или двойки вход/изход (например, многоходови "съобщения"), които могат да съдържат ясни инструкции - и отговорът от AI се опитва да следва тази инструкция.

Това използва техники като Усилване на обучението с обратна връзка от хора (RLHF), които могат да обучат модела да _следва инструкции_ и _да учи от обратна връзка_, така че да създава отговори, които са по-подходящи за практически приложения и по-релевантни за потребителските цели.

Нека го изпробваме - прегледайте горната подканка, но сега променете _системното съобщение_, за да предоставите следната инструкция като контекст:

> _Обобщете съдържанието, което ви е предоставено, за ученик от втори клас. Запазете резултата в един параграф с 3-5 точки._

Вижте как резултатът сега е настроен да отразява желаната цел и формат? Преподавателят може сега директно да използва този отговор в своите слайдове за този клас.

## Защо ни е необходимо инженерство на подканите?

Сега, когато знаем как подканките се обработват от LLM, нека поговорим за _защо_ ни е необходимо инженерство на подканите. Отговорът се крие във факта, че текущите LLM поставят редица предизвикателства, които правят _надеждните и последователни завършвания_ по-трудни за постигане, без да се вложи усилие в конструирането и оптимизацията на подканките. Например:

1. **Отговорите на модела са стохастични.** _Една и съща подканка_ вероятно ще произведе различни отговори с различни модели или версии на моделите. И тя може дори да произведе различни резултати със _същия модел_ в различни моменти. _Техниките за инженерство на подканките могат да ни помогнат да минимизираме тези вариации, като предоставяме по-добри рамки_.

2. **Моделите могат да фабрикуват отговори.** Моделите са предварително обучени с _големи, но ограничени_ набори от данни, което означава, че им липсва знание за концепции извън този обхват на обучение. В резултат те могат да произведат завършвания, които са неточни, въображаеми или директно противоречащи на известни факти. _Техниките за инженерство на подканките помагат на потребителите да идентифицират и смекчат такива фабрикации, например, като поискат от AI цитати или разсъждения_.

3. **Възможностите на моделите ще варират.** По-новите модели или поколения модели ще имат по-богати възможности, но също така ще донесат уникални особености и компромиси в разходите и сложността. _Инженерството на подканките може да ни помогне да разработим най-добри практики и работни потоци, които абстрахират различията и се адаптират към изискванията на моделите по мащабируем и безпроблемен начин_.

Нека видим това в действие в OpenAI или Azure OpenAI Playground:

- Използвайте същата подканка с различни разположения на LLM (например, OpenAI, Azure OpenAI, Hugging Face) - видяхте ли вариациите?
- Използвайте същата подканка многократно със _същото_ разположение на LLM (например, Azure OpenAI Playground) - как се различаваха тези вариации?

### Пример за фабрикации

В този курс използваме термина **"фабрикация"** за да обозначим феномена, при който LLM понякога генерират фактически неправилна информация поради ограничения в обучението си или други ограничения. Може да сте чували това да се нарича _"халюцинации"_ в популярни статии или научни трудове. Въпреки това, силно препоръчваме използването на _"фабрикация"_ като термин, за да не антропоморфизираме поведението, като приписваме човешка черта на резултат, задвижван от машина. Това също така укрепва [Насоките за отговорен AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) от гледна точка на терминологията, премахвайки термини, които могат да бъдат считани за обидни или неинклузивни в някои контексти.

Искате ли да получите усещане за това как работят фабрикациите? Помислете за подканка, която инструктира AI да генерира съдържание за несъществуваща тема (за да се уверите, че не се намира в набора от данни за обучение). Например - аз опитах тази подканка:

> **Подканка:** генерирайте план на урок за Марсианската война от 2076.

Търсене в уеб
Накрая, истинската стойност на шаблоните се крие в способността да се създават и публикуват _библиотеки с подсказки_ за вертикални приложни домейни - където шаблонът за подсказка е _оптимизиран_ да отразява специфичен контекст или примери, които правят отговорите по-релевантни и точни за целевата аудитория. Репозиторият [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) е чудесен пример за този подход, събирайки библиотека с подсказки за образователния домейн с акцент върху ключови цели като планиране на уроци, проектиране на учебни програми, обучение на студенти и др.

## Поддържащо съдържание

Ако разглеждаме създаването на подсказки като включващо инструкция (задача) и цел (основно съдържание), тогава _вторичното съдържание_ е като допълнителен контекст, който предоставяме, за да **влияе на изхода по някакъв начин**. То може да бъде настройка на параметри, инструкции за форматиране, таксономии на теми и т.н., които могат да помогнат на модела да _персонализира_ своя отговор, за да отговаря на желаните цели или очаквания на потребителя.

Например: Даден е каталог на курсове с обширни метаданни (име, описание, ниво, метаданни тагове, инструктор и т.н.) за всички налични курсове в учебната програма:

- можем да определим инструкция да "обобщим каталога на курсовете за есента на 2023"
- можем да използваме основното съдържание, за да предоставим няколко примера за желания изход
- можем да използваме вторичното съдържание, за да идентифицираме топ 5 "тагове" от интерес.

Сега моделът може да предостави обобщение във формата, показан от няколко примера - но ако резултатът има множество тагове, той може да приоритизира 5-те тагове, идентифицирани във вторичното съдържание.

---

## Най-добри практики за създаване на подсказки

Сега, когато знаем как могат да бъдат _конструирани_ подсказките, можем да започнем да мислим как да ги _проектираме_, за да отразяват най-добрите практики. Можем да разгледаме това в две части - с правилната _настройка на ума_ и прилагане на правилните _техники_.

### Настройка на ума за създаване на подсказки

Създаването на подсказки е процес на проби и грешки, така че имайте предвид три основни водещи фактора:

1. **Разбирането на домейна е важно.** Точността и релевантността на отговорите е функция на _домейна_, в който приложението или потребителят работят. Използвайте вашата интуиция и експертни знания в домейна, за да **персонализирате техниките** допълнително. Например, дефинирайте _домейн-специфични личности_ във вашите системни подсказки или използвайте _домейн-специфични шаблони_ във вашите потребителски подсказки. Предоставете вторично съдържание, което отразява домейн-специфични контексти, или използвайте _домейн-специфични подсказки и примери_, за да насочите модела към познати модели на употреба.

2. **Разбирането на модела е важно.** Знаем, че моделите са стохастични по природа. Но имплементациите на моделите също могат да варират по отношение на набора от данни, който използват за обучение (предварително обучени знания), възможностите, които предоставят (напр. чрез API или SDK) и типа съдържание, за което са оптимизирани (напр. код срещу изображения срещу текст). Разберете силните и слабите страни на модела, който използвате, и използвайте тези знания, за да _приоритизирате задачите_ или изградите _персонализирани шаблони_, които са оптимизирани за възможностите на модела.

3. **Итерацията и валидацията са важни.** Моделите се развиват бързо, както и техниките за създаване на подсказки. Като експерт в домейна, може да имате друг контекст или критерии за _вашето_ специфично приложение, които може да не се прилагат за по-широката общност. Използвайте инструменти и техники за създаване на подсказки, за да "започнете" конструирането на подсказки, след това итератирайте и валидирайте резултатите, използвайки собствената си интуиция и експертни знания в домейна. Запишете вашите прозрения и създайте **база знания** (напр. библиотеки с подсказки), която може да бъде използвана като нова основа от други, за по-бързи итерации в бъдеще.

## Най-добри практики

Сега нека разгледаме общи най-добри практики, препоръчани от [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) и практици от [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Какво                             | Защо                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Оценявайте последните модели.     | Новите поколения модели вероятно имат подобрени функции и качество - но може също така да предизвикат по-високи разходи. Оценете ги за въздействие, след това вземете решения за миграция.                                                       |
| Разделете инструкции и контекст   | Проверете дали вашият модел/доставчик дефинира _разделители_, за да разграничите по-ясно инструкциите, основното и вторичното съдържание. Това може да помогне на моделите да присвоят тегла по-точно на токените.                                |
| Бъдете специфични и ясни          | Дайте повече детайли за желания контекст, резултат, дължина, формат, стил и т.н. Това ще подобри както качеството, така и консистентността на отговорите. Записвайте рецепти в използваеми шаблони.                                                |
| Бъдете описателни, използвайте примери | Моделите могат да отговорят по-добре на подход "покажи и разкажи". Започнете с `zero-shot` approach where you give it an instruction (but no examples) then try `few-shot` as a refinement, providing a few examples of the desired output. Use analogies. |
| Use cues to jumpstart completions | Nudge it towards a desired outcome by giving it some leading words or phrases that it can use as a starting point for the response.                                                                                                               |
| Double Down                       | Sometimes you may need to repeat yourself to the model. Give instructions before and after your primary content, use an instruction and a cue, etc. Iterate & validate to see what works.                                                         |
| Order Matters                     | The order in which you present information to the model may impact the output, even in the learning examples, thanks to recency bias. Try different options to see what works best.                                                               |
| Give the model an “out”           | Give the model a _fallback_ completion response it can provide if it cannot complete the task for any reason. This can reduce chances of models generating false or fabricated responses.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

As with any best practice, remember that _your mileage may vary_ based on the model, the task and the domain. Use these as a starting point, and iterate to find what works best for you. Constantly re-evaluate your prompt engineering process as new models and tools become available, with a focus on process scalability and response quality.

<!--
LESSON TEMPLATE:
This unit should provide a code challenge if applicable

CHALLENGE:
Link to a Jupyter Notebook with only the code comments in the instructions (code sections are empty).

SOLUTION:
Link to a copy of that Notebook with the prompts filled in and run, showing what one example could be.
-->

## Assignment

Congratulations! You made it to the end of the lesson! It's time to put some of those concepts and techniques to the test with real examples!

For our assignment, we'll be using a Jupyter Notebook with exercises you can complete interactively. You can also extend the Notebook with your own Markdown and Code cells to explore ideas and techniques on your own.

### To get started, fork the repo, then

- (Recommended) Launch GitHub Codespaces
- (Alternatively) Clone the repo to your local device and use it with Docker Desktop
- (Alternatively) Open the Notebook with your preferred Notebook runtime environment.

### Next, configure your environment variables

- Copy the `.env.copy` file in repo root to `.env` and fill in the `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` and `AZURE_OPENAI_DEPLOYMENT` стойности. Върнете се към [секцията за обучение](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals), за да научите как.

### Следващо, отворете Jupyter Notebook

- Изберете ядрото на изпълнение. Ако използвате опции 1 или 2, просто изберете стандартното ядро Python 3.10.x, предоставено от dev контейнера.

Всички сте готови да изпълните упражненията. Имайте предвид, че няма _правилни и грешни_ отговори тук - просто изследвате опциите чрез проби и грешки и изграждате интуиция за това, което работи за даден модел и приложен домейн.

_Поради тази причина няма сегменти за решение на код в този урок. Вместо това, Notebook ще има клетки Markdown, озаглавени "Моето решение:", които показват един примерен изход за справка._

## Проверка на знанията

Кое от следните е добра подсказка, следваща някои разумни най-добри практики?

1. Покажи ми изображение на червена кола
2. Покажи ми изображение на червена кола от марка Volvo и модел XC90, паркирана до скала с залязващо слънце
3. Покажи ми изображение на червена кола от марка Volvo и модел XC90

A: 2, това е най-добрата подсказка, тъй като предоставя детайли за "какво" и навлиза в конкретика (не просто всяка кола, а специфична марка и модел) и също така описва общата обстановка. 3 е следващата най-добра, тъй като също съдържа много описание.

## 🚀 Предизвикателство

Вижте дали можете да използвате техниката "подсказка" с подсказката: Завършете изречението "Покажи ми изображение на червена кола от марка Volvo и ". Какво отговаря и как бихте го подобрили?

## Страхотна работа! Продължете с обучението си

Искате ли да научите повече за различни концепции за създаване на подсказки? Отидете на [страницата за продължително обучение](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), за да намерите други чудесни ресурси по тази тема.

Преминете към Урок 5, където ще разгледаме [усъвършенствани техники за подсказки](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Докато се стремим към точност, моля, имайте предвид, че автоматизираните преводи могат да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетния източник. За критична информация се препоръчва професионален човешки превод. Не носим отговорност за каквито и да било недоразумения или неправилни интерпретации, произтичащи от използването на този превод.