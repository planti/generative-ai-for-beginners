<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5466bcedc3c75aa35476270362f626a",
  "translation_date": "2025-05-20T01:49:34+00:00",
  "source_file": "15-rag-and-vector-databases/data/frameworks.md",
  "language_code": "ar"
}
-->
# أطر الشبكات العصبية

كما تعلمنا بالفعل، لكي نتمكن من تدريب الشبكات العصبية بكفاءة، نحتاج إلى القيام بأمرين:

* العمل على الموترات، مثل الضرب، الجمع، وحساب بعض الدوال مثل سيجمويد أو سوفتماكس
* حساب المشتقات لجميع التعبيرات، من أجل تنفيذ تحسين الانحدار المتدرج

بينما يمكن لمكتبة `numpy` القيام بالجزء الأول، نحتاج إلى آلية لحساب المشتقات. في الإطار الذي قمنا بتطويره في القسم السابق، كان علينا برمجة جميع الدوال المشتقة يدويًا داخل طريقة `backward`، التي تقوم بالتراجع الخلفي. من الناحية المثالية، يجب أن يوفر لنا الإطار فرصة لحساب المشتقات لأي تعبير يمكننا تعريفه.

أمر مهم آخر هو القدرة على إجراء العمليات الحسابية على وحدات معالجة الرسوميات (GPU) أو أي وحدات حسابية متخصصة أخرى مثل TPU. يتطلب تدريب الشبكات العصبية العميقة الكثير من العمليات الحسابية، والقدرة على تنفيذ هذه العمليات بالتوازي على وحدات معالجة الرسوميات أمر بالغ الأهمية.

> ✅ مصطلح "التوازي" يعني توزيع العمليات الحسابية على أجهزة متعددة.

حاليًا، الإطاران الأكثر شهرة للشبكات العصبية هما: TensorFlow وPyTorch. كلاهما يوفر واجهة برمجة تطبيقات منخفضة المستوى للعمل مع الموترات على كل من وحدة المعالجة المركزية (CPU) ووحدة معالجة الرسوميات (GPU). بالإضافة إلى واجهة برمجة التطبيقات منخفضة المستوى، هناك أيضًا واجهة برمجة تطبيقات عالية المستوى، تُسمى كيراس وPyTorch Lightning على التوالي.

واجهة برمجة التطبيقات منخفضة المستوى | TensorFlow | PyTorch
--------------|-------------------------------------|--------------------------------
واجهة برمجة التطبيقات عالية المستوى | كيراس | PyTorch Lightning

**واجهات برمجة التطبيقات منخفضة المستوى** في كلا الإطارين تتيح لك بناء ما يسمى بـ **الرسوم البيانية الحسابية**. يحدد هذا الرسم البياني كيفية حساب الناتج (عادةً ما تكون دالة الخسارة) باستخدام المعلمات المدخلة، ويمكن دفعها للحساب على وحدة معالجة الرسوميات، إذا كانت متوفرة. هناك دوال لتفريق هذا الرسم البياني الحسابي وحساب المشتقات، والتي يمكن استخدامها بعد ذلك لتحسين معلمات النموذج.

**واجهات برمجة التطبيقات عالية المستوى** تعتبر الشبكات العصبية كـ **تسلسل من الطبقات**، وتجعل بناء معظم الشبكات العصبية أسهل بكثير. عادةً ما يتطلب تدريب النموذج إعداد البيانات ثم استدعاء دالة `fit` للقيام بالمهمة.

تسمح لك واجهة برمجة التطبيقات عالية المستوى ببناء الشبكات العصبية النموذجية بسرعة كبيرة دون القلق بشأن الكثير من التفاصيل. في الوقت نفسه، تقدم واجهة برمجة التطبيقات منخفضة المستوى تحكمًا أكبر في عملية التدريب، وبالتالي تُستخدم كثيرًا في الأبحاث، عندما تتعامل مع هياكل جديدة للشبكات العصبية.

من المهم أيضًا أن نفهم أنه يمكن استخدام كلتا واجهتي برمجة التطبيقات معًا، على سبيل المثال، يمكنك تطوير بنية طبقة الشبكة الخاصة بك باستخدام واجهة برمجة التطبيقات منخفضة المستوى، ثم استخدامها داخل الشبكة الأكبر التي تم بناؤها وتدريبها باستخدام واجهة برمجة التطبيقات عالية المستوى. أو يمكنك تعريف شبكة باستخدام واجهة برمجة التطبيقات عالية المستوى كتسلسل من الطبقات، ثم استخدام حلقة تدريب منخفضة المستوى خاصة بك لتنفيذ التحسين. كلتا واجهتي برمجة التطبيقات تستخدمان نفس المفاهيم الأساسية، وهي مصممة للعمل بشكل جيد معًا.

## التعلم

في هذه الدورة، نقدم معظم المحتوى لكل من PyTorch وTensorFlow. يمكنك اختيار الإطار الذي تفضله والمرور فقط عبر الدفاتر المقابلة. إذا لم تكن متأكدًا من الإطار الذي يجب اختياره، اقرأ بعض المناقشات على الإنترنت بخصوص **PyTorch مقابل TensorFlow**. يمكنك أيضًا إلقاء نظرة على كلا الإطارين للحصول على فهم أفضل.

حيثما أمكن، سنستخدم واجهات برمجة التطبيقات عالية المستوى من أجل البساطة. ومع ذلك، نعتقد أنه من المهم فهم كيفية عمل الشبكات العصبية من الأساس، لذا في البداية نبدأ بالعمل مع واجهة برمجة التطبيقات منخفضة المستوى والموترات. ومع ذلك، إذا كنت ترغب في البدء بسرعة ولا ترغب في قضاء الكثير من الوقت في تعلم هذه التفاصيل، يمكنك تخطيها والانتقال مباشرة إلى دفاتر واجهة برمجة التطبيقات عالية المستوى.

## ✍️ تمارين: الأطر

واصل تعلمك في الدفاتر التالية:

واجهة برمجة التطبيقات منخفضة المستوى | دفتر TensorFlow+Keras | PyTorch
--------------|-------------------------------------|--------------------------------
واجهة برمجة التطبيقات عالية المستوى | كيراس | *PyTorch Lightning*

بعد إتقان الأطر، دعونا نستعرض مفهوم الإفراط في التخصيص.

# الإفراط في التخصيص

الإفراط في التخصيص هو مفهوم مهم للغاية في تعلم الآلة، ومن المهم جدًا فهمه بشكل صحيح!

لننظر في المشكلة التالية لتقريب 5 نقاط (ممثلة بـ `x` في الرسوم البيانية أدناه):

!linear | overfit
-------------------------|--------------------------
**نموذج خطي، 2 معلمات** | **نموذج غير خطي، 7 معلمات**
خطأ التدريب = 5.3 | خطأ التدريب = 0
خطأ التحقق = 5.1 | خطأ التحقق = 20

* على اليسار، نرى تقريبًا جيدًا بخط مستقيم. لأن عدد المعلمات مناسب، النموذج يفهم الفكرة وراء توزيع النقاط بشكل صحيح.
* على اليمين، النموذج قوي جدًا. لأن لدينا فقط 5 نقاط والنموذج لديه 7 معلمات، يمكنه التكيف بطريقة تمر عبر جميع النقاط، مما يجعل خطأ التدريب يساوي 0. ومع ذلك، يمنع هذا النموذج من فهم النمط الصحيح وراء البيانات، وبالتالي فإن خطأ التحقق مرتفع جدًا.

من المهم جدًا إيجاد التوازن الصحيح بين غنى النموذج (عدد المعلمات) وعدد عينات التدريب.

## لماذا يحدث الإفراط في التخصيص

  * عدم وجود بيانات تدريب كافية
  * نموذج قوي جدًا
  * الكثير من الضوضاء في بيانات الإدخال

## كيفية اكتشاف الإفراط في التخصيص

كما يمكنك أن ترى من الرسم البياني أعلاه، يمكن اكتشاف الإفراط في التخصيص عن طريق خطأ تدريب منخفض جدًا، وخطأ تحقق مرتفع. عادةً أثناء التدريب سنرى كلا من أخطاء التدريب والتحقق تبدأ في الانخفاض، ثم في مرحلة ما قد يتوقف خطأ التحقق عن الانخفاض ويبدأ في الارتفاع. سيكون هذا علامة على الإفراط في التخصيص، ومؤشرًا على أنه يجب علينا على الأرجح إيقاف التدريب في هذه المرحلة (أو على الأقل أخذ لقطة للنموذج).

## كيفية منع الإفراط في التخصيص

إذا كنت ترى أن الإفراط في التخصيص يحدث، يمكنك القيام بأحد الأمور التالية:

 * زيادة كمية بيانات التدريب
 * تقليل تعقيد النموذج
 * استخدام بعض تقنيات التنظيم، مثل الإسقاط، التي سننظر فيها لاحقًا.

## الإفراط في التخصيص ومقايضة التحيز والتباين

الإفراط في التخصيص هو في الواقع حالة من مشكلة أكثر عمومية في الإحصاء تُسمى مقايضة التحيز والتباين. إذا نظرنا إلى المصادر المحتملة للخطأ في نموذجنا، يمكننا رؤية نوعين من الأخطاء:

* **أخطاء التحيز** ناتجة عن عدم قدرة خوارزميتنا على التقاط العلاقة بين بيانات التدريب بشكل صحيح. يمكن أن تنتج عن حقيقة أن نموذجنا ليس قويًا بما فيه الكفاية (**نقص التخصيص**).
* **أخطاء التباين**، التي ناتجة عن تقريب النموذج للضوضاء في بيانات الإدخال بدلاً من العلاقة ذات المعنى (**الإفراط في التخصيص**).

أثناء التدريب، ينخفض خطأ التحيز (مع تعلم نموذجنا تقريب البيانات)، ويزداد خطأ التباين. من المهم إيقاف التدريب - إما يدويًا (عندما نكتشف الإفراط في التخصيص) أو تلقائيًا (عن طريق إدخال التنظيم) - لمنع الإفراط في التخصيص.

## الخلاصة

في هذا الدرس، تعلمت عن الفروق بين واجهات برمجة التطبيقات المختلفة لأشهر إطارين للذكاء الاصطناعي، TensorFlow وPyTorch. بالإضافة إلى ذلك، تعلمت عن موضوع مهم جدًا، الإفراط في التخصيص.

## 🚀 التحدي

في الدفاتر المرافقة، ستجد "مهام" في الأسفل؛ اعمل من خلال الدفاتر وأكمل المهام.

## المراجعة والدراسة الذاتية

قم ببعض البحث حول الموضوعات التالية:

- TensorFlow
- PyTorch
- الإفراط في التخصيص

اطرح على نفسك الأسئلة التالية:

- ما هو الفرق بين TensorFlow وPyTorch؟
- ما هو الفرق بين الإفراط في التخصيص ونقص التخصيص؟

## الواجب

في هذا المختبر، يُطلب منك حل مشكلتين في التصنيف باستخدام شبكات متصلة بالكامل بطبقة واحدة ومتعددة الطبقات باستخدام PyTorch أو TensorFlow.

**إخلاء المسؤولية**:  
تم ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى للدقة، يُرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو معلومات غير دقيقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الموثوق. بالنسبة للمعلومات الحيوية، يُوصى بالترجمة البشرية الاحترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسير خاطئ ناتج عن استخدام هذه الترجمة.