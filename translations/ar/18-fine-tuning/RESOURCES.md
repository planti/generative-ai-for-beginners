<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:27:10+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "ar"
}
-->
# مصادر للتعلم الذاتي

تم بناء الدرس باستخدام عدد من المصادر الأساسية من OpenAI و Azure OpenAI كمرجع للمصطلحات والدروس. إليك قائمة غير شاملة، لرحلاتك الخاصة في التعلم الذاتي.

## 1. المصادر الأساسية

| العنوان/الرابط                                                                                                                                                                                                                   | الوصف                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Fine-tuning with OpenAI Models](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                       | تحسين النموذج باستخدام التخصيص الدقيق يحسن التعلم من خلال التدريب على أمثلة أكثر مما يمكن أن يتسع له في الطلب، مما يوفر التكاليف، ويحسن جودة الاستجابة، ويمكّن من طلبات ذات زمن استجابة أقل. **احصل على نظرة عامة على التخصيص الدقيق من OpenAI.**                                                                                    |
| [What is Fine-Tuning with Azure OpenAI?](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                   | فهم **ما هو التخصيص الدقيق (المفهوم)**، ولماذا يجب أن تنظر فيه (المشكلة المحفزة)، وما البيانات التي يجب استخدامها (التدريب) وكيفية قياس الجودة                                                                                                                                                                           |
| [Customize a model with fine-tuning](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst) | تتيح لك خدمة Azure OpenAI تخصيص نماذجنا لبياناتك الشخصية باستخدام التخصيص الدقيق. تعلم **كيفية التخصيص الدقيق (العملية)** لاختيار النماذج باستخدام Azure AI Studio أو Python SDK أو REST API.                                                                                                                                |
| [Recommendations for LLM fine-tuning](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                    | قد لا تعمل النماذج اللغوية الكبيرة بشكل جيد على مجالات أو مهام أو مجموعات بيانات معينة، أو قد تنتج مخرجات غير دقيقة أو مضللة. **متى يجب أن تنظر في التخصيص الدقيق** كحل ممكن لهذا؟                                                                                                                                  |
| [Continuous Fine Tuning](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)             | التخصيص الدقيق المستمر هو عملية تكرارية لاختيار نموذج تم تخصيصه بالفعل كنموذج أساسي و**تخصيصه بدقة أكثر** على مجموعات جديدة من أمثلة التدريب.                                                                                                                                                     |
| [Fine-tuning and function calling](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                       | يمكن أن يؤدي التخصيص الدقيق لنموذجك **بأمثلة استدعاء الوظائف** إلى تحسين مخرجات النموذج من خلال الحصول على مخرجات أكثر دقة وتناسقًا - مع استجابات ذات تنسيق مشابه وتوفير في التكاليف                                                                                                                                          |
| [Fine-tuning Models: Azure OpenAI Guidance](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                                        | ابحث في هذا الجدول لفهم **ما النماذج التي يمكن تخصيصها بدقة** في Azure OpenAI، وفي أي المناطق تتوفر هذه النماذج. تحقق من حدود الرموز وتواريخ انتهاء بيانات التدريب إذا لزم الأمر.                                                                                                                            |
| [To Fine Tune or Not To Fine Tune? That is the Question](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                      | يناقش هذا الحلقة التي مدتها 30 دقيقة من AI Show في **أكتوبر 2023** الفوائد والعيوب والرؤى العملية التي تساعدك على اتخاذ هذا القرار.                                                                                                                                                                                        |
| [Getting Started With LLM Fine-Tuning](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                             | يأخذك هذا المورد **AI Playbook** خلال متطلبات البيانات، والتنسيق، وتخصيص المعاملات الفائقة، والتحديات/القيود التي يجب أن تعرفها.                                                                                                                                                                         |
| **Tutorial**: [Azure OpenAI GPT3.5 Turbo Fine-Tuning](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                                  | تعلم كيفية إنشاء مجموعة بيانات تخصيص دقيق نموذجية، والتحضير للتخصيص الدقيق، وإنشاء مهمة تخصيص دقيق، ونشر النموذج الذي تم تخصيصه بدقة على Azure.                                                                                                                                                                                    |
| **Tutorial**: [Fine-tune a Llama 2 model in Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                                      | يتيح لك Azure AI Studio تخصيص نماذج اللغة الكبيرة لبياناتك الشخصية _باستخدام سير عمل يعتمد على واجهة المستخدم مناسب للمطورين ذوي الكود المنخفض_. شاهد هذا المثال.                                                                                                                                                               |
| **Tutorial**:[Fine-tune Hugging Face models for a single GPU on Azure](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)               | تصف هذه المقالة كيفية تخصيص نموذج Hugging Face باستخدام مكتبة محولات Hugging Face على وحدة معالجة رسومات واحدة مع Azure DataBricks + مكتبات Hugging Face Trainer                                                                                                                                                |
| **Training:** [Fine-tune a foundation model with Azure Machine Learning](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)         | يقدم كتالوج النماذج في Azure Machine Learning العديد من النماذج مفتوحة المصدر التي يمكنك تخصيصها بدقة لمهمتك المحددة. جرب هذا النموذج [من مسار التعلم AzureML Generative AI](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst) |
| **Tutorial:** [Azure OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                | يتيح التخصيص الدقيق لنماذج GPT-3.5 أو GPT-4 على Microsoft Azure باستخدام W&B تتبعًا مفصلًا وتحليلًا لأداء النموذج. يوسع هذا الدليل المفاهيم من دليل التخصيص الدقيق لـ OpenAI مع خطوات وميزات محددة لـ Azure OpenAI.                                                                         |
|                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                               |

## 2. المصادر الثانوية

تحتوي هذه القسم على موارد إضافية تستحق الاستكشاف، ولكن لم يكن لدينا الوقت لتغطيتها في هذا الدرس. قد يتم تغطيتها في درس مستقبلي، أو كخيار مهمة ثانوية، في وقت لاحق. في الوقت الحالي، استخدمها لبناء خبرتك ومعرفتك حول هذا الموضوع.

| العنوان/الرابط                                                                                                                                                                                                            | الوصف                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI Cookbook**: [Data preparation and analysis for chat model fine-tuning](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                                      | يخدم هذا الدفتر كأداة لمعالجة وتحليل مجموعة البيانات المستخدمة لتخصيص نموذج الدردشة. يتحقق من أخطاء التنسيق، ويوفر إحصائيات أساسية، ويقدر عدد الرموز لتكاليف التخصيص الدقيق. انظر: [طريقة التخصيص الدقيق لـ gpt-3.5-turbo](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst).                                                                                                                                                                   |
| **OpenAI Cookbook**: [Fine-Tuning for Retrieval Augmented Generation (RAG) with Qdrant](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst) | الهدف من هذا الدفتر هو المرور بمثال شامل لكيفية تخصيص نماذج OpenAI لتوليد المعلومات المدعومة بالاسترجاع (RAG). سنقوم أيضًا بدمج Qdrant و Few-Shot Learning لتحسين أداء النموذج وتقليل التلفيقات.                                                                                                                                                                                                                                                                |
| **OpenAI Cookbook**: [Fine-tuning GPT with Weights & Biases](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                             | Weights & Biases (W&B) هو منصة مطورين للذكاء الاصطناعي، مع أدوات لتدريب النماذج، وتخصيص النماذج، والاستفادة من النماذج الأساسية. اقرأ دليلهم [OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst) أولاً، ثم جرب تمرين Cookbook.                                                                                                                                                                                                                  |
| **Community Tutorial** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - fine-tuning for Small Language Models                                                   | تعرف على [Phi-2](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst)، النموذج الصغير الجديد من Microsoft، قوي بشكل ملحوظ ومع ذلك مضغوط. سيرشدك هذا البرنامج التعليمي عبر تخصيص Phi-2، ويظهر لك كيفية بناء مجموعة بيانات فريدة وتخصيص النموذج باستخدام QLoRA.                                                                                                                                                                       |
| **Hugging Face Tutorial** [How to Fine-Tune LLMs in 2024 with Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | يأخذك هذا المنشور في المدونة عبر كيفية تخصيص النماذج اللغوية الكبيرة المفتوحة باستخدام Hugging Face TRL، وTransformers وdatasets في عام 2024. تحدد حالة استخدام، إعداد بيئة تطوير، تحضير مجموعة بيانات، تخصيص النموذج، اختباره وتقييمه، ثم نشره للإنتاج.                                                                                                                                                                                                                                                                |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                            | يجلب تدريبًا ونشرًا أسرع وأسهل لـ [نماذج التعلم الآلي المتطورة](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst). يحتوي المستودع على دروس صديقة لـ Colab مع إرشادات فيديو على YouTube، للتخصيص الدقيق. **يعكس التحديث الأخير [local-first](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst)** . اقرأ [وثائق AutoTrain](https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst) |
|                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |

**إخلاء المسؤولية**:  
تم ترجمة هذه الوثيقة باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى للدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار الوثيقة الأصلية بلغتها الأم المصدر الرسمي. للحصول على معلومات حاسمة، يُوصى بالترجمة البشرية الاحترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسير خاطئ ناتج عن استخدام هذه الترجمة.