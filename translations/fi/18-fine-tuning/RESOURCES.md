<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:43:01+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "fi"
}
-->
# Itseopiskelun Resurssit

Tämä oppitunti rakennettiin käyttäen useita keskeisiä resursseja OpenAI:lta ja Azure OpenAI:lta, jotka toimivat viitteinä terminologialle ja tutoriaaleille. Tässä on epätäydellinen lista, jota voit hyödyntää omalla itseopiskelumatkallasi.

## 1. Ensisijaiset Resurssit

| Otsikko/Linkki                                                                                                                                                                                                                   | Kuvaus                                                                                                                                                                                                                                                                                                                   |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| [OpenAI-mallien hienosäätö](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                               | Hienosäätö parantaa vähäesimerkkistä oppimista kouluttamalla huomattavasti enemmän esimerkkejä kuin mitä mahtuu kehotteeseen, mikä säästää kustannuksia, parantaa vastausten laatua ja mahdollistaa alhaisemman viiveen pyynnöt. **Tutustu hienosäädön yleiskatsaukseen OpenAI:lta.**                                      |
| [Mitä on hienosäätö Azure OpenAI:n kanssa?](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                    | Ymmärrä **mitä hienosäätö on (konsepti)**, miksi sinun pitäisi harkita sitä (motivaatio), mitä dataa käyttää (koulutus) ja laadun mittaaminen.                                                                                                                                                                           |
| [Mukauta mallia hienosäädöllä](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)          | Azure OpenAI Service antaa sinun mukauttaa mallejamme omiin tietoaineistoihisi hienosäädön avulla. Opi **kuinka hienosäätö tehdään (prosessi)** valitsemalla malleja Azure AI Studiota, Python SDK:ta tai REST API:a käyttäen.                                                                                           |
| [Suositukset LLM:n hienosäädölle](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                         | LLM:t eivät välttämättä toimi hyvin tietyillä aloilla, tehtävissä tai tietoaineistoissa, tai saattavat tuottaa epätarkkoja tai harhaanjohtavia tuloksia. **Milloin sinun pitäisi harkita hienosäätöä** mahdollisena ratkaisuna tähän?                                                                                     |
| [Jatkuva hienosäätö](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)                   | Jatkuva hienosäätö on iteratiivinen prosessi, jossa valitaan jo hienosäädetty malli pohjamalliksi ja **hienosäädetään sitä edelleen** uusilla koulutusesimerkeillä.                                                                                                                                                       |
| [Hienosäätö ja toimintojen kutsuminen](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                      | Mallin hienosäätö **toimintojen kutsumisesimerkeillä** voi parantaa mallin tuottamaa tulosta saaden tarkempia ja johdonmukaisempia vastauksia - samankaltaisesti muotoiltuja vastauksia ja kustannussäästöjä.                                                                                                              |
| [Hienosäätömallit: Azure OpenAI:n ohjeistus](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                                          | Katso tämä taulukko ymmärtääksesi **mitä malleja voidaan hienosäätää** Azure OpenAI:ssa ja missä alueilla ne ovat saatavilla. Katso niiden token-rajoitukset ja koulutusdatan vanhentumispäivät tarvittaessa.                                                                                                             |
| [Hienosäätääkö vai ei? Siinäpä kysymys](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                                         | Tämä 30-minuutin **lokakuu 2023** jakso AI Show'ssa käsittelee etuja, haittoja ja käytännön näkemyksiä, jotka auttavat sinua tekemään tämän päätöksen.                                                                                                                                                                    |
| [Aloittaminen LLM:n hienosäädöllä](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                       | Tämä **AI Playbook** -resurssi opastaa sinua datavaatimusten, muotoilun, hyperparametrien hienosäädön ja haasteiden/rajoitusten läpi, jotka sinun pitäisi tietää.                                                                                                                                                          |
| **Tutoriaali**: [Azure OpenAI GPT3.5 Turbo Hienosäätö](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                                  | Opi luomaan esimerkkidatasetti hienosäätöä varten, valmistautumaan hienosäätöön, luomaan hienosäätötyö ja ottamaan hienosäädetty malli käyttöön Azurella.                                                                                                                                                                  |
| **Tutoriaali**: [Hienosäädä Llama 2 -malli Azure AI Studiossa](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                                     | Azure AI Studio antaa sinun mukauttaa suuria kielimalleja omiin tietoaineistoihisi _käyttäen käyttöliittymäpohjaista työnkulkua, joka sopii vähäkoodisille kehittäjille_. Katso tämä esimerkki.                                                                                                                            |
| **Tutoriaali**: [Hienosäädä Hugging Face -malleja yhdellä GPU:lla Azuren kanssa](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)      | Tämä artikkeli kuvaa, kuinka hienosäätää Hugging Face -mallia Hugging Face transformers -kirjastolla yhdellä GPU:lla käyttäen Azure DataBricks + Hugging Face Trainer -kirjastoja.                                                                                                                                         |
| **Koulutus:** [Hienosäädä perusmalli Azure Machine Learningilla](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)                    | Mallikatalogi Azure Machine Learningissa tarjoaa monia avoimen lähdekoodin malleja, joita voit hienosäätää omaan tehtävääsi. Kokeile tätä moduulia [AzureML Generative AI Learning Path](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst) osana. |
| **Tutoriaali:** [Azure OpenAI Hienosäätö](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                               | GPT-3.5- tai GPT-4-mallien hienosäätö Microsoft Azurella W&B:n avulla mahdollistaa mallin suorituskyvyn yksityiskohtaisen seurannan ja analysoinnin. Tämä opas laajentaa OpenAI:n hienosäätöoppaan käsitteitä erityisillä vaiheilla ja ominaisuuksilla Azure OpenAI:lle.                                                    |
|                                                                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                           |

## 2. Toissijaiset Resurssit

Tämä osio sisältää lisäresursseja, jotka ovat tutustumisen arvoisia, mutta joita emme ehtineet käsitellä tässä oppitunnissa. Ne voidaan käsitellä tulevassa oppitunnissa tai toissijaisena tehtävävaihtoehtona myöhemmin. Toistaiseksi käytä niitä rakentaaksesi omaa asiantuntemustasi ja tietämystäsi tästä aiheesta.

| Otsikko/Linkki                                                                                                                                                                                                                   | Kuvaus                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI Cookbook**: [Datan valmistelu ja analysointi chat-mallin hienosäätöä varten](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                                           | Tämä muistikirja toimii työkaluna chat-tietoaineiston esikäsittelyyn ja analysointiin, jota käytetään chat-mallin hienosäätöön. Se tarkistaa muotovirheet, tarjoaa perustilastoja ja arvioi token-määriä hienosäätökustannuksia varten. Katso: [Hienosäätömenetelmä gpt-3.5-turbo:lle](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst).                                                                                                                                              |
| **OpenAI Cookbook**: [Hienosäätö hakupohjaiselle generoinnille (RAG) Qdrantin kanssa](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst)             | Tämän muistikirjan tarkoituksena on käydä läpi kattava esimerkki siitä, kuinka hienosäätää OpenAI-malleja hakupohjaista generointia (RAG) varten. Integroimme myös Qdrantin ja vähäesimerkkisen oppimisen parantaaksemme mallin suorituskykyä ja vähentääksemme virheitä.                                                                                                                                                                                                                      |
| **OpenAI Cookbook**: [Hienosäätö GPT:lle Weights & Biases:in kanssa](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                               | Weights & Biases (W&B) on AI-kehittäjäalusta, jossa on työkaluja mallien kouluttamiseen, hienosäätöön ja perustamallien hyödyntämiseen. Lue heidän [OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst) oppaansa ensin, ja kokeile sitten Cookbook-harjoitusta.                                                                                                                                                                                            |
| **Yhteisön Tutoriaali** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - hienosäätö pienille kielimalleille                                                              | Tutustu [Phi-2:een](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst), Microsoftin uuteen pieneen malliin, joka on yllättävän tehokas mutta kompakti. Tämä tutoriaali opastaa sinua Phi-2:n hienosäädössä, näyttäen kuinka rakentaa ainutlaatuinen datasetti ja hienosäätää malli käyttäen QLoRA:a.                                                                                                                                     |
| **Hugging Face Tutoriaali** [Kuinka hienosäätää LLM:ä vuonna 2024 Hugging Face:in kanssa](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                         | Tämä blogikirjoitus opastaa sinua, kuinka hienosäätää avoimia LLM:ä Hugging Face TRL:n, Transformersin ja datasetien avulla vuonna 2024. Määrität käyttötapauksen, asetat kehitysympäristön, valmistelet datasetin, hienosäädät mallin, testaat ja arvioit sen, ja sitten otat sen tuotantoon.                                                                                                                                                                                        |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                                     | Mahdollistaa nopeamman ja helpomman koulutuksen ja käyttöönoton [huipputeknologian koneoppimismalleille](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst). Repo sisältää Colab-ystävällisiä tutoriaaleja YouTube-videon opastuksella hienosäätöön. **Heijastaa viimeisintä [local-first](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst) päivitystä**. Lue [AutoTrain dokumentaatio](https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst). |
|                                                                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |

**Vastuuvapauslauseke**:  
Tämä asiakirja on käännetty käyttämällä tekoälyn käännöspalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Pyrimme tarkkuuteen, mutta huomioithan, että automaattiset käännökset voivat sisältää virheitä tai epätarkkuuksia. Alkuperäistä asiakirjaa sen alkuperäisellä kielellä tulisi pitää auktoriteettina. Kriittistä tietoa varten suositellaan ammattilaisten tekemää ihmiskäännöstä. Emme ole vastuussa väärinkäsityksistä tai virhetulkinnoista, jotka johtuvat tämän käännöksen käytöstä.