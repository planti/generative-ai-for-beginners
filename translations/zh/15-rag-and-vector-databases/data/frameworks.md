<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5466bcedc3c75aa35476270362f626a",
  "translation_date": "2025-05-20T01:51:03+00:00",
  "source_file": "15-rag-and-vector-databases/data/frameworks.md",
  "language_code": "zh"
}
-->
# 神经网络框架

正如我们已经学习过的，要有效地训练神经网络，我们需要做到以下两点：

* 操作张量，例如进行乘法、加法，并计算一些函数如sigmoid或softmax
* 计算所有表达式的梯度，以进行梯度下降优化

虽然`numpy`库可以完成第一部分，但我们需要某种机制来计算梯度。在我们在上一节中开发的框架中，我们必须手动在`backward`方法中编写所有导数函数，该方法执行反向传播。理想情况下，一个框架应该能够计算我们定义的*任何表达式*的梯度。

另一个重要的事情是能够在GPU或其他专用计算单元（如TPU）上进行计算。深度神经网络训练需要*大量*计算，能够在GPU上并行化这些计算非常重要。

> ✅ “并行化”一词指的是将计算分布到多个设备上。

目前，最流行的两个神经框架是：TensorFlow和PyTorch。两者都提供了一个低级API，可以在CPU和GPU上操作张量。在低级API之上，还有一个高级API，分别称为Keras和PyTorch Lightning。

低级API | TensorFlow | PyTorch
--------|------------|--------
高级API | Keras      | PyTorch Lightning

**低级API** 在两个框架中都允许你构建所谓的**计算图**。这个图定义了如何用给定的输入参数计算输出（通常是损失函数），并且可以在GPU上进行计算（如果可用）。有一些函数可以对这个计算图进行微分并计算梯度，然后可以用来优化模型参数。

**高级API** 基本上将神经网络视为一个**层的序列**，使得构建大多数神经网络变得更加容易。训练模型通常需要准备数据，然后调用`fit`函数来完成任务。

高级API允许你快速构建典型的神经网络，而无需担心很多细节。同时，低级API提供了对训练过程的更多控制，因此在研究中经常使用，尤其是在处理新的神经网络架构时。

还需要理解的是，你可以同时使用这两个API，例如，你可以使用低级API开发自己的网络层架构，然后在用高级API构建和训练的大型网络中使用它。或者，你可以使用高级API将网络定义为层的序列，然后使用自己的低级训练循环进行优化。两个API使用相同的基本概念，并且设计为可以很好地协同工作。

## 学习

在本课程中，我们为PyTorch和TensorFlow提供了大部分内容。你可以选择自己喜欢的框架，只需浏览相应的笔记本。如果你不确定选择哪个框架，可以在网上阅读一些关于**PyTorch与TensorFlow**的讨论。你也可以同时查看两个框架以更好地理解。

在可能的情况下，我们将使用高级API以简化过程。然而，我们认为了解神经网络从基础开始的工作原理很重要，因此一开始我们会从低级API和张量入手。然而，如果你想快速入门，不想花太多时间学习这些细节，可以跳过这些直接进入高级API笔记本。

## ✍️ 练习：框架

在以下笔记本中继续学习：

低级API | TensorFlow+Keras 笔记本 | PyTorch
--------|---------------------------|--------
高级API | Keras                     | *PyTorch Lightning*

掌握这些框架后，让我们回顾一下过拟合的概念。

# 过拟合

过拟合是机器学习中一个极其重要的概念，非常重要的是要正确理解它！

考虑以下近似5个点的问题（用`x`在下图中表示）：

!线性 | 过拟合
-------------------------|--------------------------
**线性模型，2个参数** | **非线性模型，7个参数**
训练误差 = 5.3 | 训练误差 = 0
验证误差 = 5.1 | 验证误差 = 20

* 左边，我们看到一个不错的直线近似。因为参数数量适当，模型正确理解了点的分布。
* 右边，模型过于强大。因为我们只有5个点，而模型有7个参数，它可以调整为通过所有点，使得训练误差为0。然而，这阻碍了模型理解数据背后的正确模式，因此验证误差非常高。

在模型的复杂性（参数数量）和训练样本数量之间找到正确的平衡非常重要。

## 为什么会发生过拟合

  * 训练数据不足
  * 模型过于强大
  * 输入数据中噪声过多

## 如何检测过拟合

如上图所示，过拟合可以通过非常低的训练误差和高验证误差来检测。通常在训练过程中，我们会看到训练误差和验证误差都开始下降，然后在某个点验证误差可能停止下降并开始上升。这将是过拟合的信号，并且是我们可能应该停止训练的指示（或者至少对模型进行快照）。

## 如何防止过拟合

如果你发现发生了过拟合，你可以采取以下措施之一：

 * 增加训练数据的数量
 * 减少模型的复杂性
 * 使用一些正则化技术，如Dropout，我们将在后面考虑。

## 过拟合与偏差-方差权衡

过拟合实际上是统计学中一个更通用的问题，称为偏差-方差权衡。如果我们考虑模型中可能的误差来源，可以看到两种类型的误差：

* **偏差误差** 由我们的算法无法正确捕捉训练数据之间的关系引起。它可能是因为我们的模型不够强大（**欠拟合**）。
* **方差误差** 由模型近似输入数据中的噪声而非有意义的关系引起（**过拟合**）。

在训练过程中，偏差误差减少（因为我们的模型学习近似数据），方差误差增加。重要的是要停止训练——无论是手动（当我们检测到过拟合时）还是自动（通过引入正则化）——以防止过拟合。

## 结论

在本课中，你学习了两个最流行的AI框架TensorFlow和PyTorch的各种API之间的差异。此外，你还学习了一个非常重要的话题，过拟合。

## 🚀 挑战

在附带的笔记本中，你会在底部找到“任务”；浏览笔记本并完成任务。

## 回顾与自学

对以下主题进行一些研究：

- TensorFlow
- PyTorch
- 过拟合

问自己以下问题：

- TensorFlow和PyTorch有什么区别？
- 过拟合和欠拟合有什么区别？

## 作业

在本实验中，你需要使用PyTorch或TensorFlow解决两个使用单层和多层全连接网络的分类问题。

**免责声明**：
本文档已使用AI翻译服务[Co-op Translator](https://github.com/Azure/co-op-translator)进行翻译。尽管我们努力确保准确性，但请注意，自动翻译可能包含错误或不准确之处。应将原始语言的文档视为权威来源。对于关键信息，建议进行专业的人类翻译。我们不对因使用本翻译而产生的任何误解或误读负责。