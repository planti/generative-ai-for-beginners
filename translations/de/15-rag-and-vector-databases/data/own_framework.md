<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df98b2c59f87d8543135301e87969f70",
  "translation_date": "2025-05-20T02:11:10+00:00",
  "source_file": "15-rag-and-vector-databases/data/own_framework.md",
  "language_code": "de"
}
-->
# EinfÃ¼hrung in neuronale Netze. Mehrschichtiges Perzeptron

Im vorherigen Abschnitt haben Sie das einfachste Modell eines neuronalen Netzes kennengelernt - das einlagige Perzeptron, ein lineares Zwei-Klassen-Klassifikationsmodell.

In diesem Abschnitt werden wir dieses Modell in ein flexibleres Framework erweitern, das es uns ermÃ¶glicht:

* **Mehrklassenklassifikation** zusÃ¤tzlich zur Zwei-Klassen-Klassifikation durchzufÃ¼hren
* **Regressionsprobleme** zusÃ¤tzlich zur Klassifikation zu lÃ¶sen
* Klassen zu trennen, die nicht linear separierbar sind

Wir werden auch unser eigenes modulares Framework in Python entwickeln, das es uns ermÃ¶glicht, verschiedene Architekturen von neuronalen Netzen zu konstruieren.

## Formalisierung des maschinellen Lernens

Beginnen wir mit der Formalisierung des Problems des maschinellen Lernens. Angenommen, wir haben einen Trainingsdatensatz **X** mit Labels **Y**, und wir mÃ¼ssen ein Modell *f* erstellen, das die genauesten Vorhersagen trifft. Die QualitÃ¤t der Vorhersagen wird durch die **Verlustfunktion** â„’ gemessen. Die folgenden Verlustfunktionen werden hÃ¤ufig verwendet:

* FÃ¼r Regressionsprobleme, wenn wir eine Zahl vorhersagen mÃ¼ssen, kÃ¶nnen wir den **absoluten Fehler** âˆ‘<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>| oder den **quadratischen Fehler** âˆ‘<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup> verwenden
* FÃ¼r die Klassifikation verwenden wir den **0-1-Verlust** (was im Wesentlichen dasselbe ist wie die **Genauigkeit** des Modells) oder den **logistischen Verlust**.

FÃ¼r das einlagige Perzeptron wurde die Funktion *f* als lineare Funktion *f(x)=wx+b* definiert (hier ist *w* die Gewichtsmatrix, *x* ist der Vektor der Eingabefeatures und *b* ist der Bias-Vektor). FÃ¼r verschiedene Architekturen von neuronalen Netzen kann diese Funktion eine komplexere Form annehmen.

> Im Fall der Klassifikation ist es oft wÃ¼nschenswert, Wahrscheinlichkeiten der entsprechenden Klassen als Netzwerkausgabe zu erhalten. Um beliebige Zahlen in Wahrscheinlichkeiten umzuwandeln (z.B. um die Ausgabe zu normalisieren), verwenden wir oft die **Softmax-Funktion** Ïƒ, und die Funktion *f* wird zu *f(x)=Ïƒ(wx+b)*

In der Definition von *f* oben werden *w* und *b* als **Parameter** Î¸=âŸ¨*w,b*âŸ© bezeichnet. Angesichts des Datensatzes âŸ¨**X**,**Y**âŸ© kÃ¶nnen wir einen Gesamten Fehler fÃ¼r den gesamten Datensatz als Funktion der Parameter Î¸ berechnen.

> âœ… **Das Ziel des Trainings von neuronalen Netzen ist es, den Fehler durch Variation der Parameter Î¸ zu minimieren**

## Gradient-Abstiegsoptimierung

Es gibt eine bekannte Methode der Funktionsoptimierung namens **Gradientenabstieg**. Die Idee ist, dass wir eine Ableitung (im mehrdimensionalen Fall **Gradient** genannt) der Verlustfunktion bezÃ¼glich der Parameter berechnen kÃ¶nnen und die Parameter so variieren, dass der Fehler abnimmt. Dies kann wie folgt formalisiert werden:

* Initialisieren Sie die Parameter mit einigen Zufallswerten w<sup>(0)</sup>, b<sup>(0)</sup>
* Wiederholen Sie den folgenden Schritt viele Male:
    - w<sup>(i+1)</sup> = w<sup>(i)</sup>-Î·âˆ‚â„’/âˆ‚w
    - b<sup>(i+1)</sup> = b<sup>(i)</sup>-Î·âˆ‚â„’/âˆ‚b

WÃ¤hrend des Trainings sollen die Optimierungsschritte unter BerÃ¼cksichtigung des gesamten Datensatzes berechnet werden (denken Sie daran, dass der Verlust als Summe Ã¼ber alle Trainingsproben berechnet wird). In der RealitÃ¤t nehmen wir jedoch kleine Teile des Datensatzes, sogenannte **Minibatches**, und berechnen die Gradienten basierend auf einem Teil der Daten. Da der Teil jedes Mal zufÃ¤llig gewÃ¤hlt wird, wird diese Methode als **stochastischer Gradientenabstieg** (SGD) bezeichnet.

## Mehrschichtige Perzeptrons und Backpropagation

Ein einlagiges Netzwerk, wie wir oben gesehen haben, ist in der Lage, linear separierbare Klassen zu klassifizieren. Um ein reichhaltigeres Modell zu erstellen, kÃ¶nnen wir mehrere Schichten des Netzwerks kombinieren. Mathematisch wÃ¼rde dies bedeuten, dass die Funktion *f* eine komplexere Form hat und in mehreren Schritten berechnet wird:
* z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub>
* z<sub>2</sub>=w<sub>2</sub>Î±(z<sub>1</sub>)+b<sub>2</sub>
* f = Ïƒ(z<sub>2</sub>)

Hier ist Î± eine **nichtlineare Aktivierungsfunktion**, Ïƒ ist eine Softmax-Funktion und die Parameter Î¸=<*w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>*>.

Der Gradientenabstiegsalgorithmus wÃ¼rde gleich bleiben, aber es wÃ¤re schwieriger, die Gradienten zu berechnen. Angesichts der Kettenregel der Differentiation kÃ¶nnen wir die Ableitungen wie folgt berechnen:

* âˆ‚â„’/âˆ‚w<sub>2</sub> = (âˆ‚â„’/âˆ‚Ïƒ)(âˆ‚Ïƒ/âˆ‚z<sub>2</sub>)(âˆ‚z<sub>2</sub>/âˆ‚w<sub>2</sub>)
* âˆ‚â„’/âˆ‚w<sub>1</sub> = (âˆ‚â„’/âˆ‚Ïƒ)(âˆ‚Ïƒ/âˆ‚z<sub>2</sub>)(âˆ‚z<sub>2</sub>/âˆ‚Î±)(âˆ‚Î±/âˆ‚z<sub>1</sub>)(âˆ‚z<sub>1</sub>/âˆ‚w<sub>1</sub>)

> âœ… Die Kettenregel der Differentiation wird verwendet, um die Ableitungen der Verlustfunktion bezÃ¼glich der Parameter zu berechnen.

Beachten Sie, dass der linke Teil all dieser AusdrÃ¼cke gleich ist und wir daher die Ableitungen effektiv berechnen kÃ¶nnen, indem wir von der Verlustfunktion aus "rÃ¼ckwÃ¤rts" durch den Berechnungsgraphen gehen. Daher wird die Methode des Trainings eines mehrschichtigen Perzeptrons als **Backpropagation** oder 'Backprop' bezeichnet.

> TODO: Bildzitat

> âœ… Wir werden Backprop in unserem Notebook-Beispiel viel detaillierter behandeln.  

## Fazit

In dieser Lektion haben wir unsere eigene Bibliothek fÃ¼r neuronale Netze erstellt und sie fÃ¼r eine einfache zweidimensionale Klassifikationsaufgabe verwendet.

## ğŸš€ Herausforderung

Im begleitenden Notebook werden Sie Ihr eigenes Framework fÃ¼r den Bau und das Training mehrschichtiger Perzeptrons implementieren. Sie werden im Detail sehen kÃ¶nnen, wie moderne neuronale Netze arbeiten.

Gehen Sie zum OwnFramework-Notebook und arbeiten Sie es durch.

## ÃœberprÃ¼fung & Selbststudium

Backpropagation ist ein hÃ¤ufig verwendeter Algorithmus in KI und ML, der es wert ist, im Detail studiert zu werden.

## Aufgabe

In diesem Labor werden Sie aufgefordert, das Framework, das Sie in dieser Lektion erstellt haben, zur LÃ¶sung der MNIST-Handschriftenerkennung zu verwenden.

* Anweisungen
* Notebook

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-Ãœbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) Ã¼bersetzt. Obwohl wir uns um Genauigkeit bemÃ¼hen, beachten Sie bitte, dass automatisierte Ãœbersetzungen Fehler oder Ungenauigkeiten enthalten kÃ¶nnen. Das Originaldokument in seiner ursprÃ¼nglichen Sprache sollte als maÃŸgebliche Quelle betrachtet werden. FÃ¼r kritische Informationen wird eine professionelle menschliche Ãœbersetzung empfohlen. Wir haften nicht fÃ¼r MissverstÃ¤ndnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser Ãœbersetzung ergeben.