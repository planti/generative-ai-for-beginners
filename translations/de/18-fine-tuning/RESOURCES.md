<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:25:57+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "de"
}
-->
# Ressourcen für selbstgesteuertes Lernen

Die Lektion wurde mit einer Reihe von Kernressourcen von OpenAI und Azure OpenAI erstellt, die als Referenzen für die Terminologie und Tutorials dienen. Hier ist eine nicht umfassende Liste für eure eigenen selbstgesteuerten Lernreisen.

## 1. Primäre Ressourcen

| Titel/Link                                                                                                                                                                                                                  | Beschreibung                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Feinabstimmung mit OpenAI-Modellen](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                  | Feinabstimmung verbessert das Few-Shot-Learning, indem auf viele mehr Beispiele trainiert wird, als in den Prompt passen, wodurch Kosten gespart, die Antwortqualität verbessert und Anfragen mit geringerer Latenz ermöglicht werden. **Erhaltet einen Überblick über die Feinabstimmung von OpenAI.**                                                              |
| [Was ist Feinabstimmung mit Azure OpenAI?](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                 | Versteht **was Feinabstimmung ist (Konzept)**, warum ihr es in Betracht ziehen solltet (motiviertes Problem), welche Daten verwendet werden sollen (Training) und wie die Qualität gemessen wird.                                                                                                                                                                    |
| [Anpassen eines Modells mit Feinabstimmung](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst) | Der Azure OpenAI Service ermöglicht es euch, unsere Modelle mit Feinabstimmung auf eure persönlichen Datensätze abzustimmen. Lernt **wie man Modelle auswählt (Prozess)** und mit Azure AI Studio, Python SDK oder REST API feinabstimmt.                                                                                                                             |
| [Empfehlungen für LLM-Feinabstimmung](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                     | LLMs können in bestimmten Domänen, Aufgaben oder Datensätzen nicht gut abschneiden oder ungenaue oder irreführende Ausgaben erzeugen. **Wann solltet ihr Feinabstimmung** als mögliche Lösung in Betracht ziehen?                                                                                                                                                    |
| [Kontinuierliche Feinabstimmung](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)    | Kontinuierliche Feinabstimmung ist der iterative Prozess, ein bereits feinabgestimmtes Modell als Basismodell auszuwählen und **es weiter** auf neuen Sets von Trainingsbeispielen zu verfeinern.                                                                                                                                                                   |
| [Feinabstimmung und Funktionsaufrufe](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                    | Die Feinabstimmung eures Modells **mit Beispielen für Funktionsaufrufe** kann die Modellausgabe verbessern, indem genauere und konsistentere Ausgaben erzielt werden - mit ähnlich formatierten Antworten und Kosteneinsparungen.                                                                                                                                     |
| [Feinabstimmung von Modellen: Azure OpenAI Anleitung](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                             | Schaut euch diese Tabelle an, um zu verstehen, **welche Modelle in Azure OpenAI feinabgestimmt werden können** und in welchen Regionen diese verfügbar sind. Schaut euch bei Bedarf deren Tokenlimits und Ablaufdaten der Trainingsdaten an.                                                                                                                         |
| [Feinabstimmen oder nicht Feinabstimmen? Das ist die Frage](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                  | Diese 30-minütige **Okt 2023** Episode der AI Show diskutiert Vorteile, Nachteile und praktische Einblicke, die euch bei dieser Entscheidung helfen.                                                                                                                                                                          |
| [Erste Schritte mit LLM-Feinabstimmung](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                 | Diese **AI Playbook**-Ressource führt euch durch Datenanforderungen, Formatierung, Hyperparameter-Feinabstimmung und Herausforderungen/Beschränkungen, die ihr kennen solltet.                                                                                                                                                                                     |
| **Tutorial**: [Azure OpenAI GPT3.5 Turbo Feinabstimmung](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                               | Lernt, wie ihr einen Beispiel-Feinabstimmungsdatensatz erstellt, euch auf die Feinabstimmung vorbereitet, einen Feinabstimmungsjob erstellt und das feinabgestimmte Modell auf Azure bereitstellt.                                                                                                                                                                  |
| **Tutorial**: [Ein Llama 2 Modell in Azure AI Studio feinabstimmen](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                              | Azure AI Studio ermöglicht es euch, große Sprachmodelle auf eure persönlichen Datensätze zuzuschneiden _mithilfe eines UI-basierten Workflows, der für Low-Code-Entwickler geeignet ist_. Seht euch dieses Beispiel an.                                                                                                                                             |
| **Tutorial**: [Hugging Face Modelle für eine einzelne GPU auf Azure feinabstimmen](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)   | Dieser Artikel beschreibt, wie man ein Hugging Face Modell mit der Hugging Face Transformers-Bibliothek auf einer einzelnen GPU mit Azure DataBricks + Hugging Face Trainer Bibliotheken feinabstimmt.                                                                                                                                                              |
| **Training:** [Ein Foundation-Modell mit Azure Machine Learning feinabstimmen](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)          | Der Modellkatalog in Azure Machine Learning bietet viele Open-Source-Modelle, die ihr für eure spezifische Aufgabe feinabstimmen könnt. Probiert dieses Modul aus [aus dem AzureML Generative AI Learning Path](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst).                   |
| **Tutorial:** [Azure OpenAI Feinabstimmung](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                            | Die Feinabstimmung von GPT-3.5 oder GPT-4 Modellen auf Microsoft Azure mit W&B ermöglicht eine detaillierte Nachverfolgung und Analyse der Modellleistung. Dieser Leitfaden erweitert die Konzepte aus dem OpenAI Feinabstimmungsleitfaden mit spezifischen Schritten und Funktionen für Azure OpenAI.                                                              |
|                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                               |

## 2. Sekundäre Ressourcen

Dieser Abschnitt erfasst zusätzliche Ressourcen, die es wert sind, erkundet zu werden, die wir aber in dieser Lektion nicht behandelt haben. Sie könnten in einer zukünftigen Lektion oder als sekundäre Aufgabenoption zu einem späteren Zeitpunkt behandelt werden. Für jetzt könnt ihr sie nutzen, um euer eigenes Fachwissen und Wissen zu diesem Thema aufzubauen.

| Titel/Link                                                                                                                                                                                                             | Beschreibung                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI Cookbook**: [Datenvorbereitung und -analyse für die Feinabstimmung von Chatmodellen](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                        | Dieses Notizbuch dient als Werkzeug zur Vorverarbeitung und Analyse des Chat-Datensatzes, der zur Feinabstimmung eines Chatmodells verwendet wird. Es überprüft Formatfehler, bietet grundlegende Statistiken und schätzt Token-Anzahlen für Feinabstimmungskosten. Siehe: [Feinabstimmungsmethode für gpt-3.5-turbo](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst).                                                                                                                                                                   |
| **OpenAI Cookbook**: [Feinabstimmung für Retrieval Augmented Generation (RAG) mit Qdrant](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst) | Das Ziel dieses Notizbuchs ist es, ein umfassendes Beispiel zu geben, wie OpenAI-Modelle für Retrieval Augmented Generation (RAG) feinabgestimmt werden können. Wir werden auch Qdrant und Few-Shot Learning integrieren, um die Modellleistung zu steigern und Erfindungen zu reduzieren.                                                                                                                                                                                                                                       |
| **OpenAI Cookbook**: [Feinabstimmung von GPT mit Weights & Biases](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                       | Weights & Biases (W&B) ist die AI-Entwicklerplattform mit Werkzeugen zum Trainieren von Modellen, Feinabstimmen von Modellen und Nutzen von Foundation-Modellen. Lest zuerst ihren [OpenAI Feinabstimmungsleitfaden](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst), dann probiert die Cookbook-Übung.                                                                                                                                                                      |
| **Community Tutorial** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - Feinabstimmung für kleine Sprachmodelle                                                 | Lernt [Phi-2](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst) kennen, Microsofts neues kleines Modell, bemerkenswert leistungsfähig und doch kompakt. Dieses Tutorial führt euch durch die Feinabstimmung von Phi-2 und zeigt, wie man einen einzigartigen Datensatz erstellt und das Modell mit QLoRA feinabstimmt.                                                                                                                                                       |
| **Hugging Face Tutorial** [Wie man LLMs im Jahr 2024 mit Hugging Face feinabstimmt](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                       | Dieser Blogbeitrag führt euch durch die Feinabstimmung von offenen LLMs mit Hugging Face TRL, Transformers & Datensätzen im Jahr 2024. Ihr definiert einen Anwendungsfall, richtet eine Entwicklungsumgebung ein, bereitet einen Datensatz vor, stimmt das Modell fein ab, testet-evaluiert es und stellt es dann in der Produktion bereit.                                                                                                                                                                             |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                            | Ermöglicht schnellere und einfachere Trainings und Bereitstellungen von [State-of-the-Art-Maschinenlernmodellen](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst). Das Repo bietet Colab-freundliche Tutorials mit YouTube-Videoanleitungen zur Feinabstimmung. **Reflektiert das aktuelle [local-first](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst) Update**. Lest die [AutoTrain Dokumentation](https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst). |
|                                                                                                                                                                                                                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-Übersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) übersetzt. Obwohl wir uns um Genauigkeit bemühen, beachten Sie bitte, dass automatisierte Übersetzungen Fehler oder Ungenauigkeiten enthalten können. Das Originaldokument in seiner ursprünglichen Sprache sollte als maßgebliche Quelle betrachtet werden. Für kritische Informationen wird eine professionelle menschliche Übersetzung empfohlen. Wir haften nicht für Missverständnisse oder Fehlinterpretationen, die sich aus der Verwendung dieser Übersetzung ergeben.