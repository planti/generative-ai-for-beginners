<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:51:07+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "sr"
}
-->
# Resursi za samostalno učenje

Lekcija je kreirana koristeći brojne osnovne resurse iz OpenAI i Azure OpenAI kao reference za terminologiju i tutorijale. Ovde je nekompletna lista za vaše samostalne puteve učenja.

## 1. Osnovni resursi

| Naslov/Link                                                                                                                                                                                                                   | Opis                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Fine-tuning sa OpenAI modelima](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                       | Fine-tuning poboljšava učenje sa malim brojem primera treniranjem na mnogo više primera nego što može stati u prompt, štedi troškove, poboljšava kvalitet odgovora i omogućava zahteve sa nižom latencijom. **Pogledajte pregled fine-tuning-a od OpenAI.**                                                                                    |
| [Šta je Fine-Tuning sa Azure OpenAI?](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                   | Razumite **šta je fine-tuning (koncept)**, zašto biste trebali da ga razmotrite (motivacioni problem), koje podatke koristiti (trening) i kako meriti kvalitet.                                                                                                                                                                           |
| [Prilagodite model sa fine-tuningom](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst) | Azure OpenAI Service vam omogućava da prilagodite naše modele vašim ličnim datasetima koristeći fine-tuning. Naučite **kako da fine-tune (proces)** izaberete modele koristeći Azure AI Studio, Python SDK ili REST API.                                                                                                                                |
| [Preporuke za fine-tuning LLM-a](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                    | LLM-ovi možda ne rade dobro na specifičnim domenima, zadacima ili datasetima, ili mogu proizvoditi netačne ili obmanjujuće izlaze. **Kada biste trebali razmotriti fine-tuning** kao moguće rešenje za ovo?                                                                                                                                  |
| [Kontinuirani Fine Tuning](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)             | Kontinuirani fine-tuning je iterativni proces odabira već fine-tuned modela kao osnovnog modela i **dalje fine-tuning-a** na novim setovima trening primera.                                                                                                                                                     |
| [Fine-tuning i pozivanje funkcija](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                       | Fine-tuning vašeg modela **sa primerima pozivanja funkcija** može poboljšati izlaz modela dobijanjem tačnijih i konzistentnijih izlaza - sa slično formatiranim odgovorima i uštedom troškova.                                                                                                                                        |
| [Fine-tuning modela: Azure OpenAI smernice](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                                        | Pogledajte ovu tabelu da razumete **koji modeli mogu biti fine-tuned** u Azure OpenAI, i u kojim regionima su dostupni. Pogledajte njihove limite tokena i datume isteka trening podataka ako je potrebno.                                                                                                                            |
| [Da li Fine-Tuning ili ne Fine-Tuning? To je pitanje](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                      | Ova 30-minutna **epizoda iz oktobra 2023** AI Show-a diskutuje o prednostima, nedostacima i praktičnim uvidima koji vam pomažu da donesete ovu odluku.                                                                                                                                                                                        |
| [Početak sa Fine-Tuningom LLM-a](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                             | Ovaj **AI Playbook** resurs vas vodi kroz zahteve za podatke, formatiranje, fine-tuning hiperparametara i izazove/ograničenja koje biste trebali znati.                                                                                                                                                                         |
| **Tutorijal**: [Azure OpenAI GPT3.5 Turbo Fine-Tuning](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                                  | Naučite kako da kreirate uzorak dataset-a za fine-tuning, pripremite se za fine-tuning, kreirate posao fine-tuning-a i implementirate fine-tuned model na Azure.                                                                                                                                                                                    |
| **Tutorijal**: [Fine-tune modela Llama 2 u Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                                      | Azure AI Studio vam omogućava da prilagodite velike jezičke modele vašim ličnim datasetima _koristeći UI-bazirani workflow pogodan za developere sa malo koda_. Pogledajte ovaj primer.                                                                                                                                                               |
| **Tutorijal**:[Fine-tune Hugging Face modela za jedan GPU na Azure](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)               | Ovaj članak opisuje kako da fine-tune Hugging Face model sa Hugging Face transformers bibliotekom na jednom GPU-u sa Azure DataBricks + Hugging Face Trainer bibliotekama.                                                                                                                                                |
| **Trening:** [Fine-tune osnovnog modela sa Azure Machine Learning](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)         | Katalog modela u Azure Machine Learning nudi mnoge open source modele koje možete fine-tune za vaš specifični zadatak. Isprobajte ovaj modul iz [AzureML Generative AI Learning Path](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst) |
| **Tutorijal:** [Azure OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                | Fine-tuning GPT-3.5 ili GPT-4 modela na Microsoft Azure koristeći W&B omogućava detaljno praćenje i analizu performansi modela. Ovaj vodič proširuje koncepte iz OpenAI Fine-Tuning vodiča sa specifičnim koracima i funkcijama za Azure OpenAI.                                                                         |
|                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                               |

## 2. Sekundarni resursi

Ovaj deo obuhvata dodatne resurse koji su vredni istraživanja, ali koje nismo imali vremena da pokrijemo u ovoj lekciji. Mogu biti pokriveni u budućoj lekciji, ili kao opcija za sekundarni zadatak, u kasnijem periodu. Za sada, koristite ih da izgradite sopstvenu ekspertizu i znanje o ovoj temi.

| Naslov/Link                                                                                                                                                                                                            | Opis                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI Cookbook**: [Priprema podataka i analiza za fine-tuning modela za ćaskanje](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                                      | Ovaj notebook služi kao alat za predprocesiranje i analizu dataset-a za ćaskanje koji se koristi za fine-tuning modela za ćaskanje. Proverava greške u formatu, pruža osnovne statistike i procenjuje broj tokena za troškove fine-tuning-a. Pogledajte: [Metoda fine-tuning-a za gpt-3.5-turbo](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst).                                                                                                                                                                   |
| **OpenAI Cookbook**: [Fine-Tuning za generaciju sa poboljšanim preuzimanjem (RAG) sa Qdrant](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst) | Cilj ovog notebook-a je da vas provede kroz sveobuhvatan primer kako da fine-tune OpenAI modele za generaciju sa poboljšanim preuzimanjem (RAG). Takođe ćemo integrisati Qdrant i učenje sa malim brojem primera da poboljšamo performanse modela i smanjimo fabricacije.                                                                                                                                                                                                                                                                |
| **OpenAI Cookbook**: [Fine-tuning GPT sa Weights & Biases](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                             | Weights & Biases (W&B) je AI platforma za developere, sa alatima za treniranje modela, fine-tuning modela i korišćenje osnovnih modela. Prvo pročitajte njihov [OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst) vodič, zatim isprobajte vežbu iz Cookbook-a.                                                                                                                                                                                                                  |
| **Zajednički Tutorijal** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - fine-tuning za male jezičke modele                                                   | Upoznajte [Phi-2](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst), novi mali model kompanije Microsoft, izuzetno moćan ali kompaktan. Ovaj tutorijal će vas voditi kroz fine-tuning Phi-2, demonstrirajući kako da izgradite jedinstveni dataset i fine-tune model koristeći QLoRA.                                                                                                                                                                       |
| **Hugging Face Tutorijal** [Kako Fine-Tune LLM-ove u 2024 sa Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | Ovaj blog post vas vodi kroz kako da fine-tune otvorene LLM-ove koristeći Hugging Face TRL, Transformers & dataset-e u 2024. Definišete slučaj upotrebe, postavljate razvojno okruženje, pripremate dataset, fine-tune model, testirate i evaluirate ga, zatim ga implementirate u produkciju.                                                                                                                                                                                                                                                                |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                            | Donosi brže i lakše treniranje i implementacije [state-of-the-art mašinskih modela](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst). Repo ima Colab-friendly tutorijale sa YouTube video vodičima, za fine-tuning. **Odražava nedavnu [lokalno-prvu](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst) ažuriranje** . Pročitajte [AutoTrain dokumentaciju](https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst) |
|                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |

**Одрицање од одговорности**:  
Овај документ је преведен коришћењем услуге за превођење путем вештачке интелигенције [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да обезбедимо тачност, молимо вас да будете свесни да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати меродавним извором. За критичне информације препоручује се професионални људски превод. Не сносимо одговорност за било каква погрешна разумевања или погрешна тумачења која могу произаћи из коришћења овог превода.