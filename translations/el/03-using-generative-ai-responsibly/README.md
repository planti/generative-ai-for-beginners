<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "13084c6321a2092841b9a081b29497ba",
  "translation_date": "2025-05-19T14:39:48+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "el"
}
-->
# Χρήση της Γενεσιουργής AI με Υπευθυνότητα

> _Κάντε κλικ στην παραπάνω εικόνα για να δείτε το βίντεο αυτού του μαθήματος_

Είναι εύκολο να εντυπωσιαστεί κανείς από την AI και ειδικά τη γενεσιουργή AI, αλλά πρέπει να σκεφτείτε πώς να τη χρησιμοποιήσετε με υπευθυνότητα. Πρέπει να λάβετε υπόψη σας πώς να διασφαλίσετε ότι η έξοδος είναι δίκαιη, μη επιβλαβής και πολλά άλλα. Αυτό το κεφάλαιο στοχεύει να σας παρέχει το πλαίσιο που αναφέρθηκε, τι να λάβετε υπόψη σας και πώς να κάνετε ενεργά βήματα για να βελτιώσετε τη χρήση της AI σας.

## Εισαγωγή

Αυτό το μάθημα θα καλύψει:

- Γιατί πρέπει να δίνετε προτεραιότητα στην Υπεύθυνη AI όταν δημιουργείτε εφαρμογές Γενεσιουργής AI.
- Βασικές αρχές της Υπεύθυνης AI και πώς σχετίζονται με τη Γενεσιουργή AI.
- Πώς να εφαρμόσετε αυτές τις αρχές της Υπεύθυνης AI μέσω στρατηγικής και εργαλείων.

## Στόχοι Μάθησης

Μετά την ολοκλήρωση αυτού του μαθήματος θα γνωρίζετε:

- Τη σημασία της Υπεύθυνης AI όταν δημιουργείτε εφαρμογές Γενεσιουργής AI.
- Πότε να σκέφτεστε και να εφαρμόζετε τις βασικές αρχές της Υπεύθυνης AI όταν δημιουργείτε εφαρμογές Γενεσιουργής AI.
- Ποια εργαλεία και στρατηγικές είναι διαθέσιμα για να εφαρμόσετε την έννοια της Υπεύθυνης AI στην πράξη.

## Αρχές Υπεύθυνης AI

Η ενθουσιασμός για τη Γενεσιουργή AI δεν ήταν ποτέ υψηλότερη. Αυτός ο ενθουσιασμός έχει φέρει πολλούς νέους προγραμματιστές, προσοχή και χρηματοδότηση σε αυτόν τον τομέα. Ενώ αυτό είναι πολύ θετικό για όποιον θέλει να δημιουργήσει προϊόντα και εταιρείες χρησιμοποιώντας τη Γενεσιουργή AI, είναι επίσης σημαντικό να προχωρήσουμε με υπευθυνότητα.

Καθ' όλη τη διάρκεια αυτού του μαθήματος, επικεντρωνόμαστε στη δημιουργία της startup μας και του εκπαιδευτικού προϊόντος AI μας. Θα χρησιμοποιήσουμε τις αρχές της Υπεύθυνης AI: Δικαιοσύνη, Συμπερίληψη, Αξιοπιστία/Ασφάλεια, Ασφάλεια & Ιδιωτικότητα, Διαφάνεια και Λογοδοσία. Με αυτές τις αρχές, θα εξερευνήσουμε πώς σχετίζονται με τη χρήση της Γενεσιουργής AI στα προϊόντα μας.

## Γιατί Πρέπει να Δίνετε Προτεραιότητα στην Υπεύθυνη AI

Όταν δημιουργείτε ένα προϊόν, η προσέγγιση με επίκεντρο τον άνθρωπο, λαμβάνοντας υπόψη το καλύτερο συμφέρον του χρήστη σας, οδηγεί στα καλύτερα αποτελέσματα.

Η μοναδικότητα της Γενεσιουργής AI είναι η δύναμή της να δημιουργεί χρήσιμες απαντήσεις, πληροφορίες, καθοδήγηση και περιεχόμενο για τους χρήστες. Αυτό μπορεί να γίνει χωρίς πολλά χειροκίνητα βήματα, κάτι που μπορεί να οδηγήσει σε πολύ εντυπωσιακά αποτελέσματα. Χωρίς σωστό σχεδιασμό και στρατηγικές, μπορεί επίσης δυστυχώς να οδηγήσει σε ορισμένα επιβλαβή αποτελέσματα για τους χρήστες σας, το προϊόν σας και την κοινωνία στο σύνολό της.

Ας δούμε μερικά (αλλά όχι όλα) από αυτά τα δυνητικά επιβλαβή αποτελέσματα:

### Ψευδαισθήσεις

Οι ψευδαισθήσεις είναι ένας όρος που χρησιμοποιείται για να περιγράψει όταν ένα LLM παράγει περιεχόμενο που είναι είτε εντελώς ασυνάρτητο είτε κάτι που γνωρίζουμε ότι είναι λανθασμένο με βάση άλλες πηγές πληροφοριών.

Ας πάρουμε για παράδειγμα ότι δημιουργούμε μια δυνατότητα για τη startup μας που επιτρέπει στους μαθητές να κάνουν ιστορικές ερωτήσεις σε ένα μοντέλο. Ένας μαθητής ρωτά την ερώτηση `Who was the sole survivor of Titanic?`

Το μοντέλο παράγει μια απάντηση όπως αυτή παρακάτω:

Αυτή είναι μια πολύ σίγουρη και λεπτομερής απάντηση. Δυστυχώς, είναι λανθασμένη. Ακόμη και με μια ελάχιστη έρευνα, κάποιος θα ανακάλυπτε ότι υπήρχαν περισσότεροι από ένας επιζώντες της καταστροφής του Τιτανικού. Για έναν μαθητή που μόλις αρχίζει να ερευνά αυτό το θέμα, αυτή η απάντηση μπορεί να είναι αρκετά πειστική για να μην αμφισβητηθεί και να θεωρηθεί ως γεγονός. Οι συνέπειες αυτού μπορούν να οδηγήσουν στο να είναι το σύστημα AI αναξιόπιστο και να επηρεάσει αρνητικά τη φήμη της startup μας.

Με κάθε επανάληψη οποιουδήποτε δεδομένου LLM, έχουμε δει βελτιώσεις στην απόδοση όσον αφορά τη μείωση των ψευδαισθήσεων. Ακόμα και με αυτή τη βελτίωση, εμείς ως κατασκευαστές εφαρμογών και χρήστες πρέπει να παραμένουμε ενήμεροι για αυτούς τους περιορισμούς.

### Επιβλαβές Περιεχόμενο

Καλύψαμε στην προηγούμενη ενότητα όταν ένα LLM παράγει λανθασμένες ή ασυνάρτητες απαντήσεις. Ένας άλλος κίνδυνος που πρέπει να είμαστε ενήμεροι είναι όταν ένα μοντέλο απαντά με επιβλαβές περιεχόμενο.

Το επιβλαβές περιεχόμενο μπορεί να οριστεί ως:

- Παροχή οδηγιών ή ενθάρρυνση για αυτοτραυματισμό ή βλάβη σε συγκεκριμένες ομάδες.
- Μισαλλόδοξο ή υποτιμητικό περιεχόμενο.
- Καθοδήγηση για σχεδιασμό οποιουδήποτε είδους επίθεσης ή βίαιων πράξεων.
- Παροχή οδηγιών για το πώς να βρει κανείς παράνομο περιεχόμενο ή να διαπράξει παράνομες πράξεις.
- Προβολή σεξουαλικά απεικονιστικού περιεχομένου.

Για τη startup μας, θέλουμε να διασφαλίσουμε ότι έχουμε τα κατάλληλα εργαλεία και στρατηγικές για να αποτρέψουμε την προβολή αυτού του είδους περιεχομένου στους μαθητές.

### Έλλειψη Δικαιοσύνης

Η δικαιοσύνη ορίζεται ως «διασφάλιση ότι ένα σύστημα AI είναι απαλλαγμένο από προκαταλήψεις και διακρίσεις και ότι αντιμετωπίζει όλους δίκαια και ισότιμα». Στον κόσμο της Γενεσιουργής AI, θέλουμε να διασφαλίσουμε ότι οι αποκλειστικές κοσμοθεωρίες των περιθωριοποιημένων ομάδων δεν ενισχύονται από την έξοδο του μοντέλου.

Αυτοί οι τύποι εξόδων δεν είναι μόνο καταστροφικοί για τη δημιουργία θετικών εμπειριών προϊόντων για τους χρήστες μας, αλλά προκαλούν επίσης περαιτέρω κοινωνική βλάβη. Ως κατασκευαστές εφαρμογών, πρέπει πάντα να έχουμε υπόψη μας μια ευρεία και ποικιλόμορφη βάση χρηστών όταν δημιουργούμε λύσεις με Γενεσιουργή AI.

## Πώς να Χρησιμοποιήσετε τη Γενεσιουργή AI με Υπευθυνότητα

Τώρα που έχουμε αναγνωρίσει τη σημασία της Υπεύθυνης Γενεσιουργής AI, ας δούμε 4 βήματα που μπορούμε να κάνουμε για να δημιουργήσουμε τις λύσεις AI μας υπεύθυνα:

### Μετρήστε τις Δυνητικές Βλάβες

Στον έλεγχο λογισμικού, δοκιμάζουμε τις αναμενόμενες ενέργειες ενός χρήστη σε μια εφαρμογή. Παρομοίως, η δοκιμή ενός ποικίλου συνόλου προτροπών που οι χρήστες είναι πιο πιθανό να χρησιμοποιήσουν είναι ένας καλός τρόπος για να μετρήσουμε τη δυνητική βλάβη.

Δεδομένου ότι η startup μας δημιουργεί ένα εκπαιδευτικό προϊόν, θα ήταν καλό να προετοιμάσουμε μια λίστα με προτροπές που σχετίζονται με την εκπαίδευση. Αυτό θα μπορούσε να καλύπτει ένα συγκεκριμένο θέμα, ιστορικά γεγονότα και προτροπές για τη ζωή των μαθητών.

### Μειώστε τις Δυνητικές Βλάβες

Είναι τώρα η στιγμή να βρούμε τρόπους για να αποτρέψουμε ή να περιορίσουμε τη δυνητική βλάβη που προκαλείται από το μοντέλο και τις απαντήσεις του. Μπορούμε να το δούμε σε 4 διαφορετικά επίπεδα:

- **Μοντέλο**. Επιλογή του κατάλληλου μοντέλου για την κατάλληλη χρήση. Μεγαλύτερα και πιο πολύπλοκα μοντέλα όπως το GPT-4 μπορούν να προκαλέσουν μεγαλύτερο κίνδυνο επιβλαβούς περιεχομένου όταν εφαρμόζονται σε μικρότερες και πιο συγκεκριμένες περιπτώσεις χρήσης. Η χρήση των δεδομένων εκπαίδευσής σας για λεπτομερή ρύθμιση μειώνει επίσης τον κίνδυνο επιβλαβούς περιεχομένου.

- **Σύστημα Ασφάλειας**. Ένα σύστημα ασφάλειας είναι ένα σύνολο εργαλείων και ρυθμίσεων στην πλατφόρμα που εξυπηρετεί το μοντέλο που βοηθούν στη μείωση της βλάβης. Ένα παράδειγμα αυτού είναι το σύστημα φιλτραρίσματος περιεχομένου στην υπηρεσία Azure OpenAI. Τα συστήματα θα πρέπει επίσης να ανιχνεύουν επιθέσεις jailbreak και ανεπιθύμητη δραστηριότητα όπως αιτήματα από bots.

- **Μεταπροτροπή**. Οι μεταπροτροπές και η θεμελίωση είναι τρόποι με τους οποίους μπορούμε να κατευθύνουμε ή να περιορίσουμε το μοντέλο με βάση ορισμένες συμπεριφορές και πληροφορίες. Αυτό μπορεί να γίνει χρησιμοποιώντας εισόδους συστήματος για να ορίσουμε ορισμένα όρια του μοντέλου. Επιπλέον, παρέχοντας εξόδους που είναι πιο σχετικές με το πεδίο ή τον τομέα του συστήματος.

Μπορεί επίσης να χρησιμοποιεί τεχνικές όπως η Ανακτητική Δημιουργία (RAG) για να έχει το μοντέλο να αντλεί πληροφορίες μόνο από μια επιλογή αξιόπιστων πηγών. Υπάρχει ένα μάθημα αργότερα σε αυτό το μάθημα για [δημιουργία εφαρμογών αναζήτησης](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Εμπειρία Χρήστη**. Το τελικό επίπεδο είναι εκεί που ο χρήστης αλληλεπιδρά άμεσα με το μοντέλο μέσω της διεπαφής της εφαρμογής μας με κάποιο τρόπο. Με αυτόν τον τρόπο μπορούμε να σχεδιάσουμε το UI/UX για να περιορίσουμε τον χρήστη στους τύπους εισόδων που μπορεί να στείλει στο μοντέλο καθώς και στο κείμενο ή τις εικόνες που εμφανίζονται στον χρήστη. Όταν αναπτύσσουμε την εφαρμογή AI, πρέπει επίσης να είμαστε διαφανείς σχετικά με το τι μπορεί και δεν μπορεί να κάνει η εφαρμογή Γενεσιουργής AI μας.

Έχουμε ένα ολόκληρο μάθημα αφιερωμένο στο [Σχεδιασμό UX για Εφαρμογές AI](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Αξιολόγηση μοντέλου**. Η εργασία με LLMs μπορεί να είναι προκλητική επειδή δεν έχουμε πάντα έλεγχο στα δεδομένα που εκπαιδεύτηκε το μοντέλο. Παρ' όλα αυτά, πρέπει πάντα να αξιολογούμε την απόδοση και τις εξόδους του μοντέλου. Είναι ακόμα σημαντικό να μετράμε την ακρίβεια του μοντέλου, την ομοιότητα, τη θεμελίωση και τη συνάφεια της εξόδου. Αυτό βοηθά στην παροχή διαφάνειας και εμπιστοσύνης στους ενδιαφερόμενους και τους χρήστες.

### Λειτουργήστε μια Υπεύθυνη Γενεσιουργή AI λύση

Η δημιουργία μιας επιχειρησιακής πρακτικής γύρω από τις εφαρμογές AI σας είναι το τελικό στάδιο. Αυτό περιλαμβάνει τη συνεργασία με άλλα μέρη της startup μας, όπως το Νομικό και την Ασφάλεια, για να διασφαλίσουμε ότι συμμορφωνόμαστε με όλες τις κανονιστικές πολιτικές. Πριν από την κυκλοφορία, θέλουμε επίσης να δημιουργήσουμε σχέδια γύρω από την παράδοση, τη διαχείριση περιστατικών και την αναστροφή για να αποτρέψουμε οποιαδήποτε βλάβη στους χρήστες μας από την ανάπτυξη.

## Εργαλεία

Ενώ το έργο της ανάπτυξης Υπεύθυνων λύσεων AI μπορεί να φαίνεται πολύ, είναι έργο που αξίζει τον κόπο. Καθώς η περιοχή της Γενεσιουργής AI μεγαλώνει, περισσότερα εργαλεία για να βοηθήσουν τους προγραμματιστές να ενσωματώσουν υπευθυνότητα στις ροές εργασίας τους θα ωριμάσουν. Για παράδειγμα, το [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) μπορεί να βοηθήσει στην ανίχνευση επιβλαβούς περιεχομένου και εικόνων μέσω ενός αιτήματος API.

## Έλεγχος γνώσεων

Ποια είναι μερικά πράγματα που πρέπει να προσέξετε για να διασφαλίσετε την υπεύθυνη χρήση της AI;

1. Ότι η απάντηση είναι σωστή.
2. Επιβλαβής χρήση, ότι η AI δεν χρησιμοποιείται για εγκληματικούς σκοπούς.
3. Διασφάλιση ότι η AI είναι απαλλαγμένη από προκαταλήψεις και διακρίσεις.

Α: Οι 2 και 3 είναι σωστές. Η Υπεύθυνη AI σας βοηθά να σκεφτείτε πώς να μετριάσετε τις επιβλαβείς επιπτώσεις και τις προκαταλήψεις και πολλά άλλα.

## 🚀 Πρόκληση

Διαβάστε για το [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) και δείτε τι μπορείτε να υιοθετήσετε για τη χρήση σας.

## Συγχαρητήρια, Συνεχίστε τη Μάθησή σας

Μετά την ολοκλήρωση αυτού του μαθήματος, δείτε τη συλλογή μας [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) για να συνεχίσετε να αναβαθμίζετε τις γνώσεις σας στη Γενεσιουργή AI!

Προχωρήστε στο Μάθημα 4 όπου θα εξετάσουμε τα [Θεμελιώδη Στοιχεία Μηχανικής Προτροπών](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Αποποίηση ευθυνών**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που επιδιώκουμε την ακρίβεια, παρακαλώ να γνωρίζετε ότι οι αυτοματοποιημένες μεταφράσεις ενδέχεται να περιέχουν λάθη ή ανακρίβειες. Το πρωτότυπο έγγραφο στη μητρική του γλώσσα θα πρέπει να θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν είμαστε υπεύθυνοι για τυχόν παρεξηγήσεις ή παρερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.