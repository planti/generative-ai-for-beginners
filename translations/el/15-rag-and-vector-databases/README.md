<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2861bbca91c0567ef32bc77fe054f9e",
  "translation_date": "2025-05-20T01:18:40+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "el"
}
-->
# Ανάκτηση Ενισχυμένης Δημιουργίας (RAG) και Βάσεις Δεδομένων Διανυσμάτων

Στο μάθημα για τις εφαρμογές αναζήτησης, μάθαμε σύντομα πώς να ενσωματώνετε τα δικά σας δεδομένα σε Μεγάλα Γλωσσικά Μοντέλα (LLMs). Σε αυτό το μάθημα, θα εξετάσουμε πιο αναλυτικά τις έννοιες της θεμελίωσης των δεδομένων σας στην εφαρμογή LLM σας, τους μηχανισμούς της διαδικασίας και τις μεθόδους αποθήκευσης δεδομένων, συμπεριλαμβανομένων των ενσωματώσεων και του κειμένου.

> **Βίντεο Σύντομα Διαθέσιμο**

## Εισαγωγή

Σε αυτό το μάθημα θα καλύψουμε τα εξής:

- Μια εισαγωγή στο RAG, τι είναι και γιατί χρησιμοποιείται στην τεχνητή νοημοσύνη (AI).

- Κατανόηση τι είναι οι βάσεις δεδομένων διανυσμάτων και δημιουργία μιας για την εφαρμογή μας.

- Ένα πρακτικό παράδειγμα για το πώς να ενσωματώσετε το RAG σε μια εφαρμογή.

## Στόχοι Μάθησης

Αφού ολοκληρώσετε αυτό το μάθημα, θα μπορείτε να:

- Εξηγήσετε τη σημασία του RAG στην ανάκτηση και επεξεργασία δεδομένων.

- Ρυθμίσετε την εφαρμογή RAG και θεμελιώσετε τα δεδομένα σας σε ένα LLM.

- Αποτελεσματική ενσωμάτωση του RAG και των Βάσεων Δεδομένων Διανυσμάτων στις Εφαρμογές LLM.

## Το Σενάριό μας: ενίσχυση των LLM μας με τα δικά μας δεδομένα

Για αυτό το μάθημα, θέλουμε να προσθέσουμε τις δικές μας σημειώσεις στην εκπαιδευτική startup, που επιτρέπει στο chatbot να αποκτά περισσότερες πληροφορίες για τα διάφορα θέματα. Χρησιμοποιώντας τις σημειώσεις που έχουμε, οι μαθητές θα μπορούν να μελετούν καλύτερα και να κατανοούν τα διάφορα θέματα, διευκολύνοντας την αναθεώρηση για τις εξετάσεις τους. Για να δημιουργήσουμε το σενάριό μας, θα χρησιμοποιήσουμε:

- `Azure OpenAI:` το LLM που θα χρησιμοποιήσουμε για να δημιουργήσουμε το chatbot μας

- `AI for beginners' lesson on Neural Networks`: αυτά θα είναι τα δεδομένα στα οποία θα θεμελιώσουμε το LLM μας

- `Azure AI Search` και `Azure Cosmos DB:` βάση δεδομένων διανυσμάτων για να αποθηκεύσουμε τα δεδομένα μας και να δημιουργήσουμε έναν δείκτη αναζήτησης

Οι χρήστες θα μπορούν να δημιουργούν πρακτικά κουίζ από τις σημειώσεις τους, κάρτες αναθεώρησης και να συνοψίζουν σε συνοπτικές επισκοπήσεις. Για να ξεκινήσουμε, ας δούμε τι είναι το RAG και πώς λειτουργεί:

## Ανάκτηση Ενισχυμένης Δημιουργίας (RAG)

Ένα chatbot που τροφοδοτείται από LLM επεξεργάζεται τις προτροπές του χρήστη για να δημιουργήσει απαντήσεις. Σχεδιάζεται για να είναι διαδραστικό και να ασχολείται με τους χρήστες σε ένα ευρύ φάσμα θεμάτων. Ωστόσο, οι απαντήσεις του περιορίζονται στο πλαίσιο που παρέχεται και στα βασικά δεδομένα εκπαίδευσής του. Για παράδειγμα, το όριο γνώσης του GPT-4 είναι τον Σεπτέμβριο του 2021, πράγμα που σημαίνει ότι δεν έχει γνώση γεγονότων που έχουν συμβεί μετά από αυτήν την περίοδο. Επιπλέον, τα δεδομένα που χρησιμοποιούνται για την εκπαίδευση των LLM εξαιρούν εμπιστευτικές πληροφορίες, όπως προσωπικές σημειώσεις ή ένα εγχειρίδιο προϊόντος μιας εταιρείας.

### Πώς λειτουργούν τα RAGs (Ανάκτηση Ενισχυμένης Δημιουργίας)

Ας υποθέσουμε ότι θέλετε να αναπτύξετε ένα chatbot που δημιουργεί κουίζ από τις σημειώσεις σας, θα χρειαστείτε μια σύνδεση με τη βάση γνώσεων. Εδώ έρχεται το RAG να σώσει την κατάσταση. Τα RAGs λειτουργούν ως εξής:

- **Βάση γνώσεων:** Πριν από την ανάκτηση, αυτά τα έγγραφα πρέπει να εισαχθούν και να προεπεξεργαστούν, συνήθως διασπώντας μεγάλα έγγραφα σε μικρότερα κομμάτια, μετατρέποντάς τα σε ενσωμάτωση κειμένου και αποθηκεύοντάς τα σε μια βάση δεδομένων.

- **Ερώτηση χρήστη:** ο χρήστης κάνει μια ερώτηση

- **Ανάκτηση:** Όταν ο χρήστης κάνει μια ερώτηση, το μοντέλο ενσωμάτωσης ανακτά σχετικές πληροφορίες από τη βάση γνώσεών μας για να παρέχει περισσότερο πλαίσιο που θα ενσωματωθεί στην προτροπή.

- **Ενισχυμένη Δημιουργία:** το LLM ενισχύει την απάντησή του με βάση τα δεδομένα που ανακτήθηκαν. Επιτρέπει η απάντηση που δημιουργείται να βασίζεται όχι μόνο στα δεδομένα εκπαίδευσης αλλά και σε σχετικές πληροφορίες από το προστιθέμενο πλαίσιο. Τα ανακτημένα δεδομένα χρησιμοποιούνται για να ενισχύσουν τις απαντήσεις του LLM. Το LLM επιστρέφει στη συνέχεια μια απάντηση στην ερώτηση του χρήστη.

Η αρχιτεκτονική για τα RAGs υλοποιείται χρησιμοποιώντας μετασχηματιστές που αποτελούνται από δύο μέρη: έναν κωδικοποιητή και έναν αποκωδικοποιητή. Για παράδειγμα, όταν ένας χρήστης κάνει μια ερώτηση, το κείμενο εισόδου 'κωδικοποιείται' σε διανύσματα που αποτυπώνουν τη σημασία των λέξεων και τα διανύσματα 'αποκωδικοποιούνται' στον δείκτη εγγράφων μας και δημιουργούν νέο κείμενο με βάση την ερώτηση του χρήστη. Το LLM χρησιμοποιεί τόσο ένα μοντέλο κωδικοποιητή-αποκωδικοποιητή για να δημιουργήσει την έξοδο.

Δύο προσεγγίσεις κατά την υλοποίηση του RAG σύμφωνα με την προτεινόμενη εργασία: [Ανάκτηση-Ενισχυμένη Δημιουργία για Εργασίες NLP (λογισμικό φυσικής γλώσσας)](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) είναι:

- **_RAG-Sequence_** χρησιμοποιώντας ανακτημένα έγγραφα για να προβλέψει την καλύτερη δυνατή απάντηση σε μια ερώτηση χρήστη

- **RAG-Token** χρησιμοποιώντας έγγραφα για να δημιουργήσει το επόμενο token και στη συνέχεια να τα ανακτήσει για να απαντήσει στην ερώτηση του χρήστη

### Γιατί να χρησιμοποιήσετε τα RAGs; 

- **Πλούτος πληροφοριών:** εξασφαλίζει ότι οι απαντήσεις κειμένου είναι ενημερωμένες και τρέχουσες. Επομένως, βελτιώνει την απόδοση σε εργασίες συγκεκριμένου τομέα με την πρόσβαση στη εσωτερική βάση γνώσεων.

- Μειώνει την παραποίηση χρησιμοποιώντας **επαληθεύσιμα δεδομένα** στη βάση γνώσεων για να παρέχει πλαίσιο στις ερωτήσεις των χρηστών.

- Είναι **οικονομικά αποδοτικό** καθώς είναι πιο οικονομικό σε σύγκριση με την προσαρμογή ενός LLM

## Δημιουργία μιας βάσης γνώσεων

Η εφαρμογή μας βασίζεται στα προσωπικά μας δεδομένα, δηλαδή, το μάθημα για το Νευρωνικό Δίκτυο στο πρόγραμμα σπουδών AI Για Αρχάριους.

### Βάσεις Δεδομένων Διανυσμάτων

Μια βάση δεδομένων διανυσμάτων, σε αντίθεση με τις παραδοσιακές βάσεις δεδομένων, είναι μια εξειδικευμένη βάση δεδομένων σχεδιασμένη να αποθηκεύει, να διαχειρίζεται και να αναζητά ενσωματωμένα διανύσματα. Αποθηκεύει αριθμητικές αναπαραστάσεις εγγράφων. Η διάσπαση των δεδομένων σε αριθμητικές ενσωματώσεις διευκολύνει το σύστημα AI μας να κατανοήσει και να επεξεργαστεί τα δεδομένα.

Αποθηκεύουμε τις ενσωματώσεις μας σε βάσεις δεδομένων διανυσμάτων καθώς τα LLM έχουν όριο στον αριθμό των tokens που δέχονται ως είσοδο. Καθώς δεν μπορείτε να περάσετε ολόκληρες τις ενσωματώσεις σε ένα LLM, θα χρειαστεί να τις διασπάσετε σε κομμάτια και όταν ένας χρήστης κάνει μια ερώτηση, οι ενσωματώσεις που είναι πιο κοντά στην ερώτηση θα επιστραφούν μαζί με την προτροπή. Η διάσπαση επίσης μειώνει το κόστος στον αριθμό των tokens που περνούν μέσω ενός LLM.

Μερικές δημοφιλείς βάσεις δεδομένων διανυσμάτων περιλαμβάνουν το Azure Cosmos DB, το Clarifyai, το Pinecone, το Chromadb, το ScaNN, το Qdrant και το DeepLake. Μπορείτε να δημιουργήσετε ένα μοντέλο Azure Cosmos DB χρησιμοποιώντας το Azure CLI με την ακόλουθη εντολή:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Από κείμενο σε ενσωματώσεις

Πριν αποθηκεύσουμε τα δεδομένα μας, θα χρειαστεί να τα μετατρέψουμε σε ενσωματώσεις διανυσμάτων πριν αποθηκευτούν στη βάση δεδομένων. Εάν εργάζεστε με μεγάλα έγγραφα ή μακροσκελή κείμενα, μπορείτε να τα διασπάσετε με βάση τις ερωτήσεις που αναμένετε. Η διάσπαση μπορεί να γίνει σε επίπεδο πρότασης ή σε επίπεδο παραγράφου. Καθώς η διάσπαση εξάγει σημασίες από τις λέξεις γύρω τους, μπορείτε να προσθέσετε κάποιο άλλο πλαίσιο σε ένα κομμάτι, για παράδειγμα, προσθέτοντας τον τίτλο του εγγράφου ή συμπεριλαμβάνοντας κάποιο κείμενο πριν ή μετά το κομμάτι. Μπορείτε να διασπάσετε τα δεδομένα ως εξής:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

Αφού διασπαστούν, μπορούμε στη συνέχεια να ενσωματώσουμε το κείμενό μας χρησιμοποιώντας διαφορετικά μοντέλα ενσωμάτωσης. Μερικά μοντέλα που μπορείτε να χρησιμοποιήσετε περιλαμβάνουν: word2vec, ada-002 από την OpenAI, Azure Computer Vision και πολλά άλλα. Η επιλογή ενός μοντέλου για χρήση θα εξαρτηθεί από τις γλώσσες που χρησιμοποιείτε, τον τύπο του περιεχομένου που κωδικοποιείται (κείμενο/εικόνες/ήχος), το μέγεθος της εισόδου που μπορεί να κωδικοποιήσει και το μήκος της εξόδου ενσωμάτωσης.

Ένα παράδειγμα ενσωματωμένου κειμένου χρησιμοποιώντας το μοντέλο `text-embedding-ada-002` της OpenAI είναι:
![μια ενσωμάτωση της λέξης γάτα](../../../translated_images/cat.3db013cbca4fd5d90438ea7b312ad0364f7686cf79931ab15cd5922151aea53e.el.png)

## Ανάκτηση και Αναζήτηση Διανυσμάτων

Όταν ένας χρήστης κάνει μια ερώτηση, ο ανακτών το μετατρέπει σε ένα διάνυσμα χρησιμοποιώντας τον κωδικοποιητή ερωτήσεων, στη συνέχεια αναζητά στον δείκτη αναζήτησης εγγράφων μας για σχετικά διανύσματα στο έγγραφο που σχετίζονται με την είσοδο. Μόλις ολοκληρωθεί, μετατρέπει τόσο το διάνυσμα εισόδου όσο και τα διανύσματα εγγράφων σε κείμενο και το περνά μέσω του LLM.

### Ανάκτηση

Η ανάκτηση συμβαίνει όταν το σύστημα προσπαθεί να βρει γρήγορα τα έγγραφα από τον δείκτη που ικανοποιούν τα κριτήρια αναζήτησης. Ο στόχος του ανακτών είναι να αποκτήσει έγγραφα που θα χρησιμοποιηθούν για να παρέχουν πλαίσιο και να θεμελιώσουν το LLM στα δεδομένα σας.

Υπάρχουν διάφοροι τρόποι για να πραγματοποιήσετε αναζήτηση μέσα στη βάση δεδομένων μας, όπως:

- **Αναζήτηση με λέξεις-κλειδιά** - χρησιμοποιείται για αναζητήσεις κειμένου

- **Σημασιολογική αναζήτηση** - χρησιμοποιεί τη σημασιολογική σημασία των λέξεων

- **Αναζήτηση διανυσμάτων** - μετατρέπει έγγραφα από κείμενο σε αναπαραστάσεις διανυσμάτων χρησιμοποιώντας μοντέλα ενσωμάτωσης. Η ανάκτηση θα γίνει με την αναζήτηση των εγγράφων των οποίων οι αναπαραστάσεις διανυσμάτων είναι πιο κοντά στην ερώτηση του χρήστη.

- **Υβριδική** - ένας συνδυασμός τόσο αναζήτησης με λέξεις-κλειδιά όσο και αναζήτησης διανυσμάτων.

Μια πρόκληση με την ανάκτηση προκύπτει όταν δεν υπάρχει παρόμοια απάντηση στην ερώτηση στη βάση δεδομένων, το σύστημα θα επιστρέψει την καλύτερη πληροφορία που μπορεί να βρει, ωστόσο, μπορείτε να χρησιμοποιήσετε τακτικές όπως να ορίσετε τη μέγιστη απόσταση για τη συνάφεια ή να χρησιμοποιήσετε υβριδική αναζήτηση που συνδυάζει τόσο τις λέξεις-κλειδιά όσο και την αναζήτηση διανυσμάτων. Σε αυτό το μάθημα θα χρησιμοποιήσουμε υβριδική αναζήτηση, έναν συνδυασμό τόσο αναζήτησης διανυσμάτων όσο και λέξεων-κλειδιών. Θα αποθηκεύσουμε τα δεδομένα μας σε ένα πλαίσιο δεδομένων με στήλες που περιέχουν τα κομμάτια καθώς και τις ενσωματώσεις.

### Ομοιότητα Διανυσμάτων

Ο ανακτών θα αναζητήσει στη βάση γνώσεων για ενσωματώσεις που είναι κοντά μεταξύ τους, οι πιο κοντινοί γείτονες, καθώς είναι κείμενα που είναι παρόμοια. Στο σενάριο που ένας χρήστης κάνει μια ερώτηση, πρώτα ενσωματώνεται και στη συνέχεια αντιστοιχείται με παρόμοιες ενσωματώσεις. Η κοινή μέτρηση που χρησιμοποιείται για να βρεθεί πόσο παρόμοια είναι διαφορετικά διανύσματα είναι η συνημιτονική ομοιότητα που βασίζεται στη γωνία μεταξύ δύο διανυσμάτων.

Μπορούμε να μετρήσουμε την ομοιότητα χρησιμοποιώντας άλλες εναλλακτικές που μπορούμε να χρησιμοποιήσουμε είναι η Ευκλείδεια απόσταση που είναι η ευθεία γραμμή μεταξύ των άκρων των διανυσμάτων και το γινόμενο σημείων που μετρά το άθροισμα των γινομένων των αντίστοιχων στοιχείων δύο διανυσμάτων.

### Δείκτης Αναζήτησης

Όταν κάνουμε ανάκτηση, θα χρειαστεί να δημιουργήσουμε έναν δείκτη αναζήτησης για τη βάση γνώσεών μας πριν πραγματοποιήσουμε αναζήτηση. Ένας δείκτης θα αποθηκεύσει τις ενσωματώσεις μας και μπορεί να ανακτήσει γρήγορα τα πιο παρόμοια κομμάτια ακόμα και σε μια μεγάλη βάση δεδομένων. Μπορούμε να δημιουργήσουμε τον δείκτη μας τοπικά χρησιμοποιώντας:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### Επανεκτίμηση

Αφού έχετε ερωτήσει τη βάση δεδομένων, μπορεί να χρειαστεί να ταξινομήσετε τα αποτελέσματα από τα πιο σχετικά. Ένα LLM επανεκτίμησης χρησιμοποιεί Μηχανική Μάθηση για να βελτιώσει τη συνάφεια των αποτελεσμάτων αναζήτησης ταξινομώντας τα από τα πιο σχετικά. Χρησιμοποιώντας το Azure AI Search, η επανεκτίμηση γίνεται αυτόματα για εσάς χρησιμοποιώντας έναν σημασιολογικό επανεκτιμητή. Ένα παράδειγμα για το πώς λειτουργεί η επανεκτίμηση χρησιμοποιώντας τους πιο κοντινούς γείτονες:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## Φέρνοντας τα όλα μαζί

Το τελευταίο βήμα είναι η προσθήκη του LLM μας στο μείγμα για να μπορέσουμε να πάρουμε απαντήσεις που είναι θεμελιωμένες στα δεδομένα μας. Μπορούμε να το υλοποιήσουμε ως εξής:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## Αξιολόγηση της εφαρμογής μας

### Μετρικές Αξιολόγησης

- Ποιότητα των απαντήσεων που παρέχονται, εξασφαλίζοντας ότι ακούγεται φυσική, ρέουσα και ανθρώπινη

- Θεμελίωση των δεδομένων: αξιολόγηση αν η απάντηση προήλθε από τα παρεχόμενα έγγραφα

- Συνάφεια: αξιολόγηση αν η απάντηση ταιριάζει και σχετίζεται με την ερώτηση που τέθηκε

- Ρευστότητα - αν η απάντηση έχει νόημα γραμματικά

## Περιπτώσεις Χρήσης για τη χρήση του RAG (Ανάκτηση Ενισχυμένης Δημιουργίας) και των βάσεων δεδομένων διανυσμάτων

Υπάρχουν πολλές διαφορετικές περιπτώσεις χρήσης όπου οι κλή

**Αποποίηση ευθύνης**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Ενώ επιδιώκουμε την ακρίβεια, παρακαλούμε να γνωρίζετε ότι οι αυτοματοποιημένες μεταφράσεις μπορεί να περιέχουν σφάλματα ή ανακρίβειες. Το πρωτότυπο έγγραφο στη γλώσσα του θα πρέπει να θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή παρανοήσεις που προκύπτουν από τη χρήση αυτής της μετάφρασης.