<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:40:10+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "el"
}
-->
# Πόροι για Αυτοκαθοδηγούμενη Μάθηση

Το μάθημα δημιουργήθηκε χρησιμοποιώντας έναν αριθμό βασικών πόρων από την OpenAI και την Azure OpenAI ως αναφορές για την ορολογία και τα σεμινάρια. Εδώ είναι μια μη εξαντλητική λίστα για τις δικές σας αυτοκαθοδηγούμενες μαθησιακές διαδρομές.

## 1. Κύριοι Πόροι

| Τίτλος/Σύνδεσμος                                                                                                                                                                                                                   | Περιγραφή                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Fine-tuning with OpenAI Models](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                       | Το fine-tuning βελτιώνει τη μάθηση με λίγα παραδείγματα εκπαιδεύοντας σε πολύ περισσότερα παραδείγματα από όσα μπορούν να χωρέσουν στο prompt, μειώνοντας το κόστος, βελτιώνοντας την ποιότητα της απόκρισης και επιτρέποντας αιτήματα χαμηλότερης καθυστέρησης. **Αποκτήστε μια επισκόπηση του fine-tuning από την OpenAI.**                                                                                    |
| [What is Fine-Tuning with Azure OpenAI?](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                   | Κατανοήστε **τι είναι το fine-tuning (έννοια)**, γιατί πρέπει να το εξετάσετε (κινητροδότηση προβλήματος), ποια δεδομένα να χρησιμοποιήσετε (εκπαίδευση) και πώς να μετρήσετε την ποιότητα                                                                                                                                                                           |
| [Customize a model with fine-tuning](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst) | Η υπηρεσία Azure OpenAI σας επιτρέπει να προσαρμόσετε τα μοντέλα μας στα προσωπικά σας δεδομένα χρησιμοποιώντας fine-tuning. Μάθετε **πώς να κάνετε fine-tuning (διαδικασία)** επιλέγοντας μοντέλα χρησιμοποιώντας το Azure AI Studio, το Python SDK ή το REST API.                                                                                                                                |
| [Recommendations for LLM fine-tuning](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                    | Τα LLMs μπορεί να μην αποδίδουν καλά σε συγκεκριμένους τομείς, εργασίες ή σύνολα δεδομένων, ή μπορεί να παράγουν ανακριβείς ή παραπλανητικές εξόδους. **Πότε πρέπει να εξετάσετε το fine-tuning** ως πιθανή λύση σε αυτό;                                                                                                                                  |
| [Continuous Fine Tuning](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)             | Το συνεχές fine-tuning είναι η επαναληπτική διαδικασία επιλογής ενός ήδη fine-tuned μοντέλου ως βασικού μοντέλου και **περαιτέρω fine-tuning** του σε νέα σύνολα παραδειγμάτων εκπαίδευσης.                                                                                                                                                     |
| [Fine-tuning and function calling](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                       | Το fine-tuning του μοντέλου σας **με παραδείγματα κλήσης λειτουργιών** μπορεί να βελτιώσει την έξοδο του μοντέλου παρέχοντας πιο ακριβείς και συνεπείς εξόδους - με ομοιόμορφα μορφοποιημένες απαντήσεις και εξοικονόμηση κόστους                                                                                                                                        |
| [Fine-tuning Models: Azure OpenAI Guidance](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                                        | Ανατρέξτε σε αυτόν τον πίνακα για να κατανοήσετε **ποια μοντέλα μπορούν να υποβληθούν σε fine-tuning** στην Azure OpenAI, και σε ποιες περιοχές είναι διαθέσιμα. Ελέγξτε τα όρια token τους και τις ημερομηνίες λήξης των δεδομένων εκπαίδευσης, εάν χρειάζεται.                                                                                                                            |
| [To Fine Tune or Not To Fine Tune? That is the Question](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                      | Αυτό το 30λεπτο **επεισόδιο του Οκτωβρίου 2023** του AI Show συζητά τα οφέλη, τα μειονεκτήματα και πρακτικές πληροφορίες που σας βοηθούν να λάβετε αυτήν την απόφαση.                                                                                                                                                                                        |
| [Getting Started With LLM Fine-Tuning](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                             | Αυτός ο πόρος **AI Playbook** σας καθοδηγεί στις απαιτήσεις δεδομένων, τη μορφοποίηση, το fine-tuning υπερπαραμέτρων και τις προκλήσεις/περιορισμούς που πρέπει να γνωρίζετε.                                                                                                                                                                         |
| **Tutorial**: [Azure OpenAI GPT3.5 Turbo Fine-Tuning](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                                  | Μάθετε να δημιουργείτε ένα δείγμα συνόλου δεδομένων για fine-tuning, να προετοιμάζεστε για fine-tuning, να δημιουργείτε μια εργασία fine-tuning και να αναπτύσσετε το fine-tuned μοντέλο στο Azure.                                                                                                                                                                                    |
| **Tutorial**: [Fine-tune a Llama 2 model in Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                                      | Το Azure AI Studio σας επιτρέπει να προσαρμόσετε μεγάλα γλωσσικά μοντέλα στα προσωπικά σας δεδομένα _χρησιμοποιώντας μια διαδικασία με βάση το UI κατάλληλη για προγραμματιστές χαμηλού κώδικα_. Δείτε αυτό το παράδειγμα.                                                                                                                                                               |
| **Tutorial**:[Fine-tune Hugging Face models for a single GPU on Azure](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)               | Αυτό το άρθρο περιγράφει πώς να κάνετε fine-tuning ενός μοντέλου Hugging Face με τη βιβλιοθήκη μετασχηματιστών Hugging Face σε μία GPU με Azure DataBricks + Hugging Face Trainer βιβλιοθήκες                                                                                                                                                |
| **Training:** [Fine-tune a foundation model with Azure Machine Learning](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)         | Ο κατάλογος μοντέλων στο Azure Machine Learning προσφέρει πολλά ανοιχτά μοντέλα που μπορείτε να προσαρμόσετε για την συγκεκριμένη εργασία σας. Δοκιμάστε αυτήν τη μονάδα [από το AzureML Generative AI Learning Path](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst) |
| **Tutorial:** [Azure OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                | Το fine-tuning μοντέλων GPT-3.5 ή GPT-4 στο Microsoft Azure χρησιμοποιώντας το W&B επιτρέπει λεπτομερή παρακολούθηση και ανάλυση της απόδοσης του μοντέλου. Αυτός ο οδηγός επεκτείνει τις έννοιες από τον οδηγό Fine-Tuning της OpenAI με συγκεκριμένα βήματα και δυνατότητες για το Azure OpenAI.                                                                         |
|                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                               |

## 2. Δευτερεύοντες Πόροι

Αυτή η ενότητα περιλαμβάνει επιπλέον πόρους που αξίζει να εξερευνήσετε, αλλά που δεν είχαμε χρόνο να καλύψουμε σε αυτό το μάθημα. Μπορεί να καλυφθούν σε ένα μελλοντικό μάθημα ή ως δευτερεύουσα επιλογή ανάθεσης, σε μεταγενέστερη ημερομηνία. Προς το παρόν, χρησιμοποιήστε τους για να χτίσετε τη δική σας εξειδίκευση και γνώση γύρω από αυτό το θέμα.

| Τίτλος/Σύνδεσμος                                                                                                                                                                                                            | Περιγραφή                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI Cookbook**: [Data preparation and analysis for chat model fine-tuning](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                                      | Αυτό το σημειωματάριο χρησιμεύει ως εργαλείο για την προεπεξεργασία και ανάλυση του συνόλου δεδομένων συνομιλίας που χρησιμοποιείται για το fine-tuning ενός μοντέλου συνομιλίας. Ελέγχει για σφάλματα μορφής, παρέχει βασικά στατιστικά στοιχεία και εκτιμά τις μετρήσεις token για το κόστος fine-tuning. Δείτε: [Fine-tuning method for gpt-3.5-turbo](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst).                                                                                                                                                                   |
| **OpenAI Cookbook**: [Fine-Tuning for Retrieval Augmented Generation (RAG) with Qdrant](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst) | Στόχος αυτού του σημειωματάριου είναι να σας καθοδηγήσει σε ένα ολοκληρωμένο παράδειγμα για το πώς να κάνετε fine-tuning μοντέλων OpenAI για την Ανακτητική Ενισχυμένη Γενιά (RAG). Θα ενσωματώσουμε επίσης το Qdrant και τη μάθηση με λίγα παραδείγματα για να βελτιώσουμε την απόδοση του μοντέλου και να μειώσουμε τις κατασκευές.                                                                                                                                                                                                                                                                |
| **OpenAI Cookbook**: [Fine-tuning GPT with Weights & Biases](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                             | Το Weights & Biases (W&B) είναι η πλατφόρμα ανάπτυξης AI, με εργαλεία για την εκπαίδευση μοντέλων, το fine-tuning μοντέλων και την αξιοποίηση μοντέλων βάσης. Διαβάστε τον [OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst) οδηγό τους πρώτα, και μετά δοκιμάστε την άσκηση στο Cookbook.                                                                                                                                                                                                                  |
| **Community Tutorial** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - fine-tuning for Small Language Models                                                   | Γνωρίστε το [Phi-2](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst), το νέο μικρό μοντέλο της Microsoft, εξαιρετικά ισχυρό και ταυτόχρονα συμπαγές. Αυτό το σεμινάριο θα σας καθοδηγήσει στο fine-tuning του Phi-2, δείχνοντας πώς να δημιουργήσετε ένα μοναδικό σύνολο δεδομένων και να κάνετε fine-tuning του μοντέλου χρησιμοποιώντας το QLoRA.                                                                                                                                                                       |
| **Hugging Face Tutorial** [How to Fine-Tune LLMs in 2024 with Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | Αυτή η ανάρτηση στο blog σας καθοδηγεί στο πώς να κάνετε fine-tuning ανοιχτών LLMs χρησιμοποιώντας το Hugging Face TRL, τους Transformers και τα σύνολα δεδομένων το 2024. Ορίζετε μια περίπτωση χρήσης, ρυθμίζετε ένα περιβάλλον ανάπτυξης, προετοιμάζετε ένα σύνολο δεδομένων, κάνετε fine-tuning του μοντέλου, το δοκιμάζετε-αξιολογείτε και μετά το αναπτύσσετε στην παραγωγή.                                                                                                                                                                                                                                                                |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                            | Προσφέρει πιο γρήγορη και εύκολη εκπαίδευση και ανάπτυξη [μοντέλων μηχανικής μάθησης τελευταίας τεχνολογίας](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst). Το αποθετήριο έχει σεμινάρια φιλικά προς το Colab με καθοδήγηση βίντεο στο YouTube, για το fine-tuning. **Αντανακλά την πρόσφατη [τοπική-πρώτη](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst) ενημέρωση**. Διαβάστε την [τεκμηρίωση AutoTrain](https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst) |
|                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |

**Αποποίηση ευθύνης**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Ενώ προσπαθούμε για ακρίβεια, παρακαλούμε να γνωρίζετε ότι οι αυτοματοποιημένες μεταφράσεις ενδέχεται να περιέχουν λάθη ή ανακρίβειες. Το αρχικό έγγραφο στη μητρική του γλώσσα θα πρέπει να θεωρείται η έγκυρη πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή παρερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.