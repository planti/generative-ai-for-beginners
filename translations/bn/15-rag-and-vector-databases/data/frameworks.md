<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5466bcedc3c75aa35476270362f626a",
  "translation_date": "2025-05-20T01:54:01+00:00",
  "source_file": "15-rag-and-vector-databases/data/frameworks.md",
  "language_code": "bn"
}
-->
# নিউরাল নেটওয়ার্ক ফ্রেমওয়ার্কস

আমরা ইতিমধ্যেই শিখেছি যে নিউরাল নেটওয়ার্কগুলি দক্ষভাবে প্রশিক্ষণ করতে দুটি কাজ করতে হয়:

* টেনসরগুলিতে অপারেট করা, যেমন গুন করা, যোগ করা এবং কিছু ফাংশন যেমন সিগময়েড বা সফটম্যাক্স গণনা করা
* সমস্ত প্রকাশের গ্রেডিয়েন্ট গণনা করা, গ্রেডিয়েন্ট ডিসেন্ট অপ্টিমাইজেশন করার জন্য

যদিও `numpy` লাইব্রেরি প্রথম অংশটি করতে পারে, আমাদের কিছু মেকানিজম দরকার গ্রেডিয়েন্ট গণনা করার জন্য। আমাদের ফ্রেমওয়ার্কে যা আমরা আগের অংশে তৈরি করেছি, `backward` পদ্ধতির মধ্যে সমস্ত ডেরিভেটিভ ফাংশন ম্যানুয়ালি প্রোগ্রাম করতে হয়েছিল, যা ব্যাকপ্রোপাগেশন করে। আদর্শভাবে, একটি ফ্রেমওয়ার্ক আমাদের সুযোগ দেবে *কোনো প্রকাশের* গ্রেডিয়েন্ট গণনা করার যা আমরা সংজ্ঞায়িত করতে পারি।

আরেকটি গুরুত্বপূর্ণ বিষয় হলো GPU বা অন্য কোনো বিশেষায়িত কম্পিউট ইউনিট, যেমন TPU-তে গণনা করতে সক্ষম হওয়া। গভীর নিউরাল নেটওয়ার্ক প্রশিক্ষণ *অনেক* গণনা প্রয়োজন, এবং GPU-তে সেগুলি প্যারালালাইজ করতে সক্ষম হওয়া খুবই গুরুত্বপূর্ণ।

> ✅ 'প্যারালালাইজ' শব্দটির অর্থ হলো গণনাগুলি একাধিক ডিভাইসে বিতরণ করা।

বর্তমানে, দুটি সবচেয়ে জনপ্রিয় নিউরাল ফ্রেমওয়ার্ক হলো: TensorFlow এবং PyTorch। উভয়ই CPU এবং GPU-তে টেনসর দিয়ে অপারেট করার জন্য একটি নিম্ন-স্তরের API প্রদান করে। নিম্ন-স্তরের API-এর উপরে, একটি উচ্চ-স্তরের API রয়েছে, যথাক্রমে Keras এবং PyTorch Lightning নামে।

নিম্ন-স্তরের API | TensorFlow| PyTorch
--------------|-------------------------------------|--------------------------------
উচ্চ-স্তরের API| Keras| Pytorch

**নিম্ন-স্তরের API** উভয় ফ্রেমওয়ার্কে আপনাকে তথাকথিত **গণনা গ্রাফ** তৈরি করতে দেয়। এই গ্রাফটি সংজ্ঞায়িত করে কিভাবে প্রদত্ত ইনপুট প্যারামিটার দিয়ে আউটপুট (সাধারণত ক্ষতি ফাংশন) গণনা করতে হয়, এবং GPU-তে গণনার জন্য পাঠানো যেতে পারে, যদি এটি উপলব্ধ থাকে। এই গণনা গ্রাফটি পার্থক্য করার জন্য এবং গ্রেডিয়েন্ট গণনা করার জন্য ফাংশন রয়েছে, যা তারপর মডেল প্যারামিটার অপ্টিমাইজ করার জন্য ব্যবহার করা যেতে পারে।

**উচ্চ-স্তরের API** মূলত নিউরাল নেটওয়ার্কগুলিকে **স্তরের একটি ক্রম** হিসাবে বিবেচনা করে, এবং বেশিরভাগ নিউরাল নেটওয়ার্ক তৈরি করা অনেক সহজ করে তোলে। মডেল প্রশিক্ষণ সাধারণত ডেটা প্রস্তুত করার প্রয়োজন হয় এবং তারপর `fit` ফাংশন কল করে কাজটি সম্পন্ন করা হয়।

উচ্চ-স্তরের API আপনাকে সাধারণ নিউরাল নেটওয়ার্কগুলি খুব দ্রুত তৈরি করতে দেয় অনেক বিস্তারিত বিষয়ে চিন্তা না করেই। একই সময়ে, নিম্ন-স্তরের API প্রশিক্ষণ প্রক্রিয়ার উপর অনেক বেশি নিয়ন্ত্রণ প্রদান করে, এবং তাই গবেষণায় প্রচুর ব্যবহার করা হয়, যখন আপনি নতুন নিউরাল নেটওয়ার্ক আর্কিটেকচারের সাথে কাজ করছেন।

এটি বোঝা গুরুত্বপূর্ণ যে আপনি উভয় API একসাথে ব্যবহার করতে পারেন, যেমন আপনি নিম্ন-স্তরের API ব্যবহার করে আপনার নিজস্ব নেটওয়ার্ক স্তর আর্কিটেকচার তৈরি করতে পারেন এবং তারপর এটি উচ্চ-স্তরের API দিয়ে নির্মিত এবং প্রশিক্ষিত বড় নেটওয়ার্কের মধ্যে ব্যবহার করতে পারেন। অথবা আপনি উচ্চ-স্তরের API ব্যবহার করে স্তরের একটি ক্রম হিসাবে একটি নেটওয়ার্ক সংজ্ঞায়িত করতে পারেন এবং তারপর আপনার নিজস্ব নিম্ন-স্তরের প্রশিক্ষণ লুপ ব্যবহার করে অপ্টিমাইজেশন সম্পন্ন করতে পারেন। উভয় API একই মৌলিক ধারণা ব্যবহার করে এবং তারা একসাথে ভাল কাজ করার জন্য ডিজাইন করা হয়েছে।

## শেখা

এই কোর্সে, আমরা PyTorch এবং TensorFlow উভয়ের জন্য বেশিরভাগ বিষয়বস্তু প্রদান করি। আপনি আপনার পছন্দের ফ্রেমওয়ার্ক নির্বাচন করতে পারেন এবং শুধুমাত্র সংশ্লিষ্ট নোটবুকগুলি অনুসরণ করতে পারেন। আপনি যদি নিশ্চিত না হন কোন ফ্রেমওয়ার্ক নির্বাচন করবেন, **PyTorch vs. TensorFlow** সম্পর্কিত ইন্টারনেটে কিছু আলোচনা পড়ুন। আপনি উভয় ফ্রেমওয়ার্কের দিকে তাকাতে পারেন আরও ভালো বোঝার জন্য।

যেখানে সম্ভব, আমরা সরলতার জন্য উচ্চ-স্তরের API ব্যবহার করব। তবে, আমরা বিশ্বাস করি এটি গুরুত্বপূর্ণ যে নিউরাল নেটওয়ার্কগুলি নিচ থেকে কিভাবে কাজ করে তা বোঝা, তাই শুরুতে আমরা নিম্ন-স্তরের API এবং টেনসরগুলির সাথে কাজ শুরু করি। তবে, আপনি যদি দ্রুত শুরু করতে চান এবং এই বিস্তারিতগুলি শেখার জন্য অনেক সময় ব্যয় করতে না চান, আপনি সেগুলি বাদ দিতে পারেন এবং সরাসরি উচ্চ-স্তরের API নোটবুকগুলিতে যেতে পারেন।

## ✍️ অনুশীলন: ফ্রেমওয়ার্কস

নিম্নলিখিত নোটবুকগুলিতে আপনার শেখা চালিয়ে যান:

নিম্ন-স্তরের API | TensorFlow+Keras নোটবুক | PyTorch
--------------|-------------------------------------|--------------------------------
উচ্চ-স্তরের API| Keras | *PyTorch Lightning*

ফ্রেমওয়ার্কগুলি আয়ত্ত করার পরে, আসুন ওভারফিটিং ধারণাটি পুনরায় পর্যালোচনা করি।

# ওভারফিটিং

ওভারফিটিং মেশিন লার্নিংয়ের একটি অত্যন্ত গুরুত্বপূর্ণ ধারণা, এবং এটি সঠিকভাবে বোঝা খুবই গুরুত্বপূর্ণ!

নিচের সমস্যাটি বিবেচনা করুন ৫টি বিন্দু (গ্রাফগুলিতে `x` দ্বারা উপস্থাপিত):

!linear | overfit
-------------------------|--------------------------
**লিনিয়ার মডেল, ২টি প্যারামিটার** | **নন-লিনিয়ার মডেল, ৭টি প্যারামিটার**
প্রশিক্ষণ ত্রুটি = ৫.৩ | প্রশিক্ষণ ত্রুটি = ০
প্রমাণ ত্রুটি = ৫.১ | প্রমাণ ত্রুটি = ২০

* বামে, আমরা একটি ভালো সরল রেখার আনুমানিককরণ দেখি। কারণ প্যারামিটারের সংখ্যা যথাযথ, মডেলটি বিন্দু বিতরণের পিছনের ধারণাটি সঠিকভাবে পায়।
* ডানে, মডেলটি খুব শক্তিশালী। কারণ আমাদের মাত্র ৫টি বিন্দু আছে এবং মডেলের ৭টি প্যারামিটার আছে, এটি এমনভাবে সামঞ্জস্য করতে পারে যাতে সব বিন্দুর মধ্য দিয়ে যেতে পারে, প্রশিক্ষণ ত্রুটিকে ০ করে দেয়। তবে, এটি মডেলকে ডেটার পিছনের সঠিক প্যাটার্নটি বুঝতে বাধা দেয়, তাই প্রমাণ ত্রুটি খুব বেশি।

মডেলের সমৃদ্ধি (প্যারামিটারের সংখ্যা) এবং প্রশিক্ষণ নমুনার সংখ্যার মধ্যে একটি সঠিক ভারসাম্য বজায় রাখা খুবই গুরুত্বপূর্ণ।

## কেন ওভারফিটিং ঘটে

  * পর্যাপ্ত প্রশিক্ষণ ডেটা নেই
  * খুব শক্তিশালী মডেল
  * ইনপুট ডেটায় খুব বেশি শব্দ

## কিভাবে ওভারফিটিং সনাক্ত করবেন

আপনি উপরের গ্রাফ থেকে দেখতে পারেন, ওভারফিটিং একটি খুব কম প্রশিক্ষণ ত্রুটি এবং একটি উচ্চ প্রমাণ ত্রুটি দ্বারা সনাক্ত করা যেতে পারে। সাধারণত প্রশিক্ষণের সময় আমরা দেখব প্রশিক্ষণ এবং প্রমাণ উভয় ত্রুটিই কমতে শুরু করে, এবং তারপর কিছু সময়ে প্রমাণ ত্রুটি কমা বন্ধ করে এবং বৃদ্ধি পেতে শুরু করে। এটি ওভারফিটিংয়ের একটি চিহ্ন হবে, এবং নির্দেশক হবে যে আমাদের সম্ভবত এই সময়ে প্রশিক্ষণ বন্ধ করা উচিত (অথবা অন্তত মডেলের একটি স্ন্যাপশট তৈরি করা উচিত)।

ওভারফিটিং

## কিভাবে ওভারফিটিং প্রতিরোধ করবেন

আপনি যদি দেখতে পান যে ওভারফিটিং হচ্ছে, আপনি নিম্নলিখিতগুলির মধ্যে একটি করতে পারেন:

 * প্রশিক্ষণ ডেটার পরিমাণ বাড়ান
 * মডেলের জটিলতা কমান
 * কিছু নিয়মিতকরণ কৌশল ব্যবহার করুন, যেমন ড্রপআউট, যা আমরা পরে বিবেচনা করব।

## ওভারফিটিং এবং বায়াস-ভ্যারিয়েন্স ট্রেডঅফ

ওভারফিটিং আসলে পরিসংখ্যানের একটি আরও সাধারণ সমস্যার একটি ঘটনা যা বায়াস-ভ্যারিয়েন্স ট্রেডঅফ নামে পরিচিত। যদি আমরা আমাদের মডেলে সম্ভাব্য ত্রুটির উত্স বিবেচনা করি, আমরা দুটি ধরনের ত্রুটি দেখতে পারি:

* **বায়াস ত্রুটি** হয় আমাদের অ্যালগরিদম প্রশিক্ষণ ডেটার মধ্যে সম্পর্কটি সঠিকভাবে ধরতে না পারার কারণে। এটি হতে পারে আমাদের মডেল যথেষ্ট শক্তিশালী নয় (**আন্ডারফিটিং**)।
* **ভ্যারিয়েন্স ত্রুটি**, যা ইনপুট ডেটার মধ্যে অর্থপূর্ণ সম্পর্কের পরিবর্তে শব্দ আনুমানিক করার কারণে হয় (**ওভারফিটিং**)।

প্রশিক্ষণের সময়, বায়াস ত্রুটি কমে (যেমন আমাদের মডেল ডেটা আনুমানিক করতে শিখে), এবং ভ্যারিয়েন্স ত্রুটি বৃদ্ধি পায়। ওভারফিটিং প্রতিরোধ করতে প্রশিক্ষণ বন্ধ করা গুরুত্বপূর্ণ - হয় ম্যানুয়ালি (যখন আমরা ওভারফিটিং সনাক্ত করি) বা স্বয়ংক্রিয়ভাবে (নিয়মিতকরণ প্রবর্তন করে)।

## উপসংহার

এই পাঠে, আপনি দুটি সবচেয়ে জনপ্রিয় AI ফ্রেমওয়ার্ক, TensorFlow এবং PyTorch-এর জন্য বিভিন্ন API-এর মধ্যে পার্থক্য সম্পর্কে শিখেছেন। এছাড়াও, আপনি একটি খুব গুরুত্বপূর্ণ বিষয়, ওভারফিটিং সম্পর্কে শিখেছেন।

## 🚀 চ্যালেঞ্জ

সংযুক্ত নোটবুকগুলিতে, আপনি 'কাজ' খুঁজে পাবেন নিচে; নোটবুকগুলি অনুসরণ করুন এবং কাজগুলি সম্পন্ন করুন।

## পর্যালোচনা ও স্ব-অধ্যয়ন

নিম্নলিখিত বিষয়গুলিতে কিছু গবেষণা করুন:

- TensorFlow
- PyTorch
- ওভারফিটিং

নিজেকে নিম্নলিখিত প্রশ্নগুলি করুন:

- TensorFlow এবং PyTorch-এর মধ্যে পার্থক্য কী?
- ওভারফিটিং এবং আন্ডারফিটিং-এর মধ্যে পার্থক্য কী?

## অ্যাসাইনমেন্ট

এই ল্যাবে, আপনাকে PyTorch বা TensorFlow ব্যবহার করে একক এবং বহু-স্তরের সম্পূর্ণ সংযুক্ত নেটওয়ার্ক ব্যবহার করে দুটি শ্রেণীবিন্যাস সমস্যা সমাধান করতে বলা হয়েছে।

**অস্বীকৃতি**:  
এই নথিটি AI অনুবাদ পরিষেবা [Co-op Translator](https://github.com/Azure/co-op-translator) ব্যবহার করে অনুবাদ করা হয়েছে। আমরা যথাসম্ভব সঠিকতার চেষ্টা করি, তবে অনুগ্রহ করে সচেতন থাকুন যে স্বয়ংক্রিয় অনুবাদে ত্রুটি বা অসংগতি থাকতে পারে। মূল ভাষায় থাকা নথিটিকে প্রামাণিক উৎস হিসেবে বিবেচনা করা উচিত। গুরুত্বপূর্ণ তথ্যের জন্য, পেশাদার মানব অনুবাদ সুপারিশ করা হয়। এই অনুবাদের ব্যবহার থেকে উদ্ভূত কোন ভুল বোঝাবুঝি বা ভুল ব্যাখ্যার জন্য আমরা দায়ী নই।