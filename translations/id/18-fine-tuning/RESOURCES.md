<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:45:20+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "id"
}
-->
# Sumber Daya untuk Belajar Mandiri

Pelajaran ini dibangun menggunakan sejumlah sumber daya inti dari OpenAI dan Azure OpenAI sebagai referensi untuk terminologi dan tutorial. Berikut adalah daftar yang tidak lengkap, untuk perjalanan belajar mandiri Anda.

## 1. Sumber Daya Utama

| Judul/Tautan                                                                                                                                                                                                                   | Deskripsi                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Fine-tuning dengan Model OpenAI](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                       | Fine-tuning meningkatkan pembelajaran beberapa contoh dengan melatih pada lebih banyak contoh daripada yang bisa dimuat dalam prompt, menghemat biaya, meningkatkan kualitas respons, dan memungkinkan permintaan dengan latensi lebih rendah. **Dapatkan gambaran umum tentang fine-tuning dari OpenAI.**                                                                                    |
| [Apa itu Fine-Tuning dengan Azure OpenAI?](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                   | Memahami **apa itu fine-tuning (konsep)**, mengapa Anda harus mempertimbangkannya (masalah motivasi), data apa yang harus digunakan (pelatihan), dan mengukur kualitasnya.                                                                                                                                                                           |
| [Sesuaikan model dengan fine-tuning](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst) | Layanan Azure OpenAI memungkinkan Anda menyesuaikan model kami dengan dataset pribadi Anda menggunakan fine-tuning. Pelajari **cara melakukan fine-tuning (proses)** memilih model menggunakan Azure AI Studio, Python SDK, atau REST API.                                                                                                                                |
| [Rekomendasi untuk fine-tuning LLM](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                    | LLM mungkin tidak berkinerja baik pada domain, tugas, atau dataset tertentu, atau dapat menghasilkan output yang tidak akurat atau menyesatkan. **Kapan Anda harus mempertimbangkan fine-tuning** sebagai solusi yang mungkin untuk ini?                                                                                                                                  |
| [Fine Tuning Berkelanjutan](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)             | Fine-tuning berkelanjutan adalah proses iteratif memilih model yang sudah di-fine-tune sebagai model dasar dan **melakukan fine-tuning lebih lanjut** pada set contoh pelatihan baru.                                                                                                                                                     |
| [Fine-tuning dan pemanggilan fungsi](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                       | Fine-tuning model Anda **dengan contoh pemanggilan fungsi** dapat meningkatkan output model dengan mendapatkan output yang lebih akurat dan konsisten - dengan respons yang diformat serupa & penghematan biaya.                                                                                                                                        |
| [Fine-tuning Model: Panduan Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                                        | Lihat tabel ini untuk memahami **model apa yang dapat di-fine-tune** di Azure OpenAI, dan di wilayah mana ini tersedia. Periksa batas token dan tanggal kedaluwarsa data pelatihan jika diperlukan.                                                                                                                            |
| [Untuk Fine Tune atau Tidak Fine Tune? Itulah Pertanyaannya](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                      | Episode **Oktober 2023** dari AI Show ini membahas manfaat, kekurangan, dan wawasan praktis yang membantu Anda membuat keputusan ini.                                                                                                                                                                                        |
| [Memulai dengan Fine-Tuning LLM](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                             | Sumber daya **AI Playbook** ini membimbing Anda melalui persyaratan data, pemformatan, fine-tuning hyperparameter, dan tantangan/batasan yang harus Anda ketahui.                                                                                                                                                                         |
| **Tutorial**: [Azure OpenAI GPT3.5 Turbo Fine-Tuning](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                                  | Pelajari cara membuat dataset fine-tuning contoh, mempersiapkan fine-tuning, membuat pekerjaan fine-tuning, dan menerapkan model yang di-fine-tune di Azure.                                                                                                                                                                                    |
| **Tutorial**: [Fine-tune model Llama 2 di Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                                      | Azure AI Studio memungkinkan Anda menyesuaikan model bahasa besar dengan dataset pribadi Anda _menggunakan alur kerja berbasis antarmuka yang cocok untuk pengembang low-code_. Lihat contoh ini.                                                                                                                                                               |
| **Tutorial**:[Fine-tune model Hugging Face untuk satu GPU di Azure](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)               | Artikel ini menjelaskan cara fine-tune model Hugging Face dengan perpustakaan transformers Hugging Face pada satu GPU dengan Azure DataBricks + perpustakaan Hugging Face Trainer.                                                                                                                                                |
| **Pelatihan:** [Fine-tune model dasar dengan Azure Machine Learning](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)         | Katalog model di Azure Machine Learning menawarkan banyak model sumber terbuka yang dapat Anda fine-tune untuk tugas khusus Anda. Cobalah modul ini [dari Jalur Pembelajaran Generatif AzureML](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst) |
| **Tutorial:** [Fine-Tuning Azure OpenAI](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                | Fine-tuning model GPT-3.5 atau GPT-4 di Microsoft Azure menggunakan W&B memungkinkan pelacakan dan analisis kinerja model yang lebih rinci. Panduan ini memperluas konsep dari panduan Fine-Tuning OpenAI dengan langkah dan fitur khusus untuk Azure OpenAI.                                                                         |
|                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                               |

## 2. Sumber Daya Sekunder

Bagian ini mencakup sumber daya tambahan yang layak dijelajahi, tetapi tidak sempat kita bahas dalam pelajaran ini. Mereka mungkin akan dibahas dalam pelajaran mendatang, atau sebagai opsi tugas sekunder, di kemudian hari. Untuk saat ini, gunakan mereka untuk membangun keahlian dan pengetahuan Anda sendiri tentang topik ini.

| Judul/Tautan                                                                                                                                                                                                            | Deskripsi                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI Cookbook**: [Persiapan dan analisis data untuk fine-tuning model chat](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                                      | Notebook ini berfungsi sebagai alat untuk memproses dan menganalisis dataset chat yang digunakan untuk fine-tuning model chat. Ini memeriksa kesalahan format, memberikan statistik dasar, dan memperkirakan jumlah token untuk biaya fine-tuning. Lihat: [Metode fine-tuning untuk gpt-3.5-turbo](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst).                                                                                                                                                                   |
| **OpenAI Cookbook**: [Fine-Tuning untuk Retrieval Augmented Generation (RAG) dengan Qdrant](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst) | Tujuan dari notebook ini adalah untuk melalui contoh komprehensif tentang cara fine-tune model OpenAI untuk Retrieval Augmented Generation (RAG). Kami juga akan mengintegrasikan Qdrant dan Pembelajaran Beberapa Contoh untuk meningkatkan kinerja model dan mengurangi fabrikasi.                                                                                                                                                                                                                                                                |
| **OpenAI Cookbook**: [Fine-tuning GPT dengan Weights & Biases](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                             | Weights & Biases (W&B) adalah platform pengembang AI, dengan alat untuk melatih model, fine-tuning model, dan memanfaatkan model dasar. Bacalah panduan [OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst) mereka terlebih dahulu, kemudian coba latihan Cookbook ini.                                                                                                                                                                                                                  |
| **Tutorial Komunitas** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - fine-tuning untuk Model Bahasa Kecil                                                   | Kenali [Phi-2](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst), model kecil baru dari Microsoft, yang sangat kuat namun kompak. Tutorial ini akan membimbing Anda melalui fine-tuning Phi-2, menunjukkan cara membangun dataset unik dan fine-tune model menggunakan QLoRA.                                                                                                                                                                       |
| **Tutorial Hugging Face** [Cara Fine-Tune LLM di 2024 dengan Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | Posting blog ini membimbing Anda melalui cara fine-tune LLM terbuka menggunakan Hugging Face TRL, Transformers & dataset pada tahun 2024. Anda mendefinisikan kasus penggunaan, mengatur lingkungan pengembangan, mempersiapkan dataset, fine tune model, menguji-mengevaluasi, kemudian menerapkannya ke produksi.                                                                                                                                                                                                                                                                |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                            | Membawa pelatihan dan penerapan [model pembelajaran mesin mutakhir](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst) lebih cepat dan lebih mudah. Repo ini memiliki tutorial yang ramah-Colab dengan panduan video YouTube, untuk fine-tuning. **Mencerminkan pembaruan [local-first](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst) terbaru**. Bacalah [dokumentasi AutoTrain](https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst) |
|                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan layanan penerjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berusaha untuk akurasi, harap diingat bahwa terjemahan otomatis mungkin mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang berwenang. Untuk informasi penting, disarankan menggunakan terjemahan manusia profesional. Kami tidak bertanggung jawab atas kesalahpahaman atau salah tafsir yang timbul dari penggunaan terjemahan ini.