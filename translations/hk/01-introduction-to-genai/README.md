<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f53ba0fa49164f9323043f1c6b11f2b1",
  "translation_date": "2025-05-19T13:06:56+00:00",
  "source_file": "01-introduction-to-genai/README.md",
  "language_code": "hk"
}
-->
# 生成式人工智能和大型语言模型简介

生成式人工智能是一种能够生成文本、图像和其他内容类型的人工智能。它的神奇之处在于它使得人工智能变得大众化，任何人都可以使用它，只需一个文本提示，即一句自然语言的句子。你不需要学习像Java或SQL这样的语言来完成有价值的事情，只需使用你的语言，表达你的需求，然后人工智能模型就会给出建议。这种技术的应用和影响是巨大的，你可以在几秒钟内撰写或理解报告、编写应用程序等。

在这个课程中，我们将探讨我们的创业公司如何利用生成式人工智能在教育领域开启新场景，以及如何应对其应用带来的社会影响和技术限制的挑战。

## 简介

本课程将涵盖：

- 商业场景介绍：我们的创业公司理念和使命。
- 生成式人工智能及其在当前技术环境中的发展。
- 大型语言模型的内部工作机制。
- 大型语言模型的主要能力和实际应用案例。

## 学习目标

完成本课程后，你将了解：

- 什么是生成式人工智能以及大型语言模型的工作原理。
- 如何利用大型语言模型进行不同的应用，特别是关注教育场景。

## 场景：我们的教育创业公司

生成式人工智能代表了人工智能技术的顶峰，突破了曾经被认为不可能的界限。生成式人工智能模型有多种能力和应用，但在本课程中，我们将探讨它如何通过一个虚构的创业公司革新教育。我们将称这个创业公司为_我们的创业公司_。我们的创业公司在教育领域工作，拥有雄心勃勃的使命宣言：

> _在全球范围内提高学习的可及性，确保教育的公平获取，并根据每位学习者的需求提供个性化学习体验。_

我们的创业团队知道，如果不利用现代时代最强大的工具之一——大型语言模型（LLMs），我们将无法实现这一目标。

生成式人工智能预计将彻底改变我们今天的学习和教学方式，学生可以随时使用虚拟教师，提供大量信息和示例，教师可以利用创新工具评估学生并提供反馈。

要开始，我们先定义一些将在整个课程中使用的基本概念和术语。

## 我们是如何获得生成式人工智能的？

尽管最近生成式人工智能模型的发布引起了极大的_炒作_，但这项技术已经发展了几十年，最早的研究努力可以追溯到60年代。我们现在处于人工智能拥有类似人类认知能力的阶段，比如通过[OpenAI ChatGPT](https://openai.com/chatgpt)或[必应聊天](https://www.microsoft.com/edge/features/bing-chat?WT.mc_id=academic-105485-koreyst)，它们也使用GPT模型进行网络搜索和必应对话。

回顾一下，最早的人工智能原型是打字聊天机器人，依赖于从专家组中提取的知识库并存储到计算机中。知识库中的答案是通过输入文本中出现的关键词触发的。然而，很快就发现这种使用打字聊天机器人的方法并不能很好地扩展。

### 统计方法的人工智能：机器学习

90年代时，应用统计方法进行文本分析成为转折点。这促使开发出新的算法——即机器学习算法——能够从数据中学习模式，而无需明确编程。这种方法允许机器模拟人类语言理解：一个统计模型在文本-标签配对上进行训练，使模型能够以预定义标签分类未知输入文本，代表信息的意图。

### 神经网络和现代虚拟助手

近年来，硬件技术的进步能够处理更大量的数据和更复杂的计算，推动了人工智能领域的研究，导致开发出高级机器学习算法，即神经网络或深度学习算法。

神经网络（尤其是循环神经网络——RNNs）显著增强了自然语言处理，能够以更有意义的方式表示文本的意义，重视句子中词语的上下文。

这就是技术推动了21世纪初诞生的虚拟助手，非常擅长解释人类语言，识别需求并执行行动以满足需求——比如回答预定义脚本或使用第三方服务。

### 现今，生成式人工智能

这就是我们今天如何走到生成式人工智能的，它可以被视为深度学习的一个子集。

在人工智能领域研究几十年后，一种新的模型架构——称为_Transformer_——克服了RNNs的限制，能够接收更长的文本序列作为输入。Transformers基于注意力机制，使模型能够对接收到的输入给予不同权重，“更加关注”最相关的信息所在之处，而不论它们在文本序列中的顺序。

最近的生成式人工智能模型——也称为大型语言模型（LLMs），因为它们处理文本输入和输出——确实基于这种架构。这些模型的有趣之处在于它们经过大量来自书籍、文章和网站等不同来源的未标记数据训练，可以适应多种任务并生成语法正确且具有创造性的文本。因此，它们不仅极大地增强了机器“理解”输入文本的能力，还使其能够生成具有原创性的回复。

## 大型语言模型是如何工作的？

在下一章中，我们将探讨不同类型的生成式人工智能模型，但现在我们先看看大型语言模型是如何工作的，重点是OpenAI GPT（生成预训练Transformer）模型。

- **分词器，文本转数字**：大型语言模型接收文本作为输入并生成文本作为输出。然而，作为统计模型，它们使用数字比文本序列效果更好。这就是为什么每个输入在被核心模型使用之前要经过分词器处理。一个token是一个文本块——由可变数量的字符组成，因此分词器的主要任务是将输入拆分为token数组。然后，每个token与一个token索引映射，这是原始文本块的整数编码。

- **预测输出token**：给定n个token作为输入（最大n因模型而异），模型能够预测一个token作为输出。这个token随后被纳入下一次迭代的输入中，以扩展窗口模式，提供更好的用户体验，得到一个（或多个）句子作为答案。这解释了为什么如果你曾使用过ChatGPT，你可能注意到有时它看起来像是在句子中间停止。

- **选择过程，概率分布**：输出token由模型根据其在当前文本序列后出现的概率选择。这是因为模型预测了所有可能“下一个token”的概率分布，基于其训练进行计算。然而，并不总是从结果分布中选择概率最高的token。为了模拟创造性思维的过程，选择过程中加入了一定程度的随机性，使模型以非确定性方式行动——我们不会得到相同输入的完全相同输出。这种随机性程度可以通过模型参数称为温度进行调整。

## 我们的创业公司如何利用大型语言模型？

现在我们对大型语言模型的内部工作机制有了更好的理解，让我们看看它们可以很好地执行的一些最常见任务的实际例子，关注我们的商业场景。
我们说大型语言模型的主要能力是_从头生成文本，从自然语言写成的文本输入开始_。

但是什么样的文本输入和输出呢？
大型语言模型的输入称为提示，而输出称为完成，这个术语指的是模型生成下一个token以完成当前输入的机制。我们将深入探讨什么是提示以及如何设计它以充分利用我们的模型。但现在，我们只说一个提示可能包括：

- 一个**指令**，指定我们期望从模型获得的输出类型。这个指令有时可能包含一些示例或额外数据。

  1. 文章、书籍、产品评论等的总结，以及从非结构化数据中提取见解。

  2. 创意构思和设计文章、论文、作业等。

- 一个**问题**，以与代理进行对话的形式提出。

- 一个需要**补全的文本块**，隐含地请求写作协助。

- 一个**代码块**，同时请求解释和记录它，或者一个评论请求生成执行特定任务的代码。

上述示例非常简单，并不打算全面展示大型语言模型的能力。它们旨在展示使用生成式人工智能的潜力，特别是但不限于教育环境。

此外，生成式人工智能模型的输出并不完美，有时模型的创造力可能对其不利，导致输出是人类用户可以解释为现实的扭曲或可能是冒犯的词语组合。生成式人工智能并不智能——至少在更全面的智能定义中，包括批判性和创造性推理或情感智能；它不是确定性的，也不值得信赖，因为错误的参考、内容和陈述可能与正确信息结合，并以一种令人信服和自信的方式呈现。在接下来的课程中，我们将处理所有这些限制，并看看我们可以做些什么来减轻它们。

## 作业

你的作业是更多地阅读[生成式人工智能](https://en.wikipedia.org/wiki/Generative_artificial_intelligence?WT.mc_id=academic-105485-koreyst)，并尝试识别一个你今天会添加生成式人工智能但还没有的领域。与“旧方式”相比，影响会有什么不同，你能做以前不能做的事情吗，或者速度更快吗？写一篇300字的总结，描述你的梦想人工智能创业公司会是什么样子，并包括“问题”、“我如何使用人工智能”、“影响”和可选的商业计划等标题。

如果你完成了这项任务，你甚至可能准备好申请微软的孵化器，[微软创业公司创始人中心](https://www.microsoft.com/startups?WT.mc_id=academic-105485-koreyst)我们提供Azure、OpenAI、指导等的积分，快来看看吧！

## 知识检查

关于大型语言模型，什么是正确的？

1. 每次你都会得到完全相同的回复。
2. 它完美地完成任务，非常擅长加法、生成工作代码等。
3. 尽管使用相同的提示，回复可能会有所不同。它也非常擅长为你提供某事的初稿，无论是文本还是代码。但你需要改进结果。

A: 3，LLM是非确定性的，回复会有所不同，但你可以通过温度设置控制其变化。你也不应该期望它完美地完成任务，它在这里为你做繁重的工作，这通常意味着你得到的是一个好的初步尝试，需要逐步改进。

## 出色的工作！继续学习旅程

完成本课程后，请查看我们的[生成式人工智能学习集合](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)以继续提升你的生成式人工智能知识！

前往第2课，我们将探讨如何[探索和比较不同类型的LLM](../02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst)！

**免責聲明**：
本文檔已使用AI翻譯服務[Co-op Translator](https://github.com/Azure/co-op-translator)進行翻譯。我們努力確保準確性，但請注意，自動翻譯可能包含錯誤或不準確之處。應以原始文件的母語版本作為權威來源。對於關鍵信息，建議使用專業人工翻譯。對於使用此翻譯而產生的任何誤解或誤讀，我們不承擔責任。