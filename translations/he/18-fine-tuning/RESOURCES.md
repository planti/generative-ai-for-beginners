<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:44:09+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "he"
}
-->
# משאבים ללמידה עצמאית

השיעור נבנה באמצעות מספר משאבים מרכזיים מ-OpenAI ו-Azure OpenAI כהפניות למונחים ולמדריכים. הנה רשימה לא מקיפה, למסעות הלמידה העצמאיים שלך.

## 1. משאבים ראשיים

| כותרת/קישור                                                                                                                                                                                                                   | תיאור                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Fine-tuning עם מודלים של OpenAI](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                       | Fine-tuning משפר את הלמידה עם מעט דוגמאות על ידי אימון על הרבה יותר דוגמאות ממה שניתן להכניס להנחיה, חוסך לך עלויות, משפר את איכות התגובה ומאפשר בקשות עם זמן תגובה נמוך יותר. **קבל סקירה של Fine-tuning מ-OpenAI.**                                                                                    |
| [מהו Fine-Tuning עם Azure OpenAI?](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                   | הבן **מהו Fine-tuning (מושג)**, מדוע כדאי לך להסתכל עליו (בעיה מניעה), איזה נתונים להשתמש (אימון) ומדידת איכות                                                                                                                                                                           |
| [התאמה אישית של מודל עם Fine-Tuning](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst) | שירות Azure OpenAI מאפשר לך להתאים את המודלים שלנו לנתוני האישיים שלך באמצעות Fine-Tuning. למד **כיצד לבצע Fine-tuning (תהליך)** למודלים נבחרים באמצעות Azure AI Studio, Python SDK או REST API.                                                                                                                                |
| [המלצות ל-Fine-Tuning של LLM](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                    | LLMs עשויים לא להציג ביצועים טובים בתחומים, משימות או קבוצות נתונים ספציפיים, או עשויים להפיק תוצאות לא מדויקות או מטעות. **מתי כדאי לשקול Fine-Tuning** כפתרון אפשרי לכך?                                                                                                                                  |
| [Fine-Tuning מתמשך](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)             | Fine-Tuning מתמשך הוא תהליך איטרטיבי של בחירת מודל שכבר עבר Fine-Tuning כמודל בסיס ו-**Fine-Tuning נוסף** שלו על קבוצות חדשות של דוגמאות אימון.                                                                                                                                                     |
| [Fine-Tuning וקריאת פונקציות](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                       | Fine-Tuning של המודל שלך **עם דוגמאות לקריאת פונקציות** יכול לשפר את תפוקת המודל על ידי קבלת תוצאות מדויקות ועקביות יותר - עם תגובות בפורמט דומה וחיסכון בעלויות                                                                                                                                        |
| [Fine-Tuning של מודלים: הנחיות Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                                        | חפש בטבלה זו כדי להבין **אילו מודלים ניתן לבצע Fine-Tuning** ב-Azure OpenAI, ובאילו אזורים הם זמינים. חפש את מגבלות הטוקן שלהם ותאריכי תפוגת נתוני האימון אם יש צורך.                                                                                                                            |
| [לעשות Fine-Tune או לא לעשות Fine-Tune? זו השאלה](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                      | פרק זה של ה-AI Show בן 30 דקות **אוקטובר 2023** דן ביתרונות, חסרונות ותובנות מעשיות שיסייעו לך לקבל החלטה זו.                                                                                                                                                                                        |
| [התחלה עם Fine-Tuning של LLM](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                             | משאב זה של **AI Playbook** מלווה אותך דרך דרישות הנתונים, פורמט, Fine-Tuning של היפרפרמטרים ואתגרים/מגבלות שכדאי לדעת.                                                                                                                                                                         |
| **מדריך**: [Azure OpenAI GPT3.5 Turbo Fine-Tuning](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                                  | למד ליצור קבוצת נתונים לדוגמה ל-Fine-Tuning, להתכונן ל-Fine-Tuning, ליצור עבודה של Fine-Tuning ולפרוס את המודל שעבר Fine-Tuning ב-Azure.                                                                                                                                                                                    |
| **מדריך**: [Fine-tune מודל Llama 2 ב-Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                                      | Azure AI Studio מאפשר לך להתאים מודלים של שפה גדולה לנתונים האישיים שלך _באמצעות תהליך עבודה מבוסס UI המתאים למפתחים עם מעט קוד_. ראה דוגמה זו.                                                                                                                                                               |
| **מדריך**:[Fine-tune מודלים של Hugging Face עבור GPU יחיד ב-Azure](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)               | מאמר זה מתאר כיצד לבצע Fine-Tuning של מודל Hugging Face עם ספריית Hugging Face transformers על GPU יחיד עם Azure DataBricks + ספריות Hugging Face Trainer                                                                                                                                                |
| **הדרכה:** [Fine-tune מודל יסוד עם Azure Machine Learning](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)         | קטלוג המודלים ב-Azure Machine Learning מציע מודלים רבים בקוד פתוח שניתן לבצע Fine-Tuning למשימה הספציפית שלך. נסה מודול זה [מנתיב הלמידה של AzureML Generative AI](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst) |
| **מדריך:** [Azure OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                | Fine-Tuning של מודלים GPT-3.5 או GPT-4 ב-Microsoft Azure באמצעות W&B מאפשר מעקב וניתוח מפורט של ביצועי המודל. מדריך זה מרחיב את המושגים מהמדריך של OpenAI Fine-Tuning עם צעדים ותכונות ספציפיות ל-Azure OpenAI.                                                                         |
|                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                               |

## 2. משאבים משניים

סעיף זה מכיל משאבים נוספים שכדאי לחקור, אך שלא היה לנו זמן לכסות בשיעור זה. הם עשויים להיות מכוסים בשיעור עתידי, או כאופציה למשימה משנית, במועד מאוחר יותר. לעת עתה, השתמש בהם כדי לבנות את המומחיות והידע שלך בנושא זה.

| כותרת/קישור                                                                                                                                                                                                            | תיאור                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI Cookbook**: [הכנת נתונים וניתוח עבור Fine-Tuning של מודל צ'אט](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                                      | מחברת זו משמשת ככלי לעיבוד וניתוח קבוצת הנתונים של צ'אט המשמשת ל-Fine-Tuning של מודל צ'אט. היא בודקת שגיאות פורמט, מספקת סטטיסטיקות בסיסיות ומעריכה ספירת טוקנים עבור עלויות Fine-Tuning. ראה: [שיטת Fine-Tuning עבור gpt-3.5-turbo](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst).                                                                                                                                                                   |
| **OpenAI Cookbook**: [Fine-Tuning עבור יצירה מוגברת באמצעות חיפוש (RAG) עם Qdrant](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst) | המטרה של מחברת זו היא לעבור על דוגמה מקיפה של כיצד לבצע Fine-Tuning למודלים של OpenAI עבור יצירה מוגברת באמצעות חיפוש (RAG). אנו גם נשלב Qdrant ולמידה עם מעט דוגמאות כדי לשפר את ביצועי המודל ולהפחית את ההמצאות.                                                                                                                                                                                                                                                                |
| **OpenAI Cookbook**: [Fine-Tuning GPT עם Weights & Biases](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                             | Weights & Biases (W&B) היא פלטפורמת המפתחים AI, עם כלים לאימון מודלים, Fine-Tuning של מודלים וניצול מודלים יסודיים. קרא את [מדריך OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst) תחילה, ואז נסה את התרגיל של Cookbook.                                                                                                                                                                                                                  |
| **מדריך קהילתי** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - Fine-Tuning עבור מודלים של שפה קטנה                                                   | הכירו את [Phi-2](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst), המודל הקטן החדש של Microsoft, חזק במיוחד אך קומפקטי. מדריך זה ילווה אותך דרך Fine-Tuning של Phi-2, וידגים כיצד לבנות קבוצת נתונים ייחודית ולבצע Fine-Tuning למודל באמצעות QLoRA.                                                                                                                                                                       |
| **מדריך Hugging Face** [כיצד לבצע Fine-Tuning ל-LLMs ב-2024 עם Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | פוסט זה בבלוג מלווה אותך כיצד לבצע Fine-Tuning ל-LLMs פתוחים באמצעות Hugging Face TRL, Transformers וקבוצות נתונים ב-2024. אתה מגדיר מקרה שימוש, מקים סביבה לפיתוח, מכין קבוצת נתונים, מבצע Fine-Tuning למודל, בודק-מעריך אותו ואז מפרס אותו לייצור.                                                                                                                                                                                                                                                                |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                            | מביא אימונים ופרסומים מהירים וקלים יותר של [מודלים למידת מכונה מתקדמים](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst). ריפו מכיל מדריכים ידידותיים ל-Colab עם הדרכת וידאו ביוטיוב, ל-Fine-Tuning. **משקף עדכון [local-first](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst) עדכני**. קרא את [תיעוד AutoTrain](https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst) |
|                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום AI [Co-op Translator](https://github.com/Azure/co-op-translator). בעוד שאנו שואפים לדיוק, יש להיות מודעים לכך שתרגומים אוטומטיים עשויים להכיל שגיאות או אי-דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור הסמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי בני אדם. אנו לא נושאים באחריות לכל אי הבנות או פרשנויות שגויות הנובעות מהשימוש בתרגום זה.