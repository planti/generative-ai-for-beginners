<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "59021c5f419d3feda19075910a74280a",
  "translation_date": "2025-05-20T06:40:52+00:00",
  "source_file": "15-rag-and-vector-databases/data/perceptron.md",
  "language_code": "he"
}
-->
# מבוא לרשתות עצביות: פרספטרון

אחת מהניסיונות הראשונים ליישם משהו הדומה לרשת עצבית מודרנית נעשתה על ידי פרנק רוזנבלט ממעבדת האווירונאוטיקה של אוניברסיטת קורנל בשנת 1957. זה היה יישום חומרה שנקרא "Mark-1", שתוכנן לזהות צורות גיאומטריות פרימיטיביות, כמו משולשים, ריבועים ומעגלים.

|      |      |
|--------------|-----------|
|<img src='images/Rosenblatt-wikipedia.jpg' alt='Frank Rosenblatt'/> | <img src='images/Mark_I_perceptron_wikipedia.jpg' alt='The Mark 1 Perceptron' />|

> תמונות מוויקיפדיה

תמונת קלט הוצגה על ידי מערך של 20x20 פוטו-תאים, כך שלרשת העצבית היו 400 כניסות ויציאה בינארית אחת. רשת פשוטה הכילה נוירון אחד, שנקרא גם **יחידת לוגיקה סף**. משקולות הרשת העצבית פעלו כמו פוטנציומטרים שדרשו כוונון ידני במהלך שלב האימון.

> ✅ פוטנציומטר הוא מכשיר שמאפשר למשתמש לכוון את ההתנגדות של מעגל.

> הניו יורק טיימס כתב על הפרספטרון באותה תקופה: *עובר של מחשב אלקטרוני שהצי צפוי שיצליח ללכת, לדבר, לראות, לכתוב, לשכפל את עצמו ולהיות מודע לקיומו.*

## מודל הפרספטרון

נניח שיש לנו N מאפיינים במודל שלנו, ובמקרה כזה וקטור הקלט יהיה וקטור בגודל N. פרספטרון הוא מודל **סיווג בינארי**, כלומר הוא יכול להבחין בין שתי קטגוריות של נתוני קלט. נניח שלכל וקטור קלט x, היציאה של הפרספטרון שלנו תהיה או +1 או -1, בהתאם לקטגוריה. היציאה תחושב באמצעות הנוסחה:

y(x) = f(w<sup>T</sup>x)

כאשר f היא פונקציית הפעלה מדרגה

## אימון הפרספטרון

כדי לאמן פרספטרון, עלינו למצוא וקטור משקולות w שמסווג את רוב הערכים נכון, כלומר מביא לשגיאה **הקטנה ביותר**. שגיאה זו מוגדרת על ידי **קריטריון הפרספטרון** באופן הבא:

E(w) = -∑w<sup>T</sup>x<sub>i</sub>t<sub>i</sub>

כאשר:

* הסכום נלקח על נקודות נתוני האימון i שמובילות לסיווג שגוי
* x<sub>i</sub> הוא נתון הקלט, ו-t<sub>i</sub> הוא או -1 או +1 עבור דוגמאות שליליות וחיוביות בהתאמה.

קריטריון זה נחשב כפונקציה של משקולות w, ועלינו למזער אותו. לעיתים קרובות, משתמשים בשיטה שנקראת **ירידת גרדיאנט**, שבה אנו מתחילים עם משקולות ראשוניות w<sup>(0)</sup>, ואז בכל שלב מעדכנים את המשקולות לפי הנוסחה:

w<sup>(t+1)</sup> = w<sup>(t)</sup> - η∇E(w)

כאן η הוא מה שנקרא **קצב הלמידה**, ו-∇E(w) מסמן את **הגרדיאנט** של E. לאחר שנחשב את הגרדיאנט, נגיע ל-

w<sup>(t+1)</sup> = w<sup>(t)</sup> + ∑ηx<sub>i</sub>t<sub>i</sub>

האלגוריתם בפייתון נראה כך:

```python
def train(positive_examples, negative_examples, num_iterations = 100, eta = 1):

    weights = [0,0,0] # Initialize weights (almost randomly :)
        
    for i in range(num_iterations):
        pos = random.choice(positive_examples)
        neg = random.choice(negative_examples)

        z = np.dot(pos, weights) # compute perceptron output
        if z < 0: # positive example classified as negative
            weights = weights + eta*weights.shape

        z  = np.dot(neg, weights)
        if z >= 0: # negative example classified as positive
            weights = weights - eta*weights.shape

    return weights
```

## סיכום

בשיעור זה, למדתם על פרספטרון, שהוא מודל סיווג בינארי, וכיצד לאמן אותו באמצעות וקטור משקולות.

## 🚀 אתגר

אם תרצו לנסות לבנות פרספטרון משלכם, נסו את המעבדה הזו ב-Microsoft Learn שמשתמשת במעצב Azure ML

## סקירה ולמידה עצמית

כדי לראות כיצד ניתן להשתמש בפרספטרון כדי לפתור בעיה פשוטה כמו גם בעיות בעולם האמיתי, ולהמשיך ללמוד - גשו למחברת הפרספטרון.

הנה מאמר מעניין על פרספטרונים גם כן.

## משימה

בשיעור זה, יישמנו פרספטרון למשימת סיווג בינארי, והשתמשנו בו כדי לסווג בין שתי ספרות כתובות ידנית. במעבדה זו, אתם מתבקשים לפתור את בעיית סיווג הספרות במלואה, כלומר לקבוע איזו ספרה סביר להניח שתואמת לתמונה נתונה.

* הוראות
* מחברת

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום AI [Co-op Translator](https://github.com/Azure/co-op-translator). בעוד אנו שואפים לדיוק, יש להיות מודעים לכך שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי אנושי. אנו לא נושאים באחריות לכל אי הבנות או פרשנויות שגויות הנובעות מהשימוש בתרגום זה.