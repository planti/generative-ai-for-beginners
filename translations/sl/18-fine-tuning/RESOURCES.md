<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:52:16+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "sl"
}
-->
# Viri za samostojno učenje

Lekcija je bila zgrajena z uporabo številnih osnovnih virov iz OpenAI in Azure OpenAI kot referenc za terminologijo in vadnice. Tukaj je neizčrpen seznam za vaše samostojne učne poti.

## 1. Primarni viri

| Naslov/Povezava                                                                                                                                                                                                                   | Opis                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Fine-tuning with OpenAI Models](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                       | Fine-tuning izboljša učenje na podlagi malo primerov s treningom na veliko več primerih, kot jih lahko vključimo v poziv, kar vam prihrani stroške, izboljša kakovost odziva in omogoča zahteve z nižjo zakasnitvijo. **Pridobite pregled fine-tuninga od OpenAI.**                                                                                    |
| [What is Fine-Tuning with Azure OpenAI?](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                   | Razumeti **kaj je fine-tuning (koncept)**, zakaj bi ga morali upoštevati (motivacijski problem), katere podatke uporabiti (trening) in kako meriti kakovost.                                                                                                                                                                           |
| [Customize a model with fine-tuning](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst) | Azure OpenAI Service vam omogoča prilagajanje naših modelov vašim osebnim podatkovnim nizom z uporabo fine-tuninga. Naučite se **kako fine-tunirati (proces)** izbrane modele z uporabo Azure AI Studio, Python SDK ali REST API.                                                                                                                                |
| [Recommendations for LLM fine-tuning](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                    | LLM-ji morda ne delujejo dobro na določenih področjih, nalogah ali podatkovnih nizih ali pa lahko ustvarjajo netočne ali zavajajoče izhode. **Kdaj bi morali razmisliti o fine-tuningu** kot možni rešitvi za to?                                                                                                                                  |
| [Continuous Fine Tuning](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)             | Kontinuirani fine-tuning je iterativni proces izbire že fine-tuniranega modela kot osnovnega modela in **nadaljnjega fine-tuninga** na novih nizih trening primerov.                                                                                                                                                     |
| [Fine-tuning and function calling](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                       | Fine-tuning vašega modela **z uporabo primerov klicanja funkcij** lahko izboljša izhod modela z doseganjem bolj natančnih in doslednih izhodov - s podobno oblikovanimi odzivi in prihranki stroškov.                                                                                                                                        |
| [Fine-tuning Models: Azure OpenAI Guidance](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                                        | Oglejte si to tabelo, da razumete **katere modele je mogoče fine-tunirati** v Azure OpenAI in v katerih regijah so na voljo. Oglejte si njihove omejitve tokenov in datume izteka trening podatkov, če je potrebno.                                                                                                                            |
| [To Fine Tune or Not To Fine Tune? That is the Question](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                      | Ta 30-minutna **epizoda oktobra 2023** AI Show razpravlja o koristih, slabostih in praktičnih vpogledih, ki vam pomagajo pri tej odločitvi.                                                                                                                                                                                        |
| [Getting Started With LLM Fine-Tuning](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                             | Ta **AI Playbook** vir vas vodi skozi zahteve glede podatkov, oblikovanje, fine-tuning hiperparametrov in izzive/omejitve, ki jih morate poznati.                                                                                                                                                                         |
| **Vadnica**: [Azure OpenAI GPT3.5 Turbo Fine-Tuning](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                                  | Naučite se ustvariti vzorčni niz podatkov za fine-tuning, pripraviti se na fine-tuning, ustvariti nalogo fine-tuninga in namestiti fine-tuniran model na Azure.                                                                                                                                                                                    |
| **Vadnica**: [Fine-tune a Llama 2 model in Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                                      | Azure AI Studio vam omogoča prilagajanje velikih jezikovnih modelov vašim osebnim podatkovnim nizom _z uporabo delovnega toka, ki temelji na uporabniškem vmesniku, primernega za razvijalce z nizko količino kode_. Oglejte si ta primer.                                                                                                                                                               |
| **Vadnica**:[Fine-tune Hugging Face models for a single GPU on Azure](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)               | Ta članek opisuje, kako fine-tunirati model Hugging Face z uporabo knjižnice Hugging Face transformers na enem GPU-ju z Azure DataBricks + Hugging Face Trainer knjižnicami.                                                                                                                                                |
| **Trening:** [Fine-tune a foundation model with Azure Machine Learning](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)         | Katalog modelov v Azure Machine Learning ponuja številne odprtokodne modele, ki jih lahko fine-tunirate za vašo specifično nalogo. Preizkusite ta modul je [iz AzureML Generative AI Learning Path](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst) |
| **Vadnica:** [Azure OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                | Fine-tuning modelov GPT-3.5 ali GPT-4 na Microsoft Azure z uporabo W&B omogoča podrobno sledenje in analizo delovanja modela. Ta vodnik razširja koncepte iz OpenAI Fine-Tuning vodnika s specifičnimi koraki in funkcijami za Azure OpenAI.                                                                         |
|                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                               |

## 2. Sekundarni viri

Ta oddelek zajema dodatne vire, ki jih je vredno raziskati, vendar jih v tej lekciji nismo imeli časa obravnavati. Morda bodo zajeti v prihodnji lekciji ali kot možnost sekundarne naloge, kasneje. Za zdaj jih uporabite za izgradnjo svoje lastne strokovnosti in znanja na to temo.

| Naslov/Povezava                                                                                                                                                                                                            | Opis                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI Cookbook**: [Data preparation and analysis for chat model fine-tuning](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                                      | Ta zvezek služi kot orodje za predprocesiranje in analizo podatkovnega niza klepeta, ki se uporablja za fine-tuning modela klepeta. Preverja napake v formatu, zagotavlja osnovne statistike in ocenjuje število tokenov za stroške fine-tuninga. Glej: [Fine-tuning method for gpt-3.5-turbo](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst).                                                                                                                                                                   |
| **OpenAI Cookbook**: [Fine-Tuning for Retrieval Augmented Generation (RAG) with Qdrant](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst) | Namen tega zvezka je prehoditi celovit primer, kako fine-tunirati OpenAI modele za Retrieval Augmented Generation (RAG). Prav tako bomo integrirali Qdrant in učenje na podlagi malo primerov, da izboljšamo delovanje modela in zmanjšamo izmišljotine.                                                                                                                                                                                                                                                                |
| **OpenAI Cookbook**: [Fine-tuning GPT with Weights & Biases](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                             | Weights & Biases (W&B) je platforma za AI razvijalce z orodji za treniranje modelov, fine-tuning modelov in izkoriščanje temeljnih modelov. Najprej preberite njihov [OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst) vodnik, nato poskusite vadbo iz Cookbook-a.                                                                                                                                                                                                                  |
| **Community Tutorial** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - fine-tuning for Small Language Models                                                   | Spoznajte [Phi-2](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst), Microsoftov novi majhen model, ki je izjemno zmogljiv, a kompakten. Ta vadnica vas bo vodila skozi fine-tuning Phi-2, ki prikazuje, kako zgraditi edinstven podatkovni niz in fine-tunirati model z uporabo QLoRA.                                                                                                                                                                       |
| **Hugging Face Tutorial** [How to Fine-Tune LLMs in 2024 with Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | Ta objava na blogu vas vodi skozi postopek fine-tuniranja odprtih LLM-jev z uporabo Hugging Face TRL, Transformers in podatkovnih nizov v letu 2024. Določite primer uporabe, nastavite razvojno okolje, pripravite podatkovni niz, fine-tunirate model, ga preizkusite in ocenite, nato pa ga namestite v produkcijo.                                                                                                                                                                                                                                                                |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                            | Prinaša hitrejše in lažje treniranje ter namestitve [najnaprednejših modelov strojnega učenja](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst). Repo ima vadnice, prijazne do Colab-a, z video vodniki na YouTubu za fine-tuning. **Odraža nedavno [local-first](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst) posodobitev**. Preberite [AutoTrain dokumentacijo](https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst) |
|                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |

**Omejitev odgovornosti**: 
Ta dokument je bil preveden s pomočjo AI prevajalske storitve [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas prosimo, da se zavedate, da avtomatizirani prevodi lahko vsebujejo napake ali netočnosti. Izvirni dokument v njegovem maternem jeziku naj se šteje kot avtoritativni vir. Za kritične informacije je priporočljiv profesionalni človeški prevod. Ne odgovarjamo za morebitne nesporazume ali napačne razlage, ki bi nastale zaradi uporabe tega prevoda.