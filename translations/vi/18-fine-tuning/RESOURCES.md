<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:44:47+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "vi"
}
-->
# Tài Nguyên Tự Học

Bài học được xây dựng dựa trên một số tài nguyên cốt lõi từ OpenAI và Azure OpenAI để tham khảo thuật ngữ và hướng dẫn. Dưới đây là danh sách không đầy đủ, dành cho hành trình tự học của bạn.

## 1. Tài Nguyên Chính

| Tiêu đề/Link                                                                                                                                                                                                                   | Mô tả                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Fine-tuning với Mô Hình OpenAI](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                       | Fine-tuning cải thiện học tập ít mẫu bằng cách huấn luyện trên nhiều ví dụ hơn có thể chứa trong prompt, giúp bạn tiết kiệm chi phí, cải thiện chất lượng phản hồi và cho phép yêu cầu có độ trễ thấp hơn. **Xem tổng quan về fine-tuning từ OpenAI.**                                                                                    |
| [Fine-Tuning là gì với Azure OpenAI?](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                   | Hiểu **fine-tuning là gì (khái niệm)**, tại sao bạn nên xem xét nó (vấn đề động lực), dữ liệu nào để sử dụng (huấn luyện) và đo lường chất lượng                                                                                                                                                                           |
| [Tùy chỉnh mô hình với fine-tuning](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst) | Dịch vụ Azure OpenAI cho phép bạn điều chỉnh các mô hình của chúng tôi theo dữ liệu cá nhân của bạn bằng cách sử dụng fine-tuning. Tìm hiểu **cách fine-tuning (quy trình)** chọn mô hình bằng Azure AI Studio, Python SDK hoặc REST API.                                                                                                                                |
| [Khuyến nghị cho fine-tuning LLM](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                    | LLM có thể không hoạt động tốt trong các lĩnh vực cụ thể, nhiệm vụ hoặc tập dữ liệu, hoặc có thể tạo ra kết quả không chính xác hoặc gây hiểu lầm. **Khi nào bạn nên xem xét fine-tuning** như một giải pháp khả thi cho vấn đề này?                                                                                                                                  |
| [Fine Tuning Liên Tục](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)             | Fine-tuning liên tục là quy trình lặp đi lặp lại chọn một mô hình đã được fine-tuning làm mô hình cơ sở và **fine-tuning nó thêm nữa** trên các tập ví dụ huấn luyện mới.                                                                                                                                                     |
| [Fine-tuning và gọi hàm](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                       | Fine-tuning mô hình của bạn **với các ví dụ gọi hàm** có thể cải thiện đầu ra của mô hình bằng cách tạo ra kết quả chính xác và nhất quán hơn - với các phản hồi có định dạng tương tự & tiết kiệm chi phí                                                                                                                                        |
| [Fine-tuning Models: Hướng dẫn Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                                        | Tra cứu bảng này để hiểu **mô hình nào có thể được fine-tuning** trong Azure OpenAI, và khu vực nào có sẵn. Tra cứu giới hạn token và ngày hết hạn dữ liệu huấn luyện của chúng nếu cần.                                                                                                                            |
| [Fine-Tune hay Không Fine-Tune? Đó là Câu Hỏi](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                      | Tập này **tháng 10 năm 2023** của AI Show thảo luận về lợi ích, nhược điểm và những hiểu biết thực tiễn giúp bạn đưa ra quyết định này.                                                                                                                                                                                        |
| [Bắt Đầu Với Fine-Tuning LLM](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                             | Tài nguyên **AI Playbook** này hướng dẫn bạn qua các yêu cầu dữ liệu, định dạng, fine-tuning hyperparameter và những thách thức/hạn chế bạn nên biết.                                                                                                                                                                         |
| **Hướng dẫn**: [Azure OpenAI GPT3.5 Turbo Fine-Tuning](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                                  | Tìm hiểu cách tạo một tập dữ liệu fine-tuning mẫu, chuẩn bị cho fine-tuning, tạo một công việc fine-tuning, và triển khai mô hình đã fine-tuning trên Azure.                                                                                                                                                                                    |
| **Hướng dẫn**: [Fine-tune mô hình Llama 2 trong Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                                      | Azure AI Studio cho phép bạn điều chỉnh các mô hình ngôn ngữ lớn theo dữ liệu cá nhân của bạn _sử dụng quy trình công việc dựa trên giao diện người dùng phù hợp cho các nhà phát triển ít mã_. Xem ví dụ này.                                                                                                                                                               |
| **Hướng dẫn**:[Fine-tune mô hình Hugging Face cho một GPU trên Azure](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)               | Bài viết này mô tả cách fine-tune mô hình Hugging Face với thư viện Hugging Face transformers trên một GPU với Azure DataBricks + thư viện Hugging Face Trainer                                                                                                                                                |
| **Đào Tạo:** [Fine-tune mô hình nền tảng với Azure Machine Learning](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)         | Danh mục mô hình trong Azure Machine Learning cung cấp nhiều mô hình mã nguồn mở bạn có thể fine-tune cho nhiệm vụ cụ thể của bạn. Thử module này [từ AzureML Generative AI Learning Path](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst) |
| **Hướng dẫn:** [Azure OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                | Fine-tuning mô hình GPT-3.5 hoặc GPT-4 trên Microsoft Azure bằng W&B cho phép theo dõi chi tiết và phân tích hiệu suất mô hình. Hướng dẫn này mở rộng các khái niệm từ hướng dẫn Fine-Tuning của OpenAI với các bước và tính năng cụ thể cho Azure OpenAI.                                                                         |
|                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                               |

## 2. Tài Nguyên Phụ

Phần này ghi lại các tài nguyên bổ sung đáng để khám phá, nhưng chúng tôi không có thời gian để đề cập trong bài học này. Chúng có thể được đề cập trong bài học tương lai, hoặc như một lựa chọn bài tập phụ, vào một ngày sau đó. Hiện tại, hãy sử dụng chúng để xây dựng kiến thức và chuyên môn của riêng bạn về chủ đề này.

| Tiêu đề/Link                                                                                                                                                                                                            | Mô tả                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI Cookbook**: [Chuẩn bị và phân tích dữ liệu cho fine-tuning mô hình chat](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                                      | Notebook này phục vụ như một công cụ để tiền xử lý và phân tích tập dữ liệu chat được sử dụng cho fine-tuning mô hình chat. Nó kiểm tra lỗi định dạng, cung cấp thống kê cơ bản và ước tính số lượng token cho chi phí fine-tuning. Xem: [Phương pháp fine-tuning cho gpt-3.5-turbo](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst).                                                                                                                                                                   |
| **OpenAI Cookbook**: [Fine-Tuning cho Tạo Dữ Liệu Tăng Cường (RAG) với Qdrant](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst) | Mục đích của notebook này là hướng dẫn qua một ví dụ toàn diện về cách fine-tune mô hình OpenAI cho Tạo Dữ Liệu Tăng Cường (RAG). Chúng ta cũng sẽ tích hợp Qdrant và Học Ít Mẫu để cải thiện hiệu suất mô hình và giảm các kết quả không chính xác.                                                                                                                                                                                                                                                                |
| **OpenAI Cookbook**: [Fine-tuning GPT với Weights & Biases](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                             | Weights & Biases (W&B) là nền tảng phát triển AI, với các công cụ để huấn luyện mô hình, fine-tuning mô hình, và tận dụng các mô hình nền tảng. Đọc hướng dẫn [OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst) của họ trước, sau đó thử bài tập Cookbook.                                                                                                                                                                                                                  |
| **Hướng dẫn Cộng Đồng** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - fine-tuning cho Mô Hình Ngôn Ngữ Nhỏ                                                   | Gặp gỡ [Phi-2](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst), mô hình nhỏ mới của Microsoft, mạnh mẽ nhưng gọn nhẹ. Hướng dẫn này sẽ dẫn bạn qua quá trình fine-tuning Phi-2, trình diễn cách xây dựng tập dữ liệu độc đáo và fine-tune mô hình bằng QLoRA.                                                                                                                                                                       |
| **Hướng dẫn Hugging Face** [Cách Fine-Tune LLMs trong 2024 với Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | Bài viết blog này hướng dẫn bạn cách fine-tune LLMs mở bằng Hugging Face TRL, Transformers & datasets trong năm 2024. Bạn định nghĩa một trường hợp sử dụng, thiết lập môi trường phát triển, chuẩn bị tập dữ liệu, fine-tune mô hình, kiểm tra-đánh giá nó, sau đó triển khai nó vào sản xuất.                                                                                                                                                                                                                                                                |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                            | Mang lại việc huấn luyện và triển khai nhanh hơn và dễ dàng hơn [các mô hình học máy tiên tiến](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst). Repo có các hướng dẫn thân thiện với Colab cùng với video hướng dẫn trên YouTube, cho fine-tuning. **Phản ánh cập nhật gần đây [local-first](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst)** . Đọc tài liệu [AutoTrain](https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst) |
|                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |

**Tuyên bố miễn trừ trách nhiệm**:  
Tài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ bản địa nên được coi là nguồn chính thức. Đối với thông tin quan trọng, nên sử dụng dịch vụ dịch thuật chuyên nghiệp của con người. Chúng tôi không chịu trách nhiệm về bất kỳ sự hiểu lầm hoặc diễn giải sai nào phát sinh từ việc sử dụng bản dịch này.