<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5466bcedc3c75aa35476270362f626a",
  "translation_date": "2025-05-20T01:53:35+00:00",
  "source_file": "15-rag-and-vector-databases/data/frameworks.md",
  "language_code": "hi"
}
-->
# न्यूरल नेटवर्क फ्रेमवर्क्स

जैसा कि हमने पहले ही सीख लिया है, न्यूरल नेटवर्क्स को कुशलता से प्रशिक्षित करने के लिए हमें दो काम करने की आवश्यकता है:

* टेन्सर्स पर ऑपरेट करना, जैसे कि गुणा, जोड़ना, और कुछ फंक्शन्स जैसे सिग्मॉइड या सॉफ्टमैक्स की गणना करना
* सभी एक्सप्रेशन्स के ग्रेडिएंट्स की गणना करना, ताकि ग्रेडिएंट डिसेंट ऑप्टिमाइजेशन किया जा सके

हालांकि `numpy` लाइब्रेरी पहला हिस्सा कर सकती है, हमें ग्रेडिएंट्स की गणना के लिए कुछ तंत्र की आवश्यकता है। हमारे फ्रेमवर्क में, जिसे हमने पिछले सेक्शन में विकसित किया था, हमें `backward` मेथड के अंदर सभी डेरिवेटिव फंक्शन्स को मैन्युअली प्रोग्राम करना पड़ा, जो बैकप्रोपेगेशन करता है। आदर्श रूप से, एक फ्रेमवर्क हमें *किसी भी एक्सप्रेशन* के ग्रेडिएंट्स की गणना करने का अवसर देना चाहिए जिसे हम परिभाषित कर सकते हैं।

एक और महत्वपूर्ण बात है GPU या किसी अन्य विशेष कंप्यूट यूनिट, जैसे TPU पर गणनाएं करने में सक्षम होना। डीप न्यूरल नेटवर्क प्रशिक्षण के लिए *बहुत सारी* गणनाओं की आवश्यकता होती है, और इन गणनाओं को GPUs पर समानांतर करने में सक्षम होना बहुत महत्वपूर्ण है।

> ✅ शब्द 'parallelize' का मतलब है गणनाओं को कई उपकरणों पर वितरित करना।

वर्तमान में, दो सबसे लोकप्रिय न्यूरल फ्रेमवर्क हैं: TensorFlow और PyTorch। दोनों CPU और GPU पर टेन्सर्स के साथ ऑपरेट करने के लिए एक लो-लेवल API प्रदान करते हैं। लो-लेवल API के ऊपर, एक हाई-लेवल API भी है, जिसे क्रमशः Keras और PyTorch Lightning कहा जाता है।

लो-लेवल API | TensorFlow | PyTorch
--------------|-------------------------------------|--------------------------------
हाई-लेवल API | Keras | PyTorch Lightning

**लो-लेवल APIs** दोनों फ्रेमवर्क्स में आपको **कंप्यूटेशनल ग्राफ्स** बनाने की अनुमति देते हैं। यह ग्राफ परिभाषित करता है कि दिए गए इनपुट पैरामीटर्स के साथ आउटपुट (आमतौर पर लॉस फंक्शन) कैसे गणना की जाए, और अगर GPU उपलब्ध है तो इसे गणना के लिए पुश किया जा सकता है। इस कंप्यूटेशनल ग्राफ को डिफरेंशिएट करने और ग्रेडिएंट्स की गणना करने के लिए फंक्शन्स हैं, जिन्हें फिर मॉडल पैरामीटर्स को ऑप्टिमाइज़ करने के लिए इस्तेमाल किया जा सकता है।

**हाई-लेवल APIs** न्यूरल नेटवर्क्स को **लेयर्स के सीक्वेंस** के रूप में मानते हैं, और अधिकांश न्यूरल नेटवर्क्स को बनाना बहुत आसान बना देते हैं। मॉडल को प्रशिक्षित करने के लिए आमतौर पर डेटा तैयार करने और फिर `fit` फंक्शन को कॉल करने की आवश्यकता होती है।

हाई-लेवल API आपको सामान्य न्यूरल नेटवर्क्स को बहुत जल्दी बनाने की अनुमति देता है बिना बहुत सारे विवरणों की चिंता किए। साथ ही, लो-लेवल API प्रशिक्षण प्रक्रिया पर अधिक नियंत्रण प्रदान करते हैं, और इसलिए उन्हें रिसर्च में बहुत इस्तेमाल किया जाता है, जब आप नए न्यूरल नेटवर्क आर्किटेक्चर्स के साथ काम कर रहे होते हैं।

यह समझना भी महत्वपूर्ण है कि आप दोनों APIs को साथ में इस्तेमाल कर सकते हैं, जैसे कि आप अपनी खुद की नेटवर्क लेयर आर्किटेक्चर लो-लेवल API का उपयोग करके विकसित कर सकते हैं, और फिर इसे हाई-लेवल API के साथ बनाए और प्रशिक्षित किए गए बड़े नेटवर्क के अंदर इस्तेमाल कर सकते हैं। या आप हाई-लेवल API का उपयोग करके लेयर्स के सीक्वेंस के रूप में एक नेटवर्क परिभाषित कर सकते हैं, और फिर अपने खुद के लो-लेवल प्रशिक्षण लूप का उपयोग करके ऑप्टिमाइजेशन कर सकते हैं। दोनों APIs समान बुनियादी अवधारणाओं का उपयोग करते हैं, और उन्हें एक साथ अच्छे से काम करने के लिए डिज़ाइन किया गया है।

## सीखना

इस कोर्स में, हम PyTorch और TensorFlow दोनों के लिए अधिकांश सामग्री प्रदान करते हैं। आप अपने पसंदीदा फ्रेमवर्क को चुन सकते हैं और केवल संबंधित नोटबुक्स के माध्यम से जा सकते हैं। यदि आप सुनिश्चित नहीं हैं कि कौन सा फ्रेमवर्क चुनना है, तो इंटरनेट पर **PyTorch vs. TensorFlow** के बारे में कुछ चर्चाएँ पढ़ें। आप बेहतर समझ प्राप्त करने के लिए दोनों फ्रेमवर्क्स को भी देख सकते हैं।

जहाँ संभव होगा, हम सरलता के लिए हाई-लेवल APIs का उपयोग करेंगे। हालांकि, हम मानते हैं कि न्यूरल नेटवर्क्स कैसे काम करते हैं इसे जमीनी स्तर से समझना महत्वपूर्ण है, इसलिए शुरुआत में हम लो-लेवल API और टेन्सर्स के साथ काम करके शुरू करते हैं। हालांकि, यदि आप जल्दी से आगे बढ़ना चाहते हैं और इन विवरणों को सीखने में ज्यादा समय नहीं बिताना चाहते हैं, तो आप इन्हें छोड़ सकते हैं और सीधे हाई-लेवल API नोटबुक्स में जा सकते हैं।

## ✍️ अभ्यास: फ्रेमवर्क्स

निम्नलिखित नोटबुक्स में अपनी सीखना जारी रखें:

लो-लेवल API | TensorFlow+Keras नोटबुक | PyTorch
--------------|-------------------------------------|--------------------------------
हाई-लेवल API | Keras | *PyTorch Lightning*

फ्रेमवर्क्स में महारत हासिल करने के बाद, ओवरफिटिंग की धारणा को फिर से समझें।

# ओवरफिटिंग

ओवरफिटिंग मशीन लर्निंग में एक अत्यंत महत्वपूर्ण अवधारणा है, और इसे सही ढंग से समझना बहुत महत्वपूर्ण है!

5 डॉट्स (जो `x` द्वारा ग्राफ्स में दर्शाए गए हैं) को अनुमानित करने की निम्नलिखित समस्या पर विचार करें:

!linear | overfit
-------------------------|--------------------------
**लाइनियर मॉडल, 2 पैरामीटर्स** | **नॉन-लाइनियर मॉडल, 7 पैरामीटर्स**
प्रशिक्षण त्रुटि = 5.3 | प्रशिक्षण त्रुटि = 0
मान्यकरण त्रुटि = 5.1 | मान्यकरण त्रुटि = 20

* बाईं ओर, हम एक अच्छी सीधी रेखा का अनुमान देखते हैं। क्योंकि पैरामीटर्स की संख्या पर्याप्त है, मॉडल पॉइंट वितरण के पीछे के विचार को सही तरीके से समझता है।
* दाईं ओर, मॉडल बहुत शक्तिशाली है। क्योंकि हमारे पास केवल 5 पॉइंट्स हैं और मॉडल के पास 7 पैरामीटर्स हैं, यह सभी पॉइंट्स के माध्यम से पास होने के लिए समायोजित कर सकता है, जिससे प्रशिक्षण त्रुटि 0 हो जाती है। हालांकि, इससे मॉडल डेटा के पीछे सही पैटर्न को समझने से रोकता है, इसलिए मान्यकरण त्रुटि बहुत अधिक है।

यह मॉडल की समृद्धता (पैरामीटर्स की संख्या) और प्रशिक्षण नमूनों की संख्या के बीच सही संतुलन बनाना बहुत महत्वपूर्ण है।

## क्यों ओवरफिटिंग होती है

  * पर्याप्त प्रशिक्षण डेटा नहीं
  * बहुत शक्तिशाली मॉडल
  * इनपुट डेटा में बहुत अधिक शोर

## ओवरफिटिंग का पता कैसे लगाएं

जैसा कि आप ऊपर दिए गए ग्राफ से देख सकते हैं, ओवरफिटिंग का पता बहुत कम प्रशिक्षण त्रुटि और उच्च मान्यकरण त्रुटि द्वारा लगाया जा सकता है। आमतौर पर प्रशिक्षण के दौरान हम देखेंगे कि प्रशिक्षण और मान्यकरण त्रुटियाँ दोनों कम होने लगती हैं, और फिर किसी बिंदु पर मान्यकरण त्रुटि कम होना बंद कर सकती है और बढ़ने लग सकती है। यह ओवरफिटिंग का संकेत होगा, और संकेतक होगा कि हमें शायद इस बिंदु पर प्रशिक्षण रोकना चाहिए (या कम से कम मॉडल का स्नैपशॉट लेना चाहिए)।

ओवरफिटिंग

## ओवरफिटिंग को कैसे रोकें

यदि आप देख सकते हैं कि ओवरफिटिंग हो रही है, तो आप निम्नलिखित में से एक कर सकते हैं:

 * प्रशिक्षण डेटा की मात्रा बढ़ाएँ
 * मॉडल की जटिलता कम करें
 * कुछ नियमितीकरण तकनीक का उपयोग करें, जैसे कि ड्रॉपआउट, जिसे हम बाद में विचार करेंगे।

## ओवरफिटिंग और बायस-वैरियंस ट्रेडऑफ

ओवरफिटिंग वास्तव में सांख्यिकी में एक अधिक सामान्य समस्या का मामला है जिसे बायस-वैरियंस ट्रेडऑफ कहा जाता है। यदि हम अपने मॉडल में त्रुटि के संभावित स्रोतों पर विचार करें, तो हम दो प्रकार की त्रुटियाँ देख सकते हैं:

* **बायस त्रुटियाँ** हमारे एल्गोरिदम के कारण होती हैं जो प्रशिक्षण डेटा के बीच संबंध को सही ढंग से कैप्चर नहीं कर पाती हैं। यह तथ्य से हो सकता है कि हमारा मॉडल पर्याप्त शक्तिशाली नहीं है (**अंडरफिटिंग**).
* **वैरियंस त्रुटियाँ**, जो इनपुट डेटा में शोर को अर्थपूर्ण संबंध के बजाय मॉडल द्वारा अनुमानित करने के कारण होती हैं (**ओवरफिटिंग**).

प्रशिक्षण के दौरान, बायस त्रुटि कम होती है (जैसे कि हमारा मॉडल डेटा का अनुमान लगाना सीखता है), और वैरियंस त्रुटि बढ़ती है। ओवरफिटिंग को रोकने के लिए प्रशिक्षण को रोकना महत्वपूर्ण है - या तो मैन्युअली (जब हम ओवरफिटिंग का पता लगाते हैं) या स्वचालित रूप से (नियमितीकरण का परिचय देकर)।

## निष्कर्ष

इस पाठ में, आपने दो सबसे लोकप्रिय AI फ्रेमवर्क्स, TensorFlow और PyTorch के विभिन्न APIs के बीच के अंतर के बारे में सीखा। इसके अलावा, आपने एक बहुत महत्वपूर्ण विषय, ओवरफिटिंग के बारे में सीखा।

## 🚀 चुनौती

संबंधित नोटबुक्स में, आप 'टास्क्स' नीचे पाएंगे; नोटबुक्स के माध्यम से काम करें और टास्क्स को पूरा करें।

## समीक्षा और आत्म-अध्ययन

निम्नलिखित विषयों पर कुछ शोध करें:

- TensorFlow
- PyTorch
- ओवरफिटिंग

अपने आप से निम्नलिखित प्रश्न पूछें:

- TensorFlow और PyTorch के बीच क्या अंतर है?
- ओवरफिटिंग और अंडरफिटिंग के बीच क्या अंतर है?

## असाइनमेंट

इस प्रयोगशाला में, आपसे PyTorch या TensorFlow का उपयोग करके सिंगल- और मल्टी-लेयर्ड पूरी तरह से कनेक्टेड नेटवर्क्स का उपयोग करके दो वर्गीकरण समस्याओं को हल करने के लिए कहा जाता है।

**अस्वीकरण**:  
इस दस्तावेज़ का अनुवाद AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके किया गया है। जबकि हम सटीकता के लिए प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियाँ या अशुद्धियाँ हो सकती हैं। मूल भाषा में मूल दस्तावेज़ को आधिकारिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।