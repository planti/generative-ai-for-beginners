<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:32:46+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "hi"
}
-->
# स्व-निर्देशित शिक्षण के लिए संसाधन

यह पाठ OpenAI और Azure OpenAI के कई मुख्य संसाधनों का उपयोग करके बनाया गया था, जो शब्दावली और ट्यूटोरियल के लिए संदर्भ के रूप में काम करते हैं। यहां एक गैर-व्यापक सूची दी गई है, जो आपके स्वयं के स्व-निर्देशित शिक्षण यात्रा के लिए है।

## 1. प्राथमिक संसाधन

| शीर्षक/लिंक                                                                                                                                                                                                                   | विवरण                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [OpenAI मॉडल्स के साथ फाइन-ट्यूनिंग](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                       | फाइन-ट्यूनिंग कुछ-शॉट लर्निंग को बेहतर बनाता है, कई अधिक उदाहरणों पर प्रशिक्षण देकर जो प्रॉम्प्ट में फिट हो सकते हैं, जिससे लागत बचती है, प्रतिक्रिया की गुणवत्ता में सुधार होता है और कम विलंबता अनुरोधों को सक्षम बनाता है। **OpenAI से फाइन-ट्यूनिंग का अवलोकन प्राप्त करें।**                                                                                    |
| [Azure OpenAI के साथ फाइन-ट्यूनिंग क्या है?](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                   | समझें **फाइन-ट्यूनिंग क्या है (अवधारणा)**, आपको इसे क्यों देखना चाहिए (प्रेरणादायक समस्या), किस डेटा का उपयोग करना है (प्रशिक्षण) और गुणवत्ता का मापन करना                                                                                                                                                                           |
| [फाइन-ट्यूनिंग के साथ मॉडल को कस्टमाइज़ करें](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst) | Azure OpenAI सेवा आपको हमारे मॉडलों को आपके व्यक्तिगत डेटासेट्स के अनुसार फाइन-ट्यूनिंग के माध्यम से अनुकूलित करने देती है। जानें **कैसे फाइन-ट्यूनिंग करें (प्रक्रिया)**, Azure AI स्टूडियो, पायथन SDK या REST API का उपयोग करके चयनित मॉडलों को चुनें।                                                                                                                                |
| [LLM फाइन-ट्यूनिंग के लिए सिफारिशें](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                    | LLMs विशेष डोमेन, कार्यों, या डेटासेट्स पर अच्छा प्रदर्शन नहीं कर सकते हैं, या गलत या भ्रामक आउटपुट उत्पन्न कर सकते हैं। **आपको फाइन-ट्यूनिंग पर विचार कब करना चाहिए** इस समस्या का संभावित समाधान के रूप में?                                                                                                                                  |
| [निरंतर फाइन ट्यूनिंग](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)             | निरंतर फाइन-ट्यूनिंग एक पहले से फाइन-ट्यून किए गए मॉडल को आधार मॉडल के रूप में चुनने और **इसे आगे फाइन-ट्यूनिंग** करने की पुनरावृत्त प्रक्रिया है।                                                                                                                                                     |
| [फाइन-ट्यूनिंग और फंक्शन कॉलिंग](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                       | आपके मॉडल को **फंक्शन कॉलिंग उदाहरणों के साथ फाइन-ट्यूनिंग करना** मॉडल आउटपुट में सुधार कर सकता है, अधिक सटीक और सुसंगत आउटपुट प्राप्त करके - समान रूप से स्वरूपित प्रतिक्रियाओं और लागत-बचत के साथ                                                                                                                                        |
| [फाइन-ट्यूनिंग मॉडल्स: Azure OpenAI मार्गदर्शन](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                                        | इस तालिका को देखें कि **कौन से मॉडल्स को Azure OpenAI में फाइन-ट्यून किया जा सकता है**, और ये कौन से क्षेत्रों में उपलब्ध हैं। यदि आवश्यक हो तो उनके टोकन सीमाएं और प्रशिक्षण डेटा समाप्ति तिथियां देखें।                                                                                                                            |
| [फाइन ट्यून करना या नहीं करना? यही सवाल है](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                      | AI शो का यह 30-मिनट का **अक्टूबर 2023** एपिसोड लाभ, नुकसान और व्यावहारिक अंतर्दृष्टियों पर चर्चा करता है जो आपको इस निर्णय को लेने में मदद करता है।                                                                                                                                                                                        |
| [LLM फाइन-ट्यूनिंग के साथ शुरुआत करना](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                             | यह **AI प्लेबुक** संसाधन आपको डेटा आवश्यकताओं, स्वरूपण, हाइपरपैरामीटर फाइन-ट्यूनिंग और चुनौतियों/सीमाओं के माध्यम से मार्गदर्शन करता है जिन्हें आपको जानना चाहिए।                                                                                                                                                                         |
| **ट्यूटोरियल**: [Azure OpenAI GPT3.5 Turbo फाइन-ट्यूनिंग](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                                  | एक नमूना फाइन-ट्यूनिंग डेटासेट बनाने, फाइन-ट्यूनिंग के लिए तैयारी करने, एक फाइन-ट्यूनिंग जॉब बनाने और Azure पर फाइन-ट्यून किए गए मॉडल को तैनात करने के लिए सीखें।                                                                                                                                                                                    |
| **ट्यूटोरियल**: [Azure AI स्टूडियो में Llama 2 मॉडल को फाइन-ट्यून करें](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                                      | Azure AI स्टूडियो आपको बड़े भाषा मॉडल्स को आपके व्यक्तिगत डेटासेट्स के अनुसार _एक UI-आधारित वर्कफ़्लो का उपयोग करके, जो कम-कोड डेवलपर्स के लिए उपयुक्त है_। इस उदाहरण को देखें।                                                                                                                                                               |
| **ट्यूटोरियल**:[Azure पर एकल GPU के लिए Hugging Face मॉडल्स को फाइन-ट्यून करें](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)               | यह लेख बताता है कि Azure DataBricks + Hugging Face Trainer लाइब्रेरी के साथ Hugging Face मॉडल को एकल GPU पर Hugging Face ट्रांसफॉर्मर्स लाइब्रेरी के साथ कैसे फाइन-ट्यून करें।                                                                                                                                                |
| **प्रशिक्षण:** [Azure Machine Learning के साथ एक फाउंडेशन मॉडल को फाइन-ट्यून करें](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)         | Azure Machine Learning में मॉडल कैटलॉग कई ओपन सोर्स मॉडल्स प्रदान करता है जिन्हें आप अपने विशिष्ट कार्य के लिए फाइन-ट्यून कर सकते हैं। यह मॉड्यूल आज़माएं [AzureML जनरेटिव AI लर्निंग पाथ से](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst) |
| **ट्यूटोरियल:** [Azure OpenAI फाइन-ट्यूनिंग](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                | Microsoft Azure पर W&B का उपयोग करके GPT-3.5 या GPT-4 मॉडल्स को फाइन-ट्यून करना मॉडल प्रदर्शन का विस्तृत ट्रैकिंग और विश्लेषण की अनुमति देता है। यह गाइड Azure OpenAI के लिए विशिष्ट चरणों और सुविधाओं के साथ OpenAI फाइन-ट्यूनिंग गाइड की अवधारणाओं का विस्तार करता है।                                                                         |
|                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                               |

## 2. द्वितीयक संसाधन

यह अनुभाग अतिरिक्त संसाधनों को शामिल करता है जो अन्वेषण के योग्य हैं, लेकिन जिन्हें हमने इस पाठ में कवर करने के लिए समय नहीं पाया। उन्हें भविष्य के पाठ में या बाद की तिथि में एक द्वितीयक असाइनमेंट विकल्प के रूप में शामिल किया जा सकता है। फिलहाल, इस विषय के चारों ओर अपनी विशेषज्ञता और ज्ञान बनाने के लिए उनका उपयोग करें।

| शीर्षक/लिंक                                                                                                                                                                                                            | विवरण                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI कुकबुक**: [चैट मॉडल फाइन-ट्यूनिंग के लिए डेटा तैयारी और विश्लेषण](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                                      | यह नोटबुक चैट मॉडल को फाइन-ट्यून करने के लिए उपयोग किए जाने वाले चैट डेटासेट को पूर्व-प्रसंस्करण और विश्लेषण करने के लिए एक उपकरण के रूप में कार्य करता है। यह स्वरूप त्रुटियों की जांच करता है, बुनियादी सांख्यिकी प्रदान करता है, और फाइन-ट्यूनिंग लागतों के लिए टोकन गणना का अनुमान लगाता है। देखें: [gpt-3.5-turbo के लिए फाइन-ट्यूनिंग विधि](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)।                                                                                                                                                                   |
| **OpenAI कुकबुक**: [Qdrant के साथ रिट्रीवल ऑगमेंटेड जनरेशन (RAG) के लिए फाइन-ट्यूनिंग](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst) | इस नोटबुक का उद्देश्य रिट्रीवल ऑगमेंटेड जनरेशन (RAG) के लिए OpenAI मॉडल्स को फाइन-ट्यून करने के एक व्यापक उदाहरण के माध्यम से मार्गदर्शन करना है। हम Qdrant और Few-Shot Learning को भी एकीकृत करेंगे ताकि मॉडल प्रदर्शन को बढ़ावा मिल सके और गलतियों को कम किया जा सके।                                                                                                                                                                                                                                                                |
| **OpenAI कुकबुक**: [Weights & Biases के साथ GPT को फाइन-ट्यूनिंग](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                             | Weights & Biases (W&B) AI डेवलपर प्लेटफॉर्म है, जिसमें मॉडल्स को प्रशिक्षण देने, फाइन-ट्यूनिंग करने, और फाउंडेशन मॉडल्स का लाभ उठाने के उपकरण हैं। पहले उनका [OpenAI फाइन-ट्यूनिंग](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst) गाइड पढ़ें, फिर कुकबुक अभ्यास आजमाएं।                                                                                                                                                                                                                  |
| **समुदाय ट्यूटोरियल** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - छोटे भाषा मॉडल्स के लिए फाइन-ट्यूनिंग                                                   | [Phi-2](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst), Microsoft का नया छोटा मॉडल, मिलिए, जो आश्चर्यजनक रूप से शक्तिशाली है फिर भी कॉम्पैक्ट है। यह ट्यूटोरियल आपको Phi-2 को फाइन-ट्यूनिंग करने के माध्यम से मार्गदर्शन करेगा, यह दिखाते हुए कि कैसे एक अद्वितीय डेटासेट बनाया जाए और QLoRA का उपयोग करके मॉडल को फाइन-ट्यून किया जाए।                                                                                                                                                                       |
| **Hugging Face ट्यूटोरियल** [2024 में Hugging Face के साथ LLMs को फाइन-ट्यून कैसे करें](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | यह ब्लॉग पोस्ट आपको 2024 में Hugging Face TRL, ट्रांसफॉर्मर्स और डेटासेट्स का उपयोग करके खुले LLMs को फाइन-ट्यून करने के तरीके के माध्यम से मार्गदर्शन करता है। आप एक उपयोग केस को परिभाषित करते हैं, एक डेवलपमेंट वातावरण सेट करते हैं, एक डेटासेट तैयार करते हैं, मॉडल को फाइन-ट्यून करते हैं, इसे परीक्षण-आकलन करते हैं, फिर इसे उत्पादन में तैनात करते हैं।                                                                                                                                                                                                                                                                |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                            | [स्टेट-ऑफ-द-आर्ट मशीन लर्निंग मॉडल्स](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst) के तेजी से और आसान प्रशिक्षण और तैनाती लाता है। रेपो में YouTube वीडियो मार्गदर्शन के साथ कोलाब-फ्रेंडली ट्यूटोरियल्स हैं, फाइन-ट्यूनिंग के लिए। **हाल ही के [लोकल-फर्स्ट](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst) अपडेट को दर्शाता है**। [AutoTrain दस्तावेज़ीकरण](https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst) पढ़ें। |
|                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवादों में त्रुटियाँ या अशुद्धियाँ हो सकती हैं। मूल दस्तावेज़ को उसकी मूल भाषा में आधिकारिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम जिम्मेदार नहीं हैं।