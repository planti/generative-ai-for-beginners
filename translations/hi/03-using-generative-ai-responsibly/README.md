<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "13084c6321a2092841b9a081b29497ba",
  "translation_date": "2025-05-19T09:29:48+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "hi"
}
-->
# जिम्मेदारी से जनरेटिव एआई का उपयोग करना

> _इस पाठ के वीडियो को देखने के लिए ऊपर की छवि पर क्लिक करें_

एआई और विशेष रूप से जनरेटिव एआई से प्रभावित होना आसान है, लेकिन आपको यह सोचना होगा कि आप इसे जिम्मेदारी से कैसे उपयोग करेंगे। आपको यह विचार करना होगा कि कैसे यह सुनिश्चित करें कि आउटपुट निष्पक्ष, अहानिकर हो और अन्य चीजें भी। यह अध्याय आपको दिए गए संदर्भ, क्या विचार करना है, और आपके एआई उपयोग को सुधारने के लिए सक्रिय कदम कैसे उठाने हैं, प्रदान करने का प्रयास करता है।

## परिचय

यह पाठ शामिल करेगा:

- जनरेटिव एआई अनुप्रयोग बनाते समय जिम्मेदार एआई को प्राथमिकता क्यों दें।
- जिम्मेदार एआई के मुख्य सिद्धांत और वे जनरेटिव एआई से कैसे संबंधित हैं।
- रणनीति और उपकरणों के माध्यम से इन जिम्मेदार एआई सिद्धांतों को कैसे व्यवहार में लाएं।

## सीखने के लक्ष्य

इस पाठ को पूरा करने के बाद आप जानेंगे:

- जनरेटिव एआई अनुप्रयोग बनाते समय जिम्मेदार एआई का महत्व।
- जनरेटिव एआई अनुप्रयोग बनाते समय जिम्मेदार एआई के मुख्य सिद्धांतों को कब सोचना और लागू करना चाहिए।
- जिम्मेदार एआई की अवधारणा को व्यवहार में लाने के लिए आपके लिए कौन से उपकरण और रणनीतियाँ उपलब्ध हैं।

## जिम्मेदार एआई सिद्धांत

जनरेटिव एआई का उत्साह कभी इतना अधिक नहीं रहा। इस उत्साह ने इस क्षेत्र में कई नए डेवलपर्स, ध्यान और वित्त पोषण लाया है। जबकि यह जनरेटिव एआई का उपयोग करके उत्पाद और कंपनियां बनाने के लिए किसी के लिए बहुत सकारात्मक है, यह भी महत्वपूर्ण है कि हम जिम्मेदारी से आगे बढ़ें।

इस कोर्स में, हम अपने स्टार्टअप और हमारे एआई शिक्षा उत्पाद को बनाने पर ध्यान केंद्रित कर रहे हैं। हम जिम्मेदार एआई के सिद्धांतों का उपयोग करेंगे: निष्पक्षता, समावेशिता, विश्वसनीयता/सुरक्षा, सुरक्षा और गोपनीयता, पारदर्शिता और जवाबदेही। इन सिद्धांतों के साथ, हम यह अन्वेषण करेंगे कि वे हमारे उत्पादों में जनरेटिव एआई के उपयोग से कैसे संबंधित हैं।

## आपको जिम्मेदार एआई को प्राथमिकता क्यों देनी चाहिए

एक उत्पाद बनाते समय, अपने उपयोगकर्ता के सर्वोत्तम हित को ध्यान में रखते हुए मानव-केंद्रित दृष्टिकोण अपनाने से सर्वोत्तम परिणाम मिलते हैं।

जनरेटिव एआई की विशिष्टता इसकी क्षमता है कि यह उपयोगकर्ताओं के लिए सहायक उत्तर, जानकारी, मार्गदर्शन और सामग्री बना सकता है। यह बिना कई मैनुअल चरणों के किया जा सकता है, जो बहुत प्रभावशाली परिणाम दे सकता है। उचित योजना और रणनीतियों के बिना, यह दुर्भाग्य से आपके उपयोगकर्ताओं, आपके उत्पाद और पूरे समाज के लिए कुछ हानिकारक परिणाम दे सकता है।

आइए कुछ (लेकिन सभी नहीं) इन संभावित हानिकारक परिणामों को देखें:

### भ्रम

भ्रम एक शब्द है जो तब उपयोग किया जाता है जब एक LLM ऐसी सामग्री उत्पन्न करता है जो या तो पूरी तरह से निरर्थक होती है या कुछ ऐसा होता है जिसे हम अन्य सूचना स्रोतों के आधार पर तथ्यात्मक रूप से गलत जानते हैं।

मान लीजिए कि हम अपने स्टार्टअप के लिए एक फीचर बनाते हैं जो छात्रों को एक मॉडल से ऐतिहासिक प्रश्न पूछने की अनुमति देता है। एक छात्र प्रश्न पूछता है `Who was the sole survivor of Titanic?`

मॉडल एक उत्तर उत्पन्न करता है जैसे कि नीचे दिया गया है:

यह एक बहुत ही आत्मविश्वासी और विस्तृत उत्तर है। दुर्भाग्य से, यह गलत है। न्यूनतम शोध के साथ भी, कोई यह पता लगा सकता है कि टाइटैनिक आपदा के एक से अधिक जीवित बचे थे। एक छात्र के लिए जो इस विषय पर शोध करना शुरू कर रहा है, यह उत्तर इतना प्रभावशाली हो सकता है कि इसे प्रश्न न किया जाए और तथ्य के रूप में माना जाए। इसके परिणामस्वरूप एआई प्रणाली अविश्वसनीय हो सकती है और हमारे स्टार्टअप की प्रतिष्ठा को नकारात्मक रूप से प्रभावित कर सकती है।

किसी भी दिए गए LLM के प्रत्येक पुनरावृत्ति के साथ, हमने भ्रम को कम करने के आसपास प्रदर्शन सुधार देखा है। इस सुधार के बावजूद, हमें अभी भी इन सीमाओं के प्रति जागरूक रहना चाहिए।

### हानिकारक सामग्री

हमने पहले के अनुभाग में कवर किया जब एक LLM गलत या निरर्थक प्रतिक्रियाएं उत्पन्न करता है। एक और जोखिम है जब एक मॉडल हानिकारक सामग्री के साथ प्रतिक्रिया करता है।

हानिकारक सामग्री को इस प्रकार परिभाषित किया जा सकता है:

- आत्म-हानि या कुछ समूहों को नुकसान पहुंचाने के निर्देश या प्रोत्साहन देना।
- घृणास्पद या अपमानजनक सामग्री।
- किसी भी प्रकार के हमले या हिंसक कृत्यों की योजना का मार्गदर्शन करना।
- अवैध सामग्री खोजने या अवैध कृत्य करने के निर्देश देना।
- यौन स्पष्ट सामग्री दिखाना।

हमारे स्टार्टअप के लिए, हम यह सुनिश्चित करना चाहते हैं कि हमारे पास सही उपकरण और रणनीतियाँ हों ताकि इस प्रकार की सामग्री छात्रों को न दिखाई दे।

### निष्पक्षता की कमी

निष्पक्षता को "सुनिश्चित करना कि एक एआई प्रणाली पूर्वाग्रह और भेदभाव से मुक्त है और वे सभी को निष्पक्ष और समान रूप से व्यवहार करते हैं।" जनरेटिव एआई की दुनिया में, हम यह सुनिश्चित करना चाहते हैं कि हाशिए पर रहने वाले समूहों के बहिष्करणीय विश्वदृष्टिकोण मॉडल के आउटपुट द्वारा सुदृढ़ नहीं किए गए हैं।

इन प्रकार के आउटपुट न केवल हमारे उपयोगकर्ताओं के लिए सकारात्मक उत्पाद अनुभव बनाने के लिए विनाशकारी हैं, बल्कि वे आगे सामाजिक नुकसान भी पहुंचाते हैं। अनुप्रयोग निर्माताओं के रूप में, हमें हमेशा एक व्यापक और विविध उपयोगकर्ता आधार को ध्यान में रखना चाहिए जब हम जनरेटिव एआई के साथ समाधान बना रहे हैं।

## जनरेटिव एआई का जिम्मेदारी से उपयोग कैसे करें

अब जब हमने जिम्मेदार जनरेटिव एआई के महत्व की पहचान कर ली है, आइए 4 चरणों को देखें जिन्हें हम अपने एआई समाधानों को जिम्मेदारी से बनाने के लिए उठा सकते हैं:

### संभावित हानियों को मापें

सॉफ़्टवेयर परीक्षण में, हम किसी एप्लिकेशन पर उपयोगकर्ता की अपेक्षित क्रियाओं का परीक्षण करते हैं। इसी तरह, उन विविध संकेतों का परीक्षण करना जो उपयोगकर्ता सबसे अधिक संभावना से उपयोग करेंगे, संभावित नुकसान को मापने का एक अच्छा तरीका है।

चूंकि हमारा स्टार्टअप एक शिक्षा उत्पाद बना रहा है, यह शिक्षा से संबंधित संकेतों की एक सूची तैयार करने के लिए अच्छा होगा। यह किसी निश्चित विषय, ऐतिहासिक तथ्यों और छात्र जीवन के बारे में संकेतों को कवर कर सकता है।

### संभावित हानियों को कम करें

अब यह समय है कि हम उन तरीकों को खोजें जहां हम मॉडल और इसकी प्रतिक्रियाओं से होने वाले संभावित नुकसान को रोक सकते हैं या सीमित कर सकते हैं। हम इसे 4 विभिन्न परतों में देख सकते हैं:

- **मॉडल**. सही उपयोग केस के लिए सही मॉडल का चयन करना। बड़े और अधिक जटिल मॉडल जैसे GPT-4 छोटे और अधिक विशिष्ट उपयोग मामलों में लागू होने पर हानिकारक सामग्री का अधिक जोखिम पैदा कर सकते हैं। अपने प्रशिक्षण डेटा का उपयोग करके फाइन-ट्यूनिंग करना भी हानिकारक सामग्री के जोखिम को कम करता है।

- **सुरक्षा प्रणाली**. एक सुरक्षा प्रणाली मॉडल की सेवा करने वाले प्लेटफ़ॉर्म पर उपकरणों और कॉन्फ़िगरेशन का एक सेट है जो नुकसान को कम करने में मदद करता है। इसका एक उदाहरण Azure OpenAI सेवा पर सामग्री फ़िल्टरिंग प्रणाली है। सिस्टम को जेलब्रेक हमलों और बॉट्स से अनुरोध जैसी अवांछित गतिविधि का भी पता लगाना चाहिए।

- **मेटाप्रॉम्प्ट**. मेटाप्रॉम्प्ट और ग्राउंडिंग तरीके हैं जिनके माध्यम से हम कुछ व्यवहारों और जानकारी के आधार पर मॉडल को निर्देशित या सीमित कर सकते हैं। यह मॉडल की कुछ सीमाओं को परिभाषित करने के लिए सिस्टम इनपुट का उपयोग कर सकता है। इसके अलावा, सिस्टम के दायरे या डोमेन के लिए अधिक प्रासंगिक आउटपुट प्रदान करना।

यह तकनीकों जैसे रिट्रीवल ऑग्मेंटेड जेनरेशन (RAG) का उपयोग करके भी हो सकता है ताकि मॉडल केवल चयनित विश्वसनीय स्रोतों से जानकारी प्राप्त कर सके। इस कोर्स में बाद में [खोज अनुप्रयोग बनाना](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst) के लिए एक पाठ है।

- **उपयोगकर्ता अनुभव**. अंतिम परत वह है जहां उपयोगकर्ता हमारे एप्लिकेशन के इंटरफ़ेस के माध्यम से किसी न किसी तरह से मॉडल के साथ सीधे बातचीत करता है। इस तरह हम UI/UX को डिज़ाइन कर सकते हैं ताकि उपयोगकर्ता को उन प्रकार के इनपुट पर सीमित किया जा सके जो वे मॉडल को भेज सकते हैं और उपयोगकर्ता को प्रदर्शित किए गए पाठ या छवियों के लिए। एआई एप्लिकेशन को तैनात करते समय, हमें यह भी पारदर्शी होना चाहिए कि हमारा जनरेटिव एआई एप्लिकेशन क्या कर सकता है और क्या नहीं कर सकता है।

हमारे पास [एआई अनुप्रयोगों के लिए UX डिज़ाइन करना](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst) पर एक पूरा पाठ है।

- **मॉडल का मूल्यांकन करें**. LLMs के साथ काम करना चुनौतीपूर्ण हो सकता है क्योंकि हमारे पास हमेशा उस डेटा पर नियंत्रण नहीं होता है जिस पर मॉडल को प्रशिक्षित किया गया था। फिर भी, हमें हमेशा मॉडल के प्रदर्शन और आउटपुट का मूल्यांकन करना चाहिए। यह मॉडल की सटीकता, समानता, ग्राउंडेडनेस और आउटपुट की प्रासंगिकता को मापना महत्वपूर्ण है। यह हितधारकों और उपयोगकर्ताओं को पारदर्शिता और विश्वास प्रदान करने में मदद करता है।

### जिम्मेदार जनरेटिव एआई समाधान का संचालन करें

अपने एआई अनुप्रयोगों के आसपास एक परिचालन अभ्यास का निर्माण अंतिम चरण है। इसमें कानूनी और सुरक्षा जैसे हमारे स्टार्टअप के अन्य हिस्सों के साथ साझेदारी करना शामिल है ताकि यह सुनिश्चित हो सके कि हम सभी नियामक नीतियों का पालन कर रहे हैं। लॉन्च से पहले, हम वितरण, घटनाओं को संभालने, और रोलबैक के आसपास योजनाएं भी बनाना चाहते हैं ताकि हमारे उपयोगकर्ताओं को किसी भी नुकसान से बचाया जा सके।

## उपकरण

जिम्मेदार एआई समाधान विकसित करने का काम भले ही बहुत अधिक लगे, यह प्रयास के लायक है। जैसे-जैसे जनरेटिव एआई का क्षेत्र बढ़ता है, डेवलपर्स को अपने वर्कफ़्लोज़ में जिम्मेदारी को प्रभावी ढंग से एकीकृत करने में मदद करने के लिए अधिक उपकरण परिपक्व होंगे। उदाहरण के लिए, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) एपीआई अनुरोध के माध्यम से हानिकारक सामग्री और छवियों का पता लगाने में मदद कर सकता है।

## ज्ञान की जाँच

जिम्मेदार एआई उपयोग सुनिश्चित करने के लिए आपको किन चीजों की परवाह करनी चाहिए?

1. कि उत्तर सही है।
2. हानिकारक उपयोग, कि एआई का आपराधिक उद्देश्यों के लिए उपयोग नहीं किया जा रहा है।
3. यह सुनिश्चित करना कि एआई पूर्वाग्रह और भेदभाव से मुक्त है।

उत्तर: 2 और 3 सही हैं। जिम्मेदार एआई आपको हानिकारक प्रभावों और पूर्वाग्रहों को कम करने के तरीकों पर विचार करने में मदद करता है।

## 🚀 चुनौती

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) पर पढ़ें और देखें कि आप अपने उपयोग के लिए क्या अपनाना चाहते हैं।

## शानदार काम, अपनी शिक्षा जारी रखें

इस पाठ को पूरा करने के बाद, हमारे [जनरेटिव एआई लर्निंग संग्रह](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) को देखें ताकि आप अपने जनरेटिव एआई ज्ञान को और बढ़ा सकें!

पाठ 4 की ओर बढ़ें जहां हम [प्रॉम्प्ट इंजीनियरिंग फंडामेंटल्स](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst) को देखेंगे!

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयासरत हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियाँ या अशुद्धियाँ हो सकती हैं। मूल दस्तावेज़ को उसकी मूल भाषा में प्राधिकृत स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।