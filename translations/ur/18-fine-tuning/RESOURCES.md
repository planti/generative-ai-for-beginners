<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:28:20+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "ur"
}
-->
# خود سیکھنے کے لیے وسائل

یہ سبق اوپن اے آئی اور ایزور اوپن اے آئی کے متعدد بنیادی وسائل کا استعمال کرتے ہوئے بنایا گیا ہے جو اصطلاحات اور ٹیوٹوریلز کے حوالے کے طور پر کام کرتے ہیں۔ یہاں ایک غیر جامع فہرست ہے، آپ کی خود سیکھنے کی مہمات کے لیے۔

## 1. بنیادی وسائل

| عنوان/لنک                                                                                                                                                                                                                   | وضاحت                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [OpenAI ماڈلز کے ساتھ فائن ٹیوننگ](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                       | فائن ٹیوننگ چند شاٹ لرننگ کو بہتر کرتی ہے کیونکہ یہ پرامپٹ میں فٹ ہونے والے بہت زیادہ مثالوں پر تربیت کرتی ہے، آپ کی لاگت بچاتی ہے، جواب کی کوالٹی بہتر کرتی ہے، اور کم تاخیر والی درخواستوں کو فعال کرتی ہے۔ **OpenAI سے فائن ٹیوننگ کا ایک جائزہ حاصل کریں۔**                                                                                    |
| [Azure OpenAI کے ساتھ فائن ٹیوننگ کیا ہے؟](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                   | سمجھیں **فائن ٹیوننگ کیا ہے (تصور)**، آپ کو اس پر کیوں غور کرنا چاہیے (محرک مسئلہ)، کس ڈیٹا کو استعمال کرنا ہے (تربیت) اور کوالٹی کی پیمائش کیسے کرنی ہے۔                                                                                                                                                                           |
| [فائن ٹیوننگ کے ساتھ ماڈل کو حسب ضرورت بنائیں](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst) | Azure OpenAI سروس آپ کو ہمارے ماڈلز کو اپنے ذاتی ڈیٹاسیٹس کے مطابق بنانے کی اجازت دیتی ہے۔ **کیسے فائن ٹیون کرنا ہے (عمل)** سیکھیں، Azure AI اسٹوڈیو، Python SDK یا REST API کا استعمال کرتے ہوئے منتخب ماڈلز۔                                                                                                                                |
| [LLM فائن ٹیوننگ کے لیے سفارشات](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                    | LLMs مخصوص ڈومینز، کاموں، یا ڈیٹاسیٹس پر اچھی کارکردگی نہیں دکھا سکتے ہیں، یا غلط یا گمراہ کن آؤٹ پٹس پیدا کر سکتے ہیں۔ **آپ کو کب فائن ٹیوننگ پر غور کرنا چاہیے** اس کا ممکنہ حل کے طور پر؟                                                                                                                                  |
| [مسلسل فائن ٹیوننگ](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)             | مسلسل فائن ٹیوننگ پہلے سے فائن ٹیون کیے گئے ماڈل کو بنیادی ماڈل کے طور پر منتخب کرنے اور **نئے تربیتی مثالوں کے سیٹ پر مزید فائن ٹیوننگ کرنے** کا تکراری عمل ہے۔                                                                                                                                                     |
| [فائن ٹیوننگ اور فنکشن کالنگ](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                       | اپنے ماڈل کو **فنکشن کالنگ مثالوں** کے ساتھ فائن ٹیون کرنا ماڈل آؤٹ پٹ کو بہتر بنا سکتا ہے، زیادہ درست اور مستقل آؤٹ پٹس حاصل کرکے - اسی طرح کے فارمیٹ کیے گئے جوابات اور لاگت کی بچت کے ساتھ۔                                                                                                                                        |
| [فائن ٹیوننگ ماڈلز: Azure OpenAI رہنمائی](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                                        | اس ٹیبل کو دیکھیں تاکہ سمجھ سکیں **کون سے ماڈلز Azure OpenAI میں فائن ٹیون کیے جا سکتے ہیں**، اور یہ کون سے علاقوں میں دستیاب ہیں۔ اگر ضرورت ہو تو ان کے ٹوکن کی حدود اور تربیتی ڈیٹا کی میعاد ختم ہونے کی تاریخوں کو دیکھیں۔                                                                                                                            |
| [فائن ٹیون کرنا یا نہ کرنا؟ یہی سوال ہے](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                      | AI شو کی یہ 30 منٹ **اکتوبر 2023** کی قسط فوائد، نقصانات اور عملی بصیرتوں پر گفتگو کرتی ہے جو آپ کو یہ فیصلہ کرنے میں مدد کرتی ہیں۔                                                                                                                                                                                        |
| [LLM فائن ٹیوننگ کے ساتھ شروع کرنا](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                             | یہ **AI Playbook** وسیلہ آپ کو ڈیٹا کی ضروریات، فارمیٹنگ، ہائپر پیرامیٹر فائن ٹیوننگ اور چیلنجز/حدود کے بارے میں رہنمائی کرتا ہے جن کے بارے میں آپ کو معلوم ہونا چاہیے۔                                                                                                                                                                         |
| **سبق**: [Azure OpenAI GPT3.5 ٹربو فائن ٹیوننگ](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                                  | ایک نمونہ فائن ٹیوننگ ڈیٹاسیٹ بنانے، فائن ٹیوننگ کی تیاری، فائن ٹیوننگ کا کام بنانے، اور Azure پر فائن ٹیون شدہ ماڈل کو تعینات کرنے کا طریقہ سیکھیں۔                                                                                                                                                                                    |
| **سبق**: [Azure AI اسٹوڈیو میں لاما 2 ماڈل کو فائن ٹیون کریں](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                                      | Azure AI اسٹوڈیو آپ کو بڑے زبان کے ماڈلز کو اپنے ذاتی ڈیٹاسیٹس کے مطابق بنانے کی اجازت دیتا ہے _ایک UI پر مبنی ورک فلو کا استعمال کرتے ہوئے جو کم کوڈ ڈویلپرز کے لیے موزوں ہے_۔ اس مثال کو دیکھیں۔                                                                                                                                                               |
| **سبق**:[Azure پر ایک واحد GPU کے لیے Hugging Face ماڈلز کو فائن ٹیون کریں](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)               | یہ مضمون Azure DataBricks + Hugging Face Trainer لائبریریوں کے ساتھ ایک واحد GPU پر Hugging Face ماڈل کو Hugging Face transformers لائبریری کے ساتھ فائن ٹیون کرنے کا طریقہ بیان کرتا ہے۔                                                                                                                                                |
| **تربیت:** [Azure Machine Learning کے ساتھ ایک بنیاد ماڈل کو فائن ٹیون کریں](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)         | Azure Machine Learning میں ماڈل کیٹلاگ بہت سے اوپن سورس ماڈلز پیش کرتا ہے جنہیں آپ اپنے مخصوص کام کے لیے فائن ٹیون کر سکتے ہیں۔ اس ماڈیول کو آزمانے کی کوشش کریں [AzureML جنریٹو AI لرننگ پاتھ سے](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst) |
| **سبق:** [Azure OpenAI فائن ٹیوننگ](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                | Microsoft Azure پر W&B کا استعمال کرتے ہوئے GPT-3.5 یا GPT-4 ماڈلز کو فائن ٹیون کرنا ماڈل کی کارکردگی کی تفصیلی ٹریکنگ اور تجزیہ کی اجازت دیتا ہے۔ یہ گائیڈ Azure OpenAI کے لیے مخصوص اقدامات اور خصوصیات کے ساتھ OpenAI فائن ٹیوننگ گائیڈ کے تصورات کو بڑھاتا ہے۔                                                                         |
|                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                               |

## 2. ثانوی وسائل

یہ سیکشن اضافی وسائل کو جمع کرتا ہے جو دریافت کرنے کے لائق ہیں، لیکن جنہیں ہم اس سبق میں کور کرنے کے لیے وقت نہیں رکھتے تھے۔ انہیں مستقبل کے سبق میں کور کیا جا سکتا ہے، یا کسی ثانوی اسائنمنٹ آپشن کے طور پر، بعد کی تاریخ میں۔ ابھی کے لیے، انہیں اس موضوع کے ارد گرد اپنی مہارت اور علم بنانے کے لیے استعمال کریں۔

| عنوان/لنک                                                                                                                                                                                                            | وضاحت                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI کوک بک**: [چیٹ ماڈل فائن ٹیوننگ کے لیے ڈیٹا کی تیاری اور تجزیہ](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                                      | یہ نوٹ بک چیٹ ماڈل کو فائن ٹیون کرنے کے لیے استعمال کیے جانے والے چیٹ ڈیٹاسیٹ کو پہلے سے پروسیس اور تجزیہ کرنے کے لیے ایک ٹول کے طور پر کام کرتا ہے۔ یہ فارمیٹ کی غلطیوں کی جانچ کرتا ہے، بنیادی اعدادوشمار فراہم کرتا ہے، اور فائن ٹیوننگ کے اخراجات کے لیے ٹوکن کی تعداد کا اندازہ لگاتا ہے۔ دیکھیں: [gpt-3.5-turbo کے لیے فائن ٹیوننگ کا طریقہ](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst).                                                                                                                                                                   |
| **OpenAI کوک بک**: [Retrieval Augmented Generation (RAG) کے لیے فائن ٹیوننگ Qdrant کے ساتھ](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst) | اس نوٹ بک کا مقصد یہ ہے کہ OpenAI ماڈلز کو Retrieval Augmented Generation (RAG) کے لیے فائن ٹیون کرنے کے ایک جامع مثال کے ذریعے چلنا ہے۔ ہم ماڈل کی کارکردگی کو بڑھانے اور جعلیات کو کم کرنے کے لیے Qdrant اور Few-Shot Learning کو بھی ضم کریں گے۔                                                                                                                                                                                                                                                                |
| **OpenAI کوک بک**: [Weights & Biases کے ساتھ GPT کو فائن ٹیوننگ](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                             | Weights & Biases (W&B) AI ڈویلپر پلیٹ فارم ہے، ماڈلز کی تربیت، ماڈلز کو فائن ٹیون کرنے، اور بنیادی ماڈلز کو استعمال کرنے کے لیے ٹولز کے ساتھ۔ ان کی [OpenAI فائن ٹیوننگ](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst) گائیڈ کو پہلے پڑھیں، پھر کوک بک کی مشق آزمائیں۔                                                                                                                                                                                                                  |
| **کمیونٹی سبق** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - چھوٹے زبان کے ماڈلز کے لیے فائن ٹیوننگ                                                   | ملیں [Phi-2](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst)، Microsoft کا نیا چھوٹا ماڈل، حیرت انگیز طور پر طاقتور لیکن کمپیکٹ۔ یہ سبق آپ کو Phi-2 کو فائن ٹیون کرنے کے ذریعے رہنمائی کرے گا، ایک منفرد ڈیٹاسیٹ بنانے اور ماڈل کو QLoRA کا استعمال کرتے ہوئے فائن ٹیون کرنے کا طریقہ دکھائے گا۔                                                                                                                                                                       |
| **Hugging Face سبق** [2024 میں Hugging Face کے ساتھ LLMs کو کیسے فائن ٹیون کریں](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | یہ بلاگ پوسٹ آپ کو Hugging Face TRL، Transformers & ڈیٹاسیٹس کا استعمال کرتے ہوئے اوپن LLMs کو فائن ٹیون کرنے کا طریقہ سکھاتی ہے۔ آپ ایک استعمال کیس کی وضاحت کرتے ہیں، ایک ڈیولپمنٹ ماحول تیار کرتے ہیں، ایک ڈیٹاسیٹ تیار کرتے ہیں، ماڈل کو فائن ٹیون کرتے ہیں، اس کی جانچ اور تشخیص کرتے ہیں، پھر اسے پروڈکشن میں تعینات کرتے ہیں۔                                                                                                                                                                                                                                                                |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                            | [جدید ترین مشین لرننگ ماڈلز](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst) کی تیز تر اور آسان تربیت اور تعیناتیاں لاتا ہے۔ ریپو میں یوٹیوب ویڈیو گائیڈنس کے ساتھ کولیب دوستانہ سبق شامل ہیں، فائن ٹیوننگ کے لیے۔ **حالیہ [لوکل-فرسٹ](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst) اپ ڈیٹ کی عکاسی کرتا ہے** . [AutoTrain دستاویزات](https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst) کو پڑھیں |
|                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |

**ڈس کلیمر**:
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ جبکہ ہم درستگی کے لیے کوشش کرتے ہیں، براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا بے ضابطگیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی مقامی زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔