<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f3cac698e9eea47dd563633bd82daf8c",
  "translation_date": "2025-05-19T22:37:45+00:00",
  "source_file": "13-securing-ai-applications/README.md",
  "language_code": "pa"
}
-->
# ਆਪਣੇ ਜਨਰੇਟਿਵ AI ਐਪਲੀਕੇਸ਼ਨ ਨੂੰ ਸੁਰੱਖਿਅਤ ਕਰਨਾ

## ਜਾਣ ਪਛਾਣ

ਇਸ ਪਾਠ ਵਿੱਚ ਇਹ ਸਮਝਾਇਆ ਜਾਵੇਗਾ:

- AI ਸਿਸਟਮਾਂ ਦੇ ਸੰਦਰਭ ਵਿੱਚ ਸੁਰੱਖਿਆ।
- AI ਸਿਸਟਮਾਂ ਲਈ ਆਮ ਜੋਖਮ ਅਤੇ ਧਮਕੀਆਂ।
- AI ਸਿਸਟਮਾਂ ਨੂੰ ਸੁਰੱਖਿਅਤ ਕਰਨ ਲਈ ਵਿਧੀਆਂ ਅਤੇ ਵਿਚਾਰ।

## ਸਿਖਣ ਦੇ ਲਕਸ਼

ਇਸ ਪਾਠ ਨੂੰ ਪੂਰਾ ਕਰਨ ਤੋਂ ਬਾਅਦ, ਤੁਸੀਂ ਇਹ ਸਮਝਣਾ ਪ੍ਰਾਪਤ ਕਰ ਲਵੋਗੇ:

- AI ਸਿਸਟਮਾਂ ਲਈ ਜੋਖਮ ਅਤੇ ਧਮਕੀਆਂ।
- AI ਸਿਸਟਮਾਂ ਨੂੰ ਸੁਰੱਖਿਅਤ ਕਰਨ ਲਈ ਆਮ ਵਿਧੀਆਂ ਅਤੇ ਅਭਿਆਸ।
- ਕਿਵੇਂ ਸੁਰੱਖਿਆ ਜਾਂਚ ਕਰਨ ਨਾਲ ਅਣਪਛਾਤੇ ਨਤੀਜੇ ਅਤੇ ਯੂਜ਼ਰ ਵਿਸ਼ਵਾਸ ਦੀ ਘਾਟ ਨੂੰ ਰੋਕਿਆ ਜਾ ਸਕਦਾ ਹੈ।

## ਜਨਰੇਟਿਵ AI ਦੇ ਸੰਦਰਭ ਵਿੱਚ ਸੁਰੱਖਿਆ ਦਾ ਕੀ ਮਤਲਬ ਹੈ?

ਜਿਵੇਂ ਜਿਵੇਂ ਕ੍ਰਿਤਰਿਮ ਬੁੱਧੀ (AI) ਅਤੇ ਮਸ਼ੀਨ ਲਰਨਿੰਗ (ML) ਤਕਨਾਲੋਜੀਆਂ ਸਾਡੇ ਜੀਵਨ ਨੂੰ ਵਧੇਰੇ ਪ੍ਰਭਾਵਿਤ ਕਰ ਰਹੀਆਂ ਹਨ, ਇਹ ਸਿਰਫ ਗਾਹਕ ਡਾਟਾ ਦੀ ਹੀ ਸੁਰੱਖਿਆ ਨਹੀਂ, ਸਗੋਂ AI ਸਿਸਟਮਾਂ ਦੀ ਵੀ ਸੁਰੱਖਿਆ ਕਰਨਾ ਮਹੱਤਵਪੂਰਨ ਹੈ। AI/ML ਦਾ ਉਪਯੋਗ ਉੱਚ ਮੁੱਲ ਵਾਲੇ ਫੈਸਲੇ ਕਰਨ ਵਾਲੇ ਪ੍ਰਕਿਰਿਆਵਾਂ ਵਿੱਚ ਵਧੇਰੇ ਹੋ ਰਿਹਾ ਹੈ, ਜਿੱਥੇ ਗਲਤ ਫੈਸਲੇ ਨਾਲ ਗੰਭੀਰ ਨਤੀਜੇ ਨਿਕਲ ਸਕਦੇ ਹਨ।

ਇਹ ਰਹੇ ਕੁਝ ਮੁੱਖ ਬਿੰਦੂ:

- **AI/ML ਦਾ ਪ੍ਰਭਾਵ**: AI/ML ਦਾ ਦਿਨ-ਪ੍ਰਤੀ-ਦਿਨ ਜੀਵਨ 'ਤੇ ਮਹੱਤਵਪੂਰਨ ਪ੍ਰਭਾਵ ਹੁੰਦਾ ਹੈ ਅਤੇ ਇਸ ਲਈ ਇਹਨਾਂ ਦੀ ਸੁਰੱਖਿਆ ਕਰਨਾ ਜਰੂਰੀ ਹੋ ਗਿਆ ਹੈ।
- **ਸੁਰੱਖਿਆ ਚੁਣੌਤੀਆਂ**: ਇਹ ਪ੍ਰਭਾਵ ਜੋ AI/ML ਦਾ ਹੈ, ਇਸ ਨੂੰ ਸਹੀ ਧਿਆਨ ਦੀ ਲੋੜ ਹੈ ਤਾਂ ਜੋ AI-ਅਧਾਰਤ ਉਤਪਾਦਾਂ ਨੂੰ trolls ਜਾਂ ਸੰਗਠਿਤ ਸਮੂਹਾਂ ਤੋਂ ਸੁਧਾਰਿਤ ਹਮਲਿਆਂ ਤੋਂ ਬਚਾਇਆ ਜਾ ਸਕੇ।
- **रणनीतिक ਸਮੱਸਿਆਵਾਂ**: ਟੈਕ ਉਦਯੋਗ ਨੂੰ ਲੰਬੇ ਸਮੇਂ ਤੱਕ ਗਾਹਕ ਦੀ ਸੁਰੱਖਿਆ ਅਤੇ ਡਾਟਾ ਸੁਰੱਖਿਆ ਨੂੰ ਯਕੀਨੀ ਬਣਾਉਣ ਲਈ ਰਣਨੀਤਿਕ ਚੁਣੌਤੀਆਂ ਦਾ ਪ੍ਰਤੀਕ੍ਰਿਆਵਾਦੀ ਤੌਰ 'ਤੇ ਹੱਲ ਕਰਨਾ ਚਾਹੀਦਾ ਹੈ।

ਇਸ ਦੇ ਨਾਲ, ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਮਾਡਲ ਜ਼ਿਆਦਾਤਰ ਖਤਰਨਾਕ ਇਨਪੁਟ ਅਤੇ ਸਧਾਰਣ ਅਨੌਖੇ ਡਾਟਾ ਵਿੱਚ ਅੰਤਰ ਨਹੀਂ ਕਰ ਸਕਦੇ। ਪ੍ਰਸ਼ਿਕਸ਼ਣ ਡਾਟਾ ਦਾ ਇੱਕ ਮਹੱਤਵਪੂਰਨ ਸਰੋਤ ਅਣਕੁਰੇਟਡ, ਅਣਮੋਡਰੇਟਡ, ਜਨਤਕ ਡਾਟਾਸੈੱਟਸ ਤੋਂ ਪ੍ਰਾਪਤ ਹੁੰਦਾ ਹੈ, ਜੋ ਤੀਜੀ ਪੱਖੀ ਯੋਗਦਾਨ ਲਈ ਖੁੱਲ੍ਹੇ ਹੁੰਦੇ ਹਨ। ਹਮਲਾਵਰਾਂ ਨੂੰ ਡਾਟਾਸੈੱਟਸ ਨਾਲ ਸਮਝੌਤਾ ਕਰਨ ਦੀ ਲੋੜ ਨਹੀਂ ਹੁੰਦੀ ਜਦੋਂ ਉਹਨਾਂ ਨੂੰ ਉਨ੍ਹਾਂ ਵਿੱਚ ਯੋਗਦਾਨ ਪਾਉਣ ਦੀ ਆਜ਼ਾਦੀ ਹੁੰਦੀ ਹੈ। ਸਮੇਂ ਦੇ ਨਾਲ, ਘੱਟ-ਵਿਸ਼ਵਾਸ ਵਾਲਾ ਖਤਰਨਾਕ ਡਾਟਾ ਉੱਚ-ਵਿਸ਼ਵਾਸ ਵਾਲੇ ਵਿਸ਼ਵਾਸਯੋਗ ਡਾਟਾ ਬਣ ਜਾਂਦਾ ਹੈ, ਜੇਕਰ ਡਾਟਾ ਦੀ ਸੰਰਚਨਾ/ਫਾਰਮੈਟ ਸਹੀ ਰਹਿੰਦੀ ਹੈ।

ਇਸੇ ਲਈ ਇਹ ਯਕੀਨੀ ਬਣਾਉਣਾ ਆਵਸ਼ਯਕ ਹੈ ਕਿ ਤੁਹਾਡੇ ਮਾਡਲਾਂ ਦੇ ਫੈਸਲੇ ਕਰਨ ਲਈ ਵਰਤੇ ਜਾਣ ਵਾਲੇ ਡਾਟਾ ਸਟੋਰਾਂ ਦੀ ਅਖੰਡਤਾ ਅਤੇ ਸੁਰੱਖਿਆ ਸੁਰੱਖਿਅਤ ਹੈ।

## AI ਦੇ ਜੋਖਮ ਅਤੇ ਧਮਕੀਆਂ ਦੀ ਸਮਝ

AI ਅਤੇ ਸੰਬੰਧਿਤ ਸਿਸਟਮਾਂ ਦੇ ਮਾਮਲੇ ਵਿੱਚ, ਡਾਟਾ ਪਾਇਜ਼ਨਿੰਗ ਅੱਜ ਦੇ ਸਮੇਂ ਵਿੱਚ ਸਭ ਤੋਂ ਮਹੱਤਵਪੂਰਨ ਸੁਰੱਖਿਆ ਖਤਰਾ ਹੈ। ਡਾਟਾ ਪਾਇਜ਼ਨਿੰਗ ਤਦ ਹੁੰਦਾ ਹੈ ਜਦੋਂ ਕੋਈ ਵਿਅਕਤੀ ਜਾਨਬੂਝ ਕੇ AI ਨੂੰ ਸਿਖਾਉਣ ਲਈ ਵਰਤੀ ਜਾਣ ਵਾਲੀ ਜਾਣਕਾਰੀ ਨੂੰ ਬਦਲ ਦਿੰਦਾ ਹੈ, ਜਿਸ ਕਾਰਨ ਇਹ ਗਲਤੀਆਂ ਕਰਦਾ ਹੈ। ਇਹ ਮਿਆਰੀਕ੍ਰਿਤ ਖੋਜ ਅਤੇ ਘਟਾਉਣ ਦੀਆਂ ਵਿਧੀਆਂ ਦੀ ਗੈਰਹਾਜ਼ਰੀ ਕਾਰਨ ਹੁੰਦਾ ਹੈ, ਜਿਸ ਨਾਲ ਸਾਡੀ ਵਿਸ਼ਵਾਸਯੋਗ ਜਾਂ ਅਣਕੁਰੇਟਡ ਜਨਤਕ ਡਾਟਾਸੈੱਟਸ 'ਤੇ ਨਿਰਭਰਤਾ ਹੁੰਦੀ ਹੈ। ਡਾਟਾ ਦੀ ਅਖੰਡਤਾ ਨੂੰ ਬਣਾਈ ਰੱਖਣ ਅਤੇ ਇੱਕ ਖਰਾਬ ਪ੍ਰਸ਼ਿਕਸ਼ਣ ਪ੍ਰਕਿਰਿਆ ਤੋਂ ਬਚਣ ਲਈ, ਤੁਹਾਡੇ ਡਾਟਾ ਦੀ ਉਤਪੱਤੀ ਅਤੇ ਵੰਸ਼ਾਵਲੀ ਨੂੰ ਟ੍ਰੈਕ ਕਰਨਾ ਜ਼ਰੂਰੀ ਹੈ। ਨਹੀਂ ਤਾਂ, ਪੁਰਾਣਾ ਕਹਾਵਤ "ਕਚਰਾ ਅੰਦਰ, ਕਚਰਾ ਬਾਹਰ" ਸਹੀ ਸਾਬਤ ਹੁੰਦੀ ਹੈ, ਜਿਸ ਨਾਲ ਮਾਡਲ ਦੀ ਕਾਰਗੁਜ਼ਾਰੀ ਖਰਾਬ ਹੋ ਜਾਂਦੀ ਹੈ।

ਇਹ ਰਹੇ ਕੁਝ ਉਦਾਹਰਣ ਕਿ ਡਾਟਾ ਪਾਇਜ਼ਨਿੰਗ ਤੁਹਾਡੇ ਮਾਡਲਾਂ ਨੂੰ ਕਿਵੇਂ ਪ੍ਰਭਾਵਿਤ ਕਰ ਸਕਦੀ ਹੈ:

1. **ਲੇਬਲ ਫਲਿੱਪਿੰਗ**: ਇੱਕ ਬਾਈਨਰੀ ਵਰਗੀਕਰਨ ਕੰਮ ਵਿੱਚ, ਇੱਕ ਵਿਰੋਧੀ ਜਾਨਬੂਝ ਕੇ ਪ੍ਰਸ਼ਿਕਸ਼ਣ ਡਾਟਾ ਦੇ ਇੱਕ ਛੋਟੇ ਸੈੱਟ ਦੇ ਲੇਬਲਾਂ ਨੂੰ ਫਲਿੱਪ ਕਰਦਾ ਹੈ। ਉਦਾਹਰਣ ਲਈ, ਸਧਾਰਣ ਨਮੂਨਿਆਂ ਨੂੰ ਖਤਰਨਾਕ ਲੇਬਲ ਕੀਤਾ ਜਾਂਦਾ ਹੈ, ਜਿਸ ਨਾਲ ਮਾਡਲ ਗਲਤ ਸੰਬੰਧ ਸਿੱਖਦਾ ਹੈ।\
   **ਉਦਾਹਰਣ**: ਇੱਕ ਸਪੈਮ ਫਿਲਟਰ ਜੋ ਮੈਨੇਜਮੈਂਟ ਈਮੇਲਾਂ ਨੂੰ ਸਪੈਮ ਵਜੋਂ ਗਲਤ ਵਰਗੀਕਰਨ ਕਰਦਾ ਹੈ।
2. **ਫੀਚਰ ਪਾਇਜ਼ਨਿੰਗ**: ਇੱਕ ਹਮਲਾਵਰ ਪ੍ਰਸ਼ਿਕਸ਼ਣ ਡਾਟਾ ਵਿੱਚ ਫੀਚਰਾਂ ਨੂੰ ਸੁਖਮ ਰੂਪ ਵਿੱਚ ਬਦਲਦਾ ਹੈ ਤਾਂ ਜੋ ਪੱਖਪਾਤ ਜਾਂ ਮਾਡਲ ਨੂੰ ਗੁੰਮਰਾਹ ਕੀਤਾ ਜਾ ਸਕੇ।\
   **ਉਦਾਹਰਣ**: ਸਿਫਾਰਸ਼ੀ ਪ੍ਰਣਾਲੀਆਂ ਨੂੰ ਮੈਨੇਜ ਕਰਨ ਲਈ ਉਤਪਾਦ ਵੇਰਵੇ ਵਿੱਚ ਬੇਲੋੜੀ ਕੁੰਜੀਆਂ ਸ਼ਬਦ ਸ਼ਾਮਲ ਕਰਨਾ।
3. **ਡਾਟਾ ਇੰਜੈਕਸ਼ਨ**: ਮਾਡਲ ਦੇ ਵਿਵਹਾਰ ਨੂੰ ਪ੍ਰਭਾਵਿਤ ਕਰਨ ਲਈ ਪ੍ਰਸ਼ਿਕਸ਼ਣ ਸੈੱਟ ਵਿੱਚ ਖਤਰਨਾਕ ਡਾਟਾ ਸ਼ਾਮਲ ਕਰਨਾ।\
   **ਉਦਾਹਰਣ**: ਭਾਵਨਾਤਮਕ ਵਿਸ਼ਲੇਸ਼ਣ ਦੇ ਨਤੀਜਿਆਂ ਨੂੰ ਵਿਗਾੜਨ ਲਈ ਨਕਲੀ ਯੂਜ਼ਰ ਸਮੀਖਿਆਵਾਂ ਸ਼ਾਮਲ ਕਰਨਾ।
4. **ਬੈਕਡੋਰ ਹਮਲੇ**: ਇੱਕ ਵਿਰੋਧੀ ਪ੍ਰਸ਼ਿਕਸ਼ਣ ਡਾਟਾ ਵਿੱਚ ਇੱਕ ਛੁਪੇ ਹੋਏ ਪੈਟਰਨ (ਬੈਕਡੋਰ) ਸ਼ਾਮਲ ਕਰਦਾ ਹੈ। ਮਾਡਲ ਇਸ ਪੈਟਰਨ ਨੂੰ ਪਛਾਣਨ ਲਈ ਸਿੱਖਦਾ ਹੈ ਅਤੇ ਜਦੋਂ ਟ੍ਰਿਗਰ ਕੀਤਾ ਜਾਂਦਾ ਹੈ ਤਾਂ ਖਤਰਨਾਕ ਵਿਵਹਾਰ ਕਰਦਾ ਹੈ।\
   **ਉਦਾਹਰਣ**: ਇੱਕ ਚਿਹਰਾ ਪਛਾਣ ਪ੍ਰਣਾਲੀ ਜੋ ਬੈਕਡੋਰਡ ਚਿੱਤਰਾਂ ਨਾਲ ਪ੍ਰਸ਼ਿਕਸ਼ਿਤ ਕੀਤੀ ਜਾਂਦੀ ਹੈ ਜੋ ਇੱਕ ਵਿਸ਼ੇਸ਼ ਵਿਅਕਤੀ ਨੂੰ ਗਲਤ ਪਛਾਣਦੀ ਹੈ।

MITRE ਕਾਰਪੋਰੇਸ਼ਨ ਨੇ [ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems)](https://atlas.mitre.org/?WT.mc_id=academic-105485-koreyst) ਬਣਾਇਆ ਹੈ, ਜੋ AI ਸਿਸਟਮਾਂ 'ਤੇ ਵਿਸ਼ਵਾਸਯੋਗ ਹਮਲਿਆਂ ਵਿੱਚ ਦੁਸ਼ਮਣਾਂ ਦੁਆਰਾ ਵਰਤੇ ਜਾਣ ਵਾਲੇ ਤਰੀਕੇ ਅਤੇ ਤਕਨੀਕਾਂ ਦਾ ਇੱਕ ਗਿਆਨਧਾਰ ਹੈ।

> AI-ਸक्षम ਸਿਸਟਮਾਂ ਵਿੱਚ ਖਾਮੀਆਂ ਦੀ ਗਿਣਤੀ ਵਧ ਰਹੀ ਹੈ, ਕਿਉਂਕਿ AI ਦਾ ਸ਼ਾਮਲ ਹੋਣਾ ਮੌਜੂਦਾ ਸਿਸਟਮਾਂ ਦੇ ਹਮਲੇ ਦੀ ਸਤਹ ਨੂੰ ਰਵਾਇਤੀ ਸਾਇਬਰ ਹਮਲਿਆਂ ਤੋਂ ਪਰੇ ਵਧਾ ਦਿੰਦਾ ਹੈ। ਸਾਡੇ ਨੇ ATLAS ਨੂੰ ਇਹਨਾਂ ਵਿਲੱਖਣ ਅਤੇ ਵਿਕਸਿਤ ਖਾਮੀਆਂ ਦੇ ਪ੍ਰਤੀ ਜਾਗਰੂਕਤਾ ਵਧਾਉਣ ਲਈ ਵਿਕਸਿਤ ਕੀਤਾ ਹੈ, ਕਿਉਂਕਿ ਵਿਸ਼ਵਾਸਯੋਗ ਸਮੁਦਾਏ ਵੱਖ-ਵੱਖ ਸਿਸਟਮਾਂ ਵਿੱਚ AI ਨੂੰ ਵਧੇਰੇ ਸ਼ਾਮਲ ਕਰ ਰਹੇ ਹਨ। ATLAS ਨੂੰ MITRE ATT&CK® ਫਰੇਮਵਰਕ ਦੇ ਮਾਡਲ ਤੇ ਬਣਾਇਆ ਗਿਆ ਹੈ ਅਤੇ ਇਸ ਦੇ ਤਰੀਕੇ, ਤਕਨੀਕਾਂ ਅਤੇ ਪ੍ਰਕਿਰਿਆਵਾਂ ATT&CK ਵਿੱਚ ਮੌਜੂਦ ਤਕਨੀਕਾਂ ਨੂੰ ਪੂਰਾ ਕਰਦੀਆਂ ਹਨ।

ਬਿਲਕੁਲ MITRE ATT&CK® ਫਰੇਮਵਰਕ ਦੀ ਤਰ੍ਹਾਂ, ਜੋ ਰਵਾਇਤੀ ਸਾਇਬਰਸੁਰੱਖਿਆ ਵਿੱਚ ਉੱਨਤ ਧਮਕੀ ਨਕਲ ਸੈਨੀਰੀਓਜ਼ ਦੀ ਯੋਜਨਾ ਬਣਾਉਣ ਲਈ ਵਿਆਪਕ ਤੌਰ 'ਤੇ ਵਰਤਿਆ ਜਾਂਦਾ ਹੈ, ATLAS ਇੱਕ ਆਸਾਨੀ ਨਾਲ ਖੋਜਯੋਗ ਸੈੱਟ TTPs ਪ੍ਰਦਾਨ ਕਰਦਾ ਹੈ ਜੋ ਉਭਰ ਰਹੀਆਂ ਧਮਕੀਆਂ ਦੇ ਵਿਰੋਧ ਵਿੱਚ ਰੱਖਣ ਲਈ ਬਿਹਤਰ ਸਮਝਣ ਅਤੇ ਤਿਆਰੀ ਕਰਨ ਵਿੱਚ ਮਦਦ ਕਰ ਸਕਦਾ ਹੈ।

ਇਸ ਦੇ ਨਾਲ, ਓਪਨ ਵੈਬ ਐਪਲੀਕੇਸ਼ਨ ਸੁਰੱਖਿਆ ਪ੍ਰਾਜੈਕਟ (OWASP) ਨੇ LLMs ਦੀ ਵਰਤੋਂ ਕਰਨ ਵਾਲੀਆਂ ਐਪਲੀਕੇਸ਼ਨ ਵਿੱਚ ਮਿਲਣ ਵਾਲੀਆਂ ਸਭ ਤੋਂ ਮਹੱਤਵਪੂਰਨ ਖਾਮੀਆਂ ਦੀ ਇੱਕ "[ਟੌਪ 10 ਸੂਚੀ](https://llmtop10.com/?WT.mc_id=academic-105485-koreyst)" ਬਣਾਈ ਹੈ। ਸੂਚੀ ਵਿੱਚ ਪਹਿਲਾਂ ਉਲਲੇਖ ਕੀਤੇ ਡਾਟਾ ਪਾਇਜ਼ਨਿੰਗ ਵਰਗੀਆਂ ਧਮਕੀਆਂ ਦੇ ਜੋਖਮਾਂ ਨਾਲ ਨਾਲ ਹੋਰਾਂ ਨੂੰ ਵੀ ਉਜਾਗਰ ਕੀਤਾ ਗਿਆ ਹੈ ਜਿਵੇਂ ਕਿ:

- **ਪ੍ਰਾਂਪਟ ਇੰਜੈਕਸ਼ਨ**: ਇੱਕ ਤਕਨੀਕ ਜਿੱਥੇ ਹਮਲਾਵਰ ਵੱਡੇ ਭਾਸ਼ਾ ਮਾਡਲ (LLM) ਨੂੰ ਧਿਆਨ ਨਾਲ ਬਣਾਈਆਂ ਗਈਆਂ ਇਨਪੁਟਸ ਦੁਆਰਾ ਮੈਨੇਜ ਕਰਦੇ ਹਨ, ਜਿਸ ਕਾਰਨ ਇਹ ਆਪਣੇ ਇਰਾਦੇ ਵਾਲੇ ਵਿਵਹਾਰ ਤੋਂ ਬਾਹਰ ਵਿਵਹਾਰ ਕਰਦਾ ਹੈ।
- **ਸਪਲਾਈ ਚੇਨ ਖਾਮੀਆਂ**: LLM ਦੁਆਰਾ ਵਰਤੀ ਜਾਣ ਵਾਲੀਆਂ ਐਪਲੀਕੇਸ਼ਨਾਂ ਦੇ ਭਾਗ ਅਤੇ ਸੌਫਟਵੇਅਰ, ਜਿਵੇਂ ਕਿ ਪਾਇਥਨ ਮਾਡਿਊਲ ਜਾਂ ਬਾਹਰੀ ਡਾਟਾਸੈੱਟਸ, ਖੁਦ ਖਾਮੀਆਂ ਦਾ ਸ਼ਿਕਾਰ ਹੋ ਸਕਦੇ ਹਨ ਜਿਸ ਨਾਲ ਅਣਪਛਾਤੇ ਨਤੀਜੇ, ਪੱਖਪਾਤ ਅਤੇ ਹੇਠਾਂ ਦੇ ਢਾਂਚੇ ਵਿੱਚ ਵੀ ਖਾਮੀਆਂ ਪੈਦਾ ਹੋ ਸਕਦੀਆਂ ਹਨ।
- **ਅਧਿਕ ਅੰਤਰਭਾਰ**: LLMs ਗਲਤੀਯੋਗ ਹਨ ਅਤੇ ਗਲਤ ਜਾਂ ਅਸੁਰੱਖਿਅਤ ਨਤੀਜੇ ਦੇਣ ਲਈ ਪ੍ਰਵਣ ਹਨ। ਕਈ ਦਸਤਾਵੇਜ਼ਿਤ ਹਾਲਾਤਾਂ ਵਿੱਚ, ਲੋਕਾਂ ਨੇ ਨਤੀਜਿਆਂ ਨੂੰ ਮੰਨ ਲਿਆ ਹੈ ਜਿਸ ਨਾਲ ਅਣਪਛਾਤੇ ਅਸਲ-ਵਿਸ਼ਵ ਨਕਾਰਾਤਮਕ ਨਤੀਜੇ ਨਿਕਲੇ ਹਨ।

ਮਾਈਕਰੋਸਾਫਟ ਕਲਾਉਡ ਐਡਵੋਕੇਟ ਰੌਡ ਟ੍ਰੈਂਟ ਨੇ ਇੱਕ ਮੁਫ਼ਤ ਈਬੁੱਕ ਲਿਖੀ ਹੈ, [Must Learn AI Security](https://github.com/rod-trent/OpenAISecurity/tree/main/Must_Learn/Book_Version?WT.mc_id=academic-105485-koreyst), ਜੋ ਇਨ੍ਹਾਂ ਅਤੇ ਹੋਰ ਉਭਰ ਰਹੀਆਂ AI ਧਮਕੀਆਂ ਵਿੱਚ ਡੂੰਘਾਈ ਨਾਲ ਜਾ ਸਕਦਾ ਹੈ ਅਤੇ ਇਹਨਾਂ ਸਨਰੀਓਜ਼ ਨੂੰ ਬਿਹਤਰ ਤਰੀਕੇ ਨਾਲ ਹੱਲ ਕਰਨ ਲਈ ਵਿਸ਼ਾਲ ਮਾਰਗਦਰਸ਼ਨ ਪ੍ਰਦਾਨ ਕਰਦਾ ਹੈ।

## AI ਸਿਸਟਮਾਂ ਅਤੇ LLMs ਲਈ ਸੁਰੱਖਿਆ ਜਾਂਚ

ਕ੍ਰਿਤਰਿਮ ਬੁੱਧੀ (AI) ਵੱਖ-ਵੱਖ ਖੇਤਰਾਂ ਅਤੇ ਉਦਯੋਗਾਂ ਨੂੰ ਬਦਲ ਰਹੀ ਹੈ, ਸਮਾਜ ਲਈ ਨਵੇਂ ਸੰਭਾਵਨਾਵਾਂ ਅਤੇ ਲਾਭ ਪ੍ਰਦਾਨ ਕਰ ਰਹੀ ਹੈ। ਹਾਲਾਂਕਿ, AI ਮਹੱਤਵਪੂਰਨ ਚੁਣੌਤੀਆਂ ਅਤੇ ਜੋਖਮ ਵੀ ਪੇਸ਼ ਕਰਦਾ ਹੈ, ਜਿਵੇਂ ਕਿ ਡਾਟਾ ਗੋਪਨੀਯਤਾ, ਪੱਖਪਾਤ, ਵਿਆਖਿਆ ਦੀ ਘਾਟ, ਅਤੇ ਸੰਭਾਵਿਤ ਗਲਤ ਵਰਤੋਂ। ਇਸ ਲਈ, ਇਹ ਯਕੀਨੀ ਬਣਾਉਣਾ ਜਰੂਰੀ ਹੈ ਕਿ AI ਸਿਸਟਮ ਸੁਰੱਖਿਅਤ ਅਤੇ ਜ਼ਿੰਮੇਵਾਰ ਹਨ, ਜਿਸਦਾ ਮਤਲਬ ਹੈ ਕਿ ਉਹ ਨੈਤਿਕ ਅਤੇ ਕਾਨੂੰਨੀ ਮਿਆਰਾਂ ਦੀ ਪਾਲਣਾ ਕਰਦੇ ਹਨ ਅਤੇ ਯੂਜ਼ਰਾਂ ਅਤੇ ਹਿੱਸੇਦਾਰਾਂ ਦੁਆਰਾ ਵਿਸ਼ਵਾਸਯੋਗ ਹਨ।

ਸੁਰੱਖਿਆ ਜਾਂਚ ਇੱਕ AI ਸਿਸਟਮ ਜਾਂ LLM ਦੀ ਸੁਰੱਖਿਆ ਦੀ ਮੁਲਾਂਕਣਾ ਕਰਨ ਦੀ ਪ੍ਰਕਿਰਿਆ ਹੈ, ਜਿਸ ਵਿੱਚ ਉਹਨਾਂ ਦੀਆਂ ਖਾਮੀਆਂ ਦੀ ਪਛਾਣ ਅਤੇ ਖੋਜ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਹ ਵਿਕਾਸਕਾਰਾਂ, ਯੂਜ਼ਰਾਂ, ਜਾਂ ਤੀਜੀ ਪੱਖੀ ਆਡੀਟਰਾਂ ਦੁਆਰਾ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ, ਜਾਂਚ ਦੇ ਉਦੇਸ਼ ਅਤੇ ਦਾਇਰੇ ਦੇ ਅਨੁਸਾਰ। AI ਸਿਸਟਮਾਂ ਅਤੇ LLMs ਲਈ ਕੁਝ ਸਭ ਤੋਂ ਆਮ ਸੁਰੱਖਿਆ ਜਾਂਚ ਵਿਧੀਆਂ ਹਨ:

- **ਡਾਟਾ ਸੈਨੀਟਾਈਜ਼ੇਸ਼ਨ**: ਇਹ ਇੱਕ AI ਸਿਸਟਮ ਜਾਂ LLM ਦੇ ਪ੍ਰਸ਼ਿਕਸ਼ਣ ਡਾਟਾ ਜਾਂ ਇਨਪੁਟ ਤੋਂ ਸੰਵੇਦਨਸ਼ੀਲ ਜਾਂ ਨਿੱਜੀ ਜਾਣਕਾਰੀ ਨੂੰ ਹਟਾਉਣ ਜਾਂ ਅਗਿਆਤ ਕਰਨ ਦੀ ਪ੍ਰਕਿਰਿਆ ਹੈ। ਡਾਟਾ ਸੈਨੀਟਾਈਜ਼ੇਸ਼ਨ ਡਾਟਾ ਰਿਸਾਵਟਣ ਅਤੇ ਖਤਰਨਾਕ ਚੇੜਛਾੜ ਨੂੰ ਰੋਕਣ ਵਿੱਚ ਮਦਦ ਕਰ ਸਕਦਾ ਹੈ, ਸੰਵੇਦਨਸ਼ੀਲ ਜਾਂ ਨਿੱਜੀ ਡਾਟਾ ਦੇ ਪਰਦਾਫਾਸ਼ ਨੂੰ ਘਟਾ ਕੇ।
- **ਵਿਰੋਧੀ ਜਾਂਚ**: ਇਹ ਇੱਕ AI ਸਿਸਟਮ ਜਾਂ LLM ਦੇ ਇਨਪੁਟ ਜਾਂ ਆਉਟਪੁੱਟ 'ਤੇ ਵਿਰੋਧੀ ਉਦਾਹਰਣਾਂ ਨੂੰ ਤਿਆਰ ਕਰਨ ਅਤੇ ਲਾਗੂ ਕਰਨ ਦੀ ਪ੍ਰਕਿਰਿਆ ਹੈ ਤਾਂ ਜੋ ਇਸ ਦੀ ਰੋਬਸਟਨੈਸ ਅਤੇ ਵਿਰੋਧੀ ਹਮਲਿਆਂ ਦੇ ਵਿਰੋਧ ਵਿੱਚ ਸਹਿਨਸ਼ੀਲਤਾ ਦਾ ਮੁਲਾਂਕਣ ਕੀਤਾ ਜਾ ਸਕੇ। ਵਿਰੋਧੀ ਜਾਂਚ ਹਮਲਾਵਰਾਂ ਦੁਆਰਾ ਸ਼ੋਸ਼ਣ ਕੀਤੇ ਜਾਣ ਵਾਲੇ AI ਸਿਸਟਮ ਜਾਂ LLM ਦੀਆਂ ਖਾਮੀਆਂ ਅਤੇ ਕਮਜ਼ੋਰੀਆਂ ਦੀ ਪਛਾਣ ਅਤੇ ਘਟਾਉਣ ਵਿੱਚ ਮਦਦ ਕਰ ਸਕਦੀ ਹੈ।
- **ਮਾਡਲ ਵੈਰੀਫਿਕੇਸ਼ਨ**: ਇਹ ਇੱਕ AI ਸਿਸਟਮ ਜਾਂ LLM ਦੇ ਮਾਡਲ ਪੈਰਾਮੀਟਰਾਂ ਜਾਂ ਆਰਕੀਟੈਕਚਰ ਦੀ ਸਹੀਤਾ ਅਤੇ ਪੂਰਨਤਾ ਦੀ ਪੁਸ਼ਟੀ ਕਰਨ ਦੀ ਪ੍ਰਕਿਰਿਆ ਹੈ। ਮਾਡਲ ਵੈਰੀਫਿਕੇਸ਼ਨ ਯਕੀਨੀ ਬਣਾਉਣ ਦੁਆਰਾ ਮਾਡਲ ਦੀ ਚੋਰੀ ਨੂੰ ਪਛਾਣਨ ਅਤੇ ਰੋਕਣ ਵਿੱਚ ਮਦਦ ਕਰ ਸਕਦਾ ਹੈ ਕਿ ਮਾਡਲ ਸੁਰੱਖਿਅਤ ਅਤੇ ਪ੍ਰਮਾਣਿਤ ਹੈ।
- **ਆਉਟਪੁੱਟ ਵੈਰੀਫਿਕੇਸ਼ਨ**: ਇਹ ਇੱਕ AI ਸਿਸਟਮ ਜਾਂ LLM ਦੇ ਆਉਟਪੁੱਟ ਦੀ ਗੁਣਵੱਤਾ ਅਤੇ ਵਿਸ਼ਵਾਸਯੋਗਤਾ ਦੀ ਪੁਸ਼ਟੀ ਕਰਨ ਦੀ ਪ੍ਰਕਿਰਿਆ ਹੈ। ਆਉਟਪੁੱਟ ਵੈਰੀਫਿਕੇਸ਼ਨ ਇਹ ਯਕੀਨੀ ਬਣਾਕੇ ਖਤਰਨਾਕ ਚੇੜਛਾੜ ਦੀ ਪਛਾਣ ਅਤੇ ਸਹੀ ਕਰਨ ਵਿੱਚ ਮਦਦ ਕਰ ਸਕਦਾ ਹੈ ਕਿ ਆਉਟਪੁੱਟ ਸਥਿਰ ਅਤੇ ਸਹੀ ਹੈ।

OpenAI, AI ਸਿਸਟਮਾਂ ਵਿੱਚ ਇੱਕ ਅਗਵਾਈ ਕਰਨ ਵਾਲਾ, ਆਪਣੇ ਰੈੱਡ ਟੀਮਿੰਗ ਨੈੱਟਵਰਕ ਪਹਲ ਦੇ ਹਿੱਸੇ ਵਜੋਂ _ਸੁਰੱਖਿਆ ਮੁਲਾਂਕਣ_ ਦੀ ਇੱਕ ਲੜੀ ਸੈੱਟਅਪ ਕੀਤੀ ਹੈ, ਜਿਸਦਾ ਉਦੇਸ਼ AI ਸਿਸਟਮਾਂ ਦੇ ਨਤੀਜੇ ਦੀ ਜਾਂਚ ਕਰਨਾ ਹੈ ਤਾਂ ਕਿ AI ਸੁਰੱਖਿਆ ਵਿੱਚ ਯੋਗਦਾਨ ਪਾਇਆ ਜਾ ਸਕੇ।

> ਮੁਲਾਂਕਣ ਸਧਾਰਨ ਪ੍ਰਸ਼ਨੋੱਤਰੀ ਜਾਂਚਾਂ ਤੋਂ ਲੈ

**ਅਸਵੀਕਤੀ**:  
ਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਜਦੋਂ ਕਿ ਅਸੀਂ ਸਹੀਤਾ ਲਈ ਕੋਸ਼ਿਸ਼ ਕਰਦੇ ਹਾਂ, ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਦਿਓ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸੁੱਚੀਆਂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਇਸਦੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਮੌਜੂਦ ਮੂਲ ਦਸਤਾਵੇਜ਼ ਨੂੰ ਅਧਿਕਾਰਿਕ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਿਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੇ ਉਪਯੋਗ ਤੋਂ ਪੈਦਾ ਹੋਣ ਵਾਲੇ ਕਿਸੇ ਵੀ ਗਲਤ ਫਹਿਮੀ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।