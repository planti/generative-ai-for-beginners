<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:36:00+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "pa"
}
-->
# ਸਵੈ-ਨਿਰਦੇਸ਼ਿਤ ਸਿੱਖਿਆ ਲਈ ਸਾਧਨ

ਇਹ ਪਾਠ OpenAI ਅਤੇ Azure OpenAI ਤੋਂ ਕੁਝ ਮੁੱਖ ਸਾਧਨਾਂ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਬਣਾਇਆ ਗਿਆ ਸੀ ਜੋ ਸ਼ਬਦਾਵਲੀ ਅਤੇ ਟਿਊਟੋਰੀਅਲ ਲਈ ਸੰਦਰਭ ਵਜੋਂ ਸੇਵਾ ਕਰਦੇ ਹਨ। ਇਹ ਰੂਪ ਰੇਖਾ ਤੁਹਾਡੇ ਆਪਣੇ ਸਵੈ-ਨਿਰਦੇਸ਼ਿਤ ਸਿੱਖਿਆ ਦੇ ਸਫਰਾਂ ਲਈ ਹੈ।

## 1. ਪ੍ਰਮੁੱਖ ਸਾਧਨ

| ਸਿਰਲੇਖ/ਲਿੰਕ                                                                                                                                                                                                                   | ਵਰਣਨ                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [OpenAI ਮਾਡਲਾਂ ਨਾਲ ਫਾਈਨ-ਟਿਊਨਿੰਗ](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                       | ਫਾਈਨ-ਟਿਊਨਿੰਗ ਕੁਝ-ਸ਼ਾਟ ਸਿੱਖਿਆ 'ਤੇ ਵਧੀਆ ਹੈ ਕਿਉਂਕਿ ਇਹ ਪ੍ਰੰਪਟ ਵਿੱਚ ਫਿੱਟ ਹੋ ਸਕਣ ਵਾਲੇ ਕਈ ਉਦਾਹਰਨਾਂ 'ਤੇ ਪ੍ਰਸ਼ਿਕਸ਼ਣ ਕਰਦੀ ਹੈ, ਤੁਹਾਨੂੰ ਖਰਚੇ ਬਚਾਉਣ, ਜਵਾਬ ਦੀ ਗੁਣਵੱਤਾ ਵਿੱਚ ਸੁਧਾਰ ਕਰਨ, ਅਤੇ ਘੱਟ-ਬਿਲੰਬੀ ਅਨੁਰੋਧਾਂ ਨੂੰ ਯੋਗ ਬਣਾਉਂਦੀ ਹੈ। **OpenAI ਤੋਂ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਦਾ ਜਾਇਜ਼ਾ ਲਓ।**                                                                                    |
| [Azure OpenAI ਨਾਲ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਕੀ ਹੈ?](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                   | **ਫਾਈਨ-ਟਿਊਨਿੰਗ ਕੀ ਹੈ (ਸੰਕਲਪ)**, ਤੁਹਾਨੂੰ ਇਸ 'ਤੇ ਕਿਉਂ ਧਿਆਨ ਦੇਣਾ ਚਾਹੀਦਾ ਹੈ (ਪ੍ਰੇਰਕ ਸਮੱਸਿਆ), ਕਿਹੜਾ ਡਾਟਾ ਵਰਤਣਾ ਹੈ (ਪ੍ਰਸ਼ਿਕਸ਼ਣ) ਅਤੇ ਗੁਣਵੱਤਾ ਨੂੰ ਮਾਪਣਾ                                                                                                                                                                           |
| [ਫਾਈਨ-ਟਿਊਨਿੰਗ ਨਾਲ ਮਾਡਲ ਨੂੰ ਕਸਟਮਾਈਜ਼ ਕਰੋ](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst) | Azure OpenAI ਸੇਵਾ ਤੁਹਾਨੂੰ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਆਪਣੇ ਨਿੱਜੀ ਡਾਟਾਸੈਟਾਂ ਲਈ ਸਾਡੇ ਮਾਡਲਾਂ ਨੂੰ ਅਨੁਕੂਲਿਤ ਕਰਨ ਦੀ ਆਗਿਆ ਦਿੰਦੀ ਹੈ। ਸਿੱਖੋ **ਫਾਈਨ-ਟਿਊਨਿੰਗ (ਪ੍ਰਕਿਰਿਆ) ਕਿਵੇਂ ਕਰਨੀ ਹੈ** Azure AI Studio, Python SDK ਜਾਂ REST API ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਮਾਡਲਾਂ ਨੂੰ ਚੁਣੋ।                                                                                                                                |
| [LLM ਫਾਈਨ-ਟਿਊਨਿੰਗ ਲਈ ਸਿਫਾਰਸ਼ਾਂ](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                    | LLM ਵਿਸ਼ੇਸ਼ ਡੋਮੇਨ, ਕਾਰਜਾਂ ਜਾਂ ਡਾਟਾਸੈਟਾਂ 'ਤੇ ਚੰਗਾ ਪ੍ਰਦਰਸ਼ਨ ਨਹੀਂ ਕਰ ਸਕਦੇ, ਜਾਂ ਗਲਤ ਜਾਂ ਭ੍ਰਮਿਤ ਨਤੀਜੇ ਪੈਦਾ ਕਰ ਸਕਦੇ ਹਨ। **ਤੁਸੀਂ ਕਦੋਂ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਨੂੰ ਇਸਦਾ ਸੰਭਾਵਿਤ ਹੱਲ ਵਜੋਂ ਵਿਚਾਰਨਾ ਚਾਹੀਦਾ ਹੈ?**                                                                                                                                  |
| [ਲਗਾਤਾਰ ਫਾਈਨ ਟਿਊਨਿੰਗ](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)             | ਲਗਾਤਾਰ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਇੱਕ ਪਹਿਲਾਂ ਹੀ ਫਾਈਨ-ਟਿਊਨ ਕੀਤੇ ਮਾਡਲ ਨੂੰ ਬੇਸ ਮਾਡਲ ਵਜੋਂ ਚੁਣਨ ਅਤੇ **ਨਵੇਂ ਪ੍ਰਸ਼ਿਕਸ਼ਣ ਉਦਾਹਰਨਾਂ ਦੇ ਸੈੱਟਾਂ 'ਤੇ ਇਸਨੂੰ ਹੋਰ ਸੁਧਾਰਨ ਦੀ ਦੁਹਰਾਈ ਜਾਂਦੀ ਪ੍ਰਕਿਰਿਆ ਹੈ।                                                                                                                                                     |
| [ਫਾਈਨ-ਟਿਊਨਿੰਗ ਅਤੇ ਫੰਕਸ਼ਨ ਕਾਲਿੰਗ](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                       | ਫੰਕਸ਼ਨ ਕਾਲਿੰਗ ਉਦਾਹਰਨਾਂ ਨਾਲ **ਆਪਣੇ ਮਾਡਲ ਨੂੰ ਫਾਈਨ-ਟਿਊਨ ਕਰਨਾ** ਮਾਡਲ ਨਤੀਜੇ ਨੂੰ ਹੋਰ ਸਹੀ ਅਤੇ ਲਗਾਤਾਰ ਨਤੀਜੇ ਪ੍ਰਾਪਤ ਕਰਕੇ ਸੁਧਾਰ ਸਕਦਾ ਹੈ - ਸਮਾਨ-ਫਾਰਮੈਟ ਕੀਤੇ ਜਵਾਬਾਂ ਅਤੇ ਖਰਚੇ ਬਚਤ ਨਾਲ                                                                                                                                        |
| [ਫਾਈਨ-ਟਿਊਨਿੰਗ ਮਾਡਲ: Azure OpenAI ਮਾਰਗਦਰਸ਼ਨ](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                                        | ਇਸ ਸਾਰਣੀ ਨੂੰ ਵੇਖੋ ਕਿ **ਕਿਹੜੇ ਮਾਡਲਾਂ ਨੂੰ Azure OpenAI ਵਿੱਚ ਫਾਈਨ-ਟਿਊਨ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ**, ਅਤੇ ਕਿਹੜੇ ਖੇਤਰਾਂ ਵਿੱਚ ਇਹ ਉਪਲਬਧ ਹਨ। ਜੇ ਲੋੜ ਹੋਵੇ ਤਾਂ ਉਨ੍ਹਾਂ ਦੇ ਟੋਕਨ ਸੀਮਾਵਾਂ ਅਤੇ ਪ੍ਰਸ਼ਿਕਸ਼ਣ ਡਾਟਾ ਮਿਆਦ ਖਤਮ ਹੋਣ ਦੀਆਂ ਤਰੀਕਾਂ ਵੇਖੋ।                                                                                                                            |
| [ਫਾਈਨ ਟਿਊਨ ਕਰਨਾ ਜਾਂ ਨਾ ਕਰਨਾ? ਇਹ ਹੈ ਸਵਾਲ](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                      | AI ਸ਼ੋਅ ਦਾ ਇਹ 30 ਮਿੰਟ **ਅਕਤੂਬਰ 2023** ਐਪੀਸੋਡ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਦੇ ਫਾਇਦੇ, ਘਾਟ ਅਤੇ ਵਿਆਹਾਰਕ ਦ੍ਰਿਸ਼ਟਾਂਤਾਂ 'ਤੇ ਚਰਚਾ ਕਰਦਾ ਹੈ ਜੋ ਤੁਹਾਨੂੰ ਇਹ ਫੈਸਲਾ ਕਰਨ ਵਿੱਚ ਮਦਦ ਕਰਦੇ ਹਨ।                                                                                                                                                                                        |
| [LLM ਫਾਈਨ-ਟਿਊਨਿੰਗ ਨਾਲ ਸ਼ੁਰੂਆਤ](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                             | ਇਹ **AI Playbook** ਸਾਧਨ ਤੁਹਾਨੂੰ ਡਾਟਾ ਦੀਆਂ ਲੋੜਾਂ, ਫਾਰਮੈਟਿੰਗ, ਹਾਇਪਰਪੈਰਾਮੀਟਰ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਅਤੇ ਚੁਣੌਤੀਆਂ/ਪਾਬੰਦੀਆਂ ਜਿਨ੍ਹਾਂ ਬਾਰੇ ਤੁਹਾਨੂੰ ਜਾਣਨਾ ਚਾਹੀਦਾ ਹੈ, ਰਾਹੀਂ ਲੰਘਦਾ ਹੈ।                                                                                                                                                                         |
| **ਟਿਊਟੋਰੀਅਲ**: [Azure OpenAI GPT3.5 Turbo Fine-Tuning](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                                  | ਫਾਈਨ-ਟਿਊਨਿੰਗ ਲਈ ਨਮੂਨਾ ਡਾਟਾਸੈਟ ਬਣਾਉਣ, ਫਾਈਨ-ਟਿਊਨਿੰਗ ਲਈ ਤਿਆਰੀ ਕਰਨ, ਫਾਈਨ-ਟਿਊਨਿੰਗ ਨੌਕਰੀ ਬਣਾਉਣ ਅਤੇ Azure 'ਤੇ ਫਾਈਨ-ਟਿਊਨ ਕੀਤਾ ਮਾਡਲ ਤੈਨਾਤ ਕਰਨ ਲਈ ਸਿੱਖੋ।                                                                                                                                                                                    |
| **ਟਿਊਟੋਰੀਅਲ**: [Azure AI Studio ਵਿੱਚ Llama 2 ਮਾਡਲ ਨੂੰ ਫਾਈਨ-ਟਿਊਨ ਕਰੋ](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                                      | Azure AI Studio ਤੁਹਾਨੂੰ ਵੱਡੇ ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਨੂੰ ਆਪਣੇ ਨਿੱਜੀ ਡਾਟਾਸੈਟਾਂ _UI-ਅਧਾਰਤ ਵਰਕਫਲੋ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਜੋ ਘੱਟ-ਕੋਡ ਵਿਕਾਸਕਰਤਿਆਂ ਲਈ ਉਚਿਤ ਹੈ_ ਲਈ ਅਨੁਕੂਲਿਤ ਕਰਨ ਦੀ ਆਗਿਆ ਦਿੰਦਾ ਹੈ। ਇਸ ਉਦਾਹਰਨ ਨੂੰ ਵੇਖੋ।                                                                                                                                                               |
| **ਟਿਊਟੋਰੀਅਲ**:[Azure 'ਤੇ ਇੱਕ ਸਿੰਗਲ GPU ਲਈ Hugging Face ਮਾਡਲਾਂ ਨੂੰ ਫਾਈਨ-ਟਿਊਨ ਕਰੋ](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)               | ਇਹ ਲੇਖ ਵਰਣਨ ਕਰਦਾ ਹੈ ਕਿ Azure DataBricks + Hugging Face Trainer ਲਾਇਬ੍ਰੇਰੀਆਂ ਨਾਲ ਇੱਕ ਸਿੰਗਲ GPU ਨਾਲ Hugging Face ਮਾਡਲ ਨੂੰ Hugging Face ਟ੍ਰਾਂਸਫਾਰਮਰ ਲਾਇਬ੍ਰੇਰੀ ਨਾਲ ਕਿਵੇਂ ਫਾਈਨ-ਟਿਊਨ ਕਰਨਾ ਹੈ                                                                                                                                                |
| **ਪ੍ਰਸ਼ਿਕਸ਼ਣ:** [Azure Machine Learning ਨਾਲ ਫਾਈਨ-ਟਿਊਨ ਇੱਕ ਫਾਉਂਡੇਸ਼ਨ ਮਾਡਲ](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)         | Azure Machine Learning ਵਿੱਚ ਮਾਡਲ ਕੈਟਾਲਾਗ ਬਹੁਤ ਸਾਰੇ ਖੁੱਲ੍ਹੇ ਸਰੋਤ ਮਾਡਲਾਂ ਦੀ ਪੇਸ਼ਕਸ਼ ਕਰਦਾ ਹੈ ਜਿਨ੍ਹਾਂ ਨੂੰ ਤੁਸੀਂ ਆਪਣੇ ਵਿਸ਼ੇਸ਼ ਕਾਰਜ ਲਈ ਫਾਈਨ-ਟਿਊਨ ਕਰ ਸਕਦੇ ਹੋ। ਇਹ ਮਾਡਿਊਲ [AzureML Generative AI Learning Path](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst) ਤੋਂ ਹੈ |
| **ਟਿਊਟੋਰੀਅਲ:** [Azure OpenAI ਫਾਈਨ-ਟਿਊਨਿੰਗ](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                | Microsoft Azure 'ਤੇ W&B ਦੀ ਵਰਤੋਂ ਕਰਕੇ GPT-3.5 ਜਾਂ GPT-4 ਮਾਡਲਾਂ ਨੂੰ ਫਾਈਨ-ਟਿਊਨ ਕਰਨ ਨਾਲ ਮਾਡਲ ਦੇ ਪ੍ਰਦਰਸ਼ਨ ਦੀ ਵਿਸਤ੍ਰਿਤ ਟ੍ਰੈਕਿੰਗ ਅਤੇ ਵਿਸ਼ਲੇਸ਼ਣ ਦੀ ਆਗਿਆ ਮਿਲਦੀ ਹੈ। ਇਹ ਮਾਰਗਦਰਸ਼ਨ ਖਾਸ ਕਦਮਾਂ ਅਤੇ Azure OpenAI ਲਈ ਵਿਸ਼ੇਸ਼ਤਾਵਾਂ ਨਾਲ OpenAI ਫਾਈਨ-ਟਿਊਨਿੰਗ ਮਾਰਗਦਰਸ਼ਨ ਦੇ ਸੰਕਲਪਾਂ ਨੂੰ ਵਧਾਉਂਦਾ ਹੈ।                                                                         |
|                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                               |

## 2. ਮਾਧੀ ਸਾਧਨ

ਇਹ ਭਾਗ ਵਧੇਰੇ ਸਾਧਨਾਂ ਨੂੰ ਕੈਪਚਰ ਕਰਦਾ ਹੈ ਜੋ ਖੋਜ ਕਰਨ ਲਈ ਯੋਗ ਹਨ, ਪਰ ਜਿਨ੍ਹਾਂ ਨੂੰ ਅਸੀਂ ਇਸ ਪਾਠ ਵਿੱਚ ਕਵਰ ਕਰਨ ਦਾ ਸਮਾਂ ਨਹੀਂ ਸੀ। ਇਹਨਾਂ ਨੂੰ ਆਉਣ ਵਾਲੇ ਪਾਠ ਵਿੱਚ, ਜਾਂ ਮਾਧੀ ਅਸਾਈਨਮੈਂਟ ਵਿਕਲਪ ਵਜੋਂ, ਕਿਸੇ ਹੋਰ ਮਿਤੀ ਤੇ ਕਵਰ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ। ਇਸ ਸਮੇਂ ਲਈ, ਇਸ ਵਿਸ਼ੇ ਦੇ ਆਲੇ-ਦੁਆਲੇ ਆਪਣੀ ਮਾਹਰਤਾ ਅਤੇ ਗਿਆਨ ਬਣਾਉਣ ਲਈ ਉਨ੍ਹਾਂ ਦੀ ਵਰਤੋਂ ਕਰੋ।

| ਸਿਰਲੇਖ/ਲਿੰਕ                                                                                                                                                                                                            | ਵਰਣਨ                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI ਕੂਕਬੁੱਕ**: [ਚੈਟ ਮਾਡਲ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਲਈ ਡਾਟਾ ਤਿਆਰੀ ਅਤੇ ਵਿਸ਼ਲੇਸ਼ਣ](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                                      | ਇਹ ਨੋਟਬੁੱਕ ਚੈਟ ਮਾਡਲ ਨੂੰ ਫਾਈਨ-ਟਿਊਨ ਕਰਨ ਲਈ ਵਰਤਿਆ ਜਾਂਦਾ ਚੈਟ ਡਾਟਾਸੈਟ ਨੂੰ ਪ੍ਰੀ-ਪ੍ਰੋਸੈਸ ਅਤੇ ਵਿਸ਼ਲੇਸ਼ਣ ਕਰਨ ਲਈ ਇੱਕ ਸਾਧਨ ਵਜੋਂ ਕੰਮ ਕਰਦਾ ਹੈ। ਇਹ ਫਾਰਮੈਟ ਦੀਆਂ ਗਲਤੀਆਂ ਦੀ ਜਾਂਚ ਕਰਦਾ ਹੈ, ਮੂਲ ਸੰਖੇਪਕ ਅੰਕੜੇ ਪ੍ਰਦਾਨ ਕਰਦਾ ਹੈ, ਅਤੇ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਦੀਆਂ ਲਾਗਤਾਂ ਲਈ ਟੋਕਨ ਦੀਆਂ ਗਿਣਤੀਆਂ ਦਾ ਅਨੁਮਾਨ ਲਗਾਉਂਦਾ ਹੈ। ਵੇਖੋ: [gpt-3.5-turbo ਲਈ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਵਿਧੀ](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)।                                                                                                                                                                   |
| **OpenAI ਕੂਕਬੁੱਕ**: [Qdrant ਨਾਲ Retrieval Augmented Generation (RAG) ਲਈ ਫਾਈਨ-ਟਿਊਨਿੰਗ](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst) | ਇਸ ਨੋਟਬੁੱਕ ਦਾ ਉਦੇਸ਼ Retrieval Augmented Generation (RAG) ਲਈ OpenAI ਮਾਡਲਾਂ ਨੂੰ ਫਾਈਨ-ਟਿਊਨ ਕਰਨ ਲਈ ਇੱਕ ਵਿਸਤ੍ਰਿਤ ਉਦਾਹਰਨ ਰਾਹੀਂ ਲੰਘਣਾ ਹੈ। ਅਸੀਂ ਮਾਡਲ ਦੇ ਪ੍ਰਦਰਸ਼ਨ ਨੂੰ ਵਧਾਉਣ ਅਤੇ ਨਕਲਾਂ ਨੂੰ ਘਟਾਉਣ ਲਈ Qdrant ਅਤੇ Few-Shot Learning ਨੂੰ ਵੀ ਸੰਮੇਲਿਤ ਕਰ ਰਹੇ ਹਾਂ।                                                                                                                                                                                                                                                                |
| **OpenAI ਕੂਕਬੁੱਕ**: [Weights & Biases ਨਾਲ GPT ਨੂੰ ਫਾਈਨ-ਟਿਊਨ ਕਰਨਾ](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                             | Weights & Biases (W&B) AI ਵਿਕਾਸਕਰਤਾ ਪਲੇਟਫਾਰਮ ਹੈ, ਮਾਡਲਾਂ ਨੂੰ ਪ੍ਰਸ਼ਿਕਸ਼ਿਤ ਕਰਨ, ਮਾਡਲਾਂ ਨੂੰ ਫਾਈਨ-ਟਿਊਨ ਕਰਨ, ਅਤੇ ਫਾਉਂਡੇਸ਼ਨ ਮਾਡਲਾਂ ਦੀ ਵਰਤੋਂ ਕਰਨ ਲਈ ਸਾਧਨਾਂ ਨਾਲ। ਪਹਿਲਾਂ ਉਨ੍ਹਾਂ ਦਾ [OpenAI ਫਾਈਨ-ਟਿਊਨਿੰਗ](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst) ਮਾਰਗਦਰਸ਼ਨ ਪੜ੍ਹੋ, ਫਿਰ ਕੂਕਬੁੱਕ ਅਭਿਆਸ ਦੀ ਕੋਸ਼ਿਸ਼ ਕਰੋ।                                                                                                                                                                                                                  |
| **ਕਮਿਊਨਟੀ ਟਿਊਟੋਰੀਅਲ** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - ਛੋਟੇ ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਲਈ ਫਾਈਨ-ਟਿਊਨਿੰਗ                                                   | [Phi-2](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst), Microsoft ਦਾ ਨਵਾਂ ਛੋਟਾ ਮਾਡਲ, ਅਦਭੁਤ ਤਾਕਤਵਰ ਹਾਲਾਂਕਿ ਸੰਕੁਚਿਤ ਨਾਲ ਮਿਲੋ। ਇਹ ਟਿਊਟੋਰੀਅਲ ਤੁਹਾਨੂੰ Phi-2 ਨੂੰ ਫਾਈਨ-ਟਿਊਨ ਕਰਨ ਰਾਹੀਂ ਲੰਘਣ ਵਿੱਚ ਮਦਦ ਕਰੇਗਾ, ਇਹ ਦਿਖਾਉਂਦੇ ਹੋਏ ਕਿ ਕਿਵੇਂ ਇੱਕ ਵਿਲੱਖਣ ਡਾਟਾਸੈਟ ਬਣਾਇਆ ਜਾ ਸਕਦਾ ਹੈ ਅਤੇ QLoRA ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਮਾਡਲ ਨੂੰ ਫਾਈਨ-ਟਿਊਨ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ।                                                                                                                                                                       |
| **Hugging Face ਟਿਊਟੋਰੀਅਲ** [2024 ਵਿੱਚ Hugging Face ਨਾਲ LLMs ਨੂੰ ਫਾਈਨ-ਟਿਊਨ ਕਿਵੇਂ ਕਰਨਾ ਹੈ](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | ਇਹ ਬਲੌਗ ਪੋਸਟ ਤੁਹਾਨੂੰ Hugging Face TRL, Transformers & datasets ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਖੁੱਲ੍ਹੇ LLMs ਨੂੰ ਫਾਈਨ-ਟਿਊਨ ਕਰਨ ਰਾਹੀਂ ਲੰਘਣ ਵਿੱਚ ਮਦਦ ਕਰਦੀ ਹੈ। ਤੁਸੀਂ ਇੱਕ ਵਰਤੋਂ ਮਾਮਲਾ ਨੂੰ ਪਰਿਭਾਸ਼ਿਤ ਕਰਦੇ ਹੋ, ਇੱਕ ਡਿਵ ਐਨਵਾਇਰਮੈਂਟ ਸੈਟਅੱਪ ਕਰਦੇ ਹੋ, ਇੱਕ ਡਾਟਾਸੈਟ ਤਿਆਰ ਕਰਦੇ ਹੋ, ਮਾਡਲ ਨੂੰ ਫਾਈਨ-ਟਿਊਨ ਕਰਦੇ ਹੋ, ਇਸਨੂੰ ਟੈਸਟ-ਮੁਲਾਂਕਨ ਕਰਦੇ ਹੋ, ਫਿਰ ਇਸਨੂੰ ਉਤਪਾਦਨ ਵਿੱਚ ਤੈਨਾਤ ਕਰਦੇ ਹੋ।                                                                                                                                                                                                                                                                |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                            | [ਅਧੁਨਿਕ ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਮਾਡਲਾਂ](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst) ਦੇ ਤੇਜ਼ ਅਤੇ ਆਸਾਨ ਪ੍ਰਸ਼ਿਕਸ਼ਣ ਅਤੇ ਤੈਨਾਤੀ ਲਿਆਉਂਦਾ ਹੈ। ਰਿਪੋਜ਼ੀਟਰੀ ਕੋਲਾਬ-ਦੋਸਤਾਨਾ ਟਿਊਟੋਰੀਅਲਾਂ YouTube ਵੀਡੀਓ ਮਾਰਗਦਰਸ਼ਨ ਦੇ ਨਾਲ ਹੈ, ਫਾਈਨ-ਟਿਊਨਿੰਗ ਲਈ। **ਤਾਜ਼ਾ [ਸਥਾਨਕ-ਪਹਿਲਾਂ](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst) ਅਪਡੇਟ ਨੂੰ ਦਰਸਾਉਂਦਾ ਹੈ** . [Auto

**ਅਸਵੀਕਰਤਾ**:  
ਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਜਦੋਂ ਕਿ ਅਸੀਂ ਸ਼ੁੱਧਤਾ ਲਈ ਕੋਸ਼ਿਸ਼ ਕਰਦੇ ਹਾਂ, ਕਿਰਪਾ ਕਰਕੇ ਜਾਨੋ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸੁੱਧੀਆਂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਇਸਦੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਮੂਲ ਦਸਤਾਵੇਜ਼ ਨੂੰ ਅਧਿਕਾਰਤ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਗੰਭੀਰ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੀ ਵਰਤੋਂ ਤੋਂ ਪੈਦਾ ਹੋਣ ਵਾਲੀਆਂ ਕਿਸੇ ਵੀ ਗਲਤਫਹਿਮੀਆਂ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆਵਾਂ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।