<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:27:45+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "fa"
}
-->
# منابعی برای یادگیری خودآموز

درس با استفاده از تعدادی منابع اصلی از OpenAI و Azure OpenAI به عنوان مرجع برای اصطلاحات و آموزش‌ها ساخته شده است. در اینجا لیستی غیرجامع برای سفرهای یادگیری خودآموز شما آمده است.

## 1. منابع اصلی

| عنوان/لینک                                                                                                                                                                                                                   | توضیحات                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Fine-tuning with OpenAI Models](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                       | تنظیم دقیق با آموزش بر روی تعداد بیشتری از نمونه‌ها نسبت به آنچه که در پرامپت جا می‌شود، باعث کاهش هزینه‌ها، بهبود کیفیت پاسخ‌ها و امکان درخواست‌های با تأخیر کمتر می‌شود. **نمای کلی از تنظیم دقیق از OpenAI را دریافت کنید.**                                                                                    |
| [What is Fine-Tuning with Azure OpenAI?](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                   | درک کنید **تنظیم دقیق چیست (مفهوم)**، چرا باید به آن توجه کنید (مشکل انگیزشی)، چه داده‌ای برای استفاده (آموزش) و اندازه‌گیری کیفیت                                                                                                                                                                           |
| [Customize a model with fine-tuning](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst) | سرویس Azure OpenAI به شما امکان می‌دهد مدل‌های ما را با استفاده از تنظیم دقیق به داده‌های شخصی‌تان اختصاص دهید. یاد بگیرید **چگونه مدل‌ها را با استفاده از Azure AI Studio، Python SDK یا REST API تنظیم دقیق کنید (فرایند).**                                                                                                                                |
| [Recommendations for LLM fine-tuning](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                    | LLM ها ممکن است در دامنه‌ها، وظایف یا مجموعه داده‌های خاص عملکرد خوبی نداشته باشند یا ممکن است خروجی‌های نادرست یا گمراه‌کننده تولید کنند. **چه زمانی باید تنظیم دقیق را به عنوان یک راه حل ممکن در نظر بگیرید؟**                                                                                                                                  |
| [Continuous Fine Tuning](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)             | تنظیم دقیق پیوسته فرآیند تکراری انتخاب یک مدل تنظیم دقیق شده به عنوان مدل پایه و **تنظیم دقیق بیشتر آن** بر روی مجموعه‌های جدید از نمونه‌های آموزشی است.                                                                                                                                                     |
| [Fine-tuning and function calling](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                       | تنظیم دقیق مدل شما **با نمونه‌های فراخوانی تابع** می‌تواند خروجی مدل را با دریافت خروجی‌های دقیق‌تر و سازگارتر بهبود بخشد - با پاسخ‌های مشابه فرمت شده و صرفه‌جویی در هزینه‌ها                                                                                                                                        |
| [Fine-tuning Models: Azure OpenAI Guidance](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                                        | این جدول را بررسی کنید تا درک کنید **چه مدل‌هایی را می‌توان در Azure OpenAI تنظیم دقیق کرد** و در کدام مناطق این‌ها در دسترس هستند. اگر لازم است، محدودیت‌های توکن و تاریخ‌های انقضای داده‌های آموزشی آن‌ها را بررسی کنید.                                                                                                                            |
| [To Fine Tune or Not To Fine Tune? That is the Question](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                      | این قسمت 30 دقیقه‌ای **اکتبر 2023** از AI Show به بررسی مزایا، معایب و بینش‌های عملی می‌پردازد که به شما کمک می‌کند این تصمیم را بگیرید.                                                                                                                                                                                        |
| [Getting Started With LLM Fine-Tuning](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                             | این منبع **AI Playbook** شما را از طریق نیازهای داده، فرمت‌بندی، تنظیم دقیق هایپرپارامتر و چالش‌ها/محدودیت‌هایی که باید بدانید راهنمایی می‌کند.                                                                                                                                                                         |
| **آموزش**: [Azure OpenAI GPT3.5 Turbo Fine-Tuning](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                                  | یاد بگیرید که چگونه یک مجموعه داده تنظیم دقیق نمونه ایجاد کنید، برای تنظیم دقیق آماده شوید، یک کار تنظیم دقیق ایجاد کنید و مدل تنظیم دقیق شده را در Azure مستقر کنید.                                                                                                                                                                                    |
| **آموزش**: [Fine-tune a Llama 2 model in Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                                      | Azure AI Studio به شما امکان می‌دهد مدل‌های زبان بزرگ را به داده‌های شخصی‌تان اختصاص دهید _با استفاده از یک جریان کاری مبتنی بر رابط کاربری مناسب برای توسعه‌دهندگان کم‌کد_. این مثال را ببینید.                                                                                                                                                               |
| **آموزش**:[Fine-tune Hugging Face models for a single GPU on Azure](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)               | این مقاله توصیف می‌کند که چگونه یک مدل Hugging Face را با استفاده از کتابخانه ترانسفورمرهای Hugging Face بر روی یک GPU با Azure DataBricks + کتابخانه‌های مربی Hugging Face تنظیم دقیق کنید.                                                                                                                                                |
| **آموزش:** [Fine-tune a foundation model with Azure Machine Learning](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)         | کاتالوگ مدل در Azure Machine Learning بسیاری از مدل‌های منبع باز را ارائه می‌دهد که می‌توانید برای وظیفه خاص خود تنظیم دقیق کنید. این ماژول را امتحان کنید [از مسیر یادگیری AzureML Generative AI](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst) |
| **آموزش:** [Azure OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                | تنظیم دقیق مدل‌های GPT-3.5 یا GPT-4 در Microsoft Azure با استفاده از W&B امکان ردیابی و تحلیل دقیق عملکرد مدل را فراهم می‌کند. این راهنما مفاهیم راهنمای تنظیم دقیق OpenAI را با مراحل و ویژگی‌های خاص برای Azure OpenAI گسترش می‌دهد.                                                                         |
|                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                               |

## 2. منابع ثانویه

این بخش منابع اضافی را ثبت می‌کند که ارزش بررسی دارند، اما ما در این درس زمانی برای پوشش دادن آن‌ها نداشتیم. ممکن است در درس آینده یا به عنوان گزینه تکلیف ثانویه، در تاریخ بعدی پوشش داده شوند. فعلاً از آن‌ها برای ساخت تخصص و دانش خود در این موضوع استفاده کنید.

| عنوان/لینک                                                                                                                                                                                                            | توضیحات                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI Cookbook**: [Data preparation and analysis for chat model fine-tuning](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                                      | این نوت‌بوک به عنوان ابزاری برای پیش‌پردازش و تحلیل مجموعه داده چت که برای تنظیم دقیق مدل چت استفاده می‌شود، خدمت می‌کند. فرمت خطاها را بررسی می‌کند، آمار پایه را ارائه می‌دهد و تعداد توکن‌ها را برای هزینه‌های تنظیم دقیق تخمین می‌زند. ببینید: [روش تنظیم دقیق برای gpt-3.5-turbo](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst).                                                                                                                                                                   |
| **OpenAI Cookbook**: [Fine-Tuning for Retrieval Augmented Generation (RAG) with Qdrant](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst) | هدف این نوت‌بوک این است که از طریق یک مثال جامع نحوه تنظیم دقیق مدل‌های OpenAI برای تولید افزوده بازیابی (RAG) را نشان دهد. همچنین ما Qdrant و یادگیری چند‌نمونه‌ای را برای افزایش عملکرد مدل و کاهش ساختگی‌ها یکپارچه خواهیم کرد.                                                                                                                                                                                                                                                                |
| **OpenAI Cookbook**: [Fine-tuning GPT with Weights & Biases](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                             | Weights & Biases (W&B) پلتفرم توسعه‌دهنده AI است، با ابزارهایی برای آموزش مدل‌ها، تنظیم دقیق مدل‌ها و استفاده از مدل‌های پایه. ابتدا راهنمای [تنظیم دقیق OpenAI](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst) آن‌ها را بخوانید، سپس تمرین Cookbook را امتحان کنید.                                                                                                                                                                                                                  |
| **Community Tutorial** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - fine-tuning for Small Language Models                                                   | آشنا شوید با [Phi-2](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst)، مدل کوچک جدید مایکروسافت، به طرز شگفت‌انگیزی قدرتمند و در عین حال فشرده. این آموزش شما را از طریق تنظیم دقیق Phi-2 راهنمایی می‌کند و نشان می‌دهد چگونه یک مجموعه داده منحصر به فرد بسازید و مدل را با استفاده از QLoRA تنظیم دقیق کنید.                                                                                                                                                                       |
| **Hugging Face Tutorial** [How to Fine-Tune LLMs in 2024 with Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | این پست وبلاگ شما را از طریق نحوه تنظیم دقیق LLM های باز با استفاده از Hugging Face TRL، ترانسفورمرها و مجموعه داده‌ها در سال 2024 راهنمایی می‌کند. شما یک مورد استفاده تعریف می‌کنید، محیط توسعه را تنظیم می‌کنید، یک مجموعه داده آماده می‌کنید، مدل را تنظیم دقیق می‌کنید، آن را آزمایش و ارزیابی می‌کنید، سپس آن را به تولید مستقر می‌کنید.                                                                                                                                                                                                                                                                |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                            | آموزش و استقرار سریع‌تر و آسان‌تر [مدل‌های پیشرفته یادگیری ماشین](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst). مخزن دارای آموزش‌های مناسب برای Colab با راهنمای ویدیویی YouTube، برای تنظیم دقیق است. **بازتاب‌دهنده به‌روزرسانی اخیر [local-first](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst) است** . مستندات [AutoTrain](https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst) را بخوانید. |
|                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را رعایت کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است حاوی خطاها یا نادرستی‌ها باشند. سند اصلی به زبان مادری باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما مسئولیت هیچ گونه سوء تفاهم یا سوء تعبیر ناشی از استفاده از این ترجمه را نمی‌پذیریم.