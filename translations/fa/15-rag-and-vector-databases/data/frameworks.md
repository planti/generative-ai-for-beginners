<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5466bcedc3c75aa35476270362f626a",
  "translation_date": "2025-05-20T01:50:05+00:00",
  "source_file": "15-rag-and-vector-databases/data/frameworks.md",
  "language_code": "fa"
}
-->
# چارچوب‌های شبکه عصبی

همانطور که قبلاً یاد گرفته‌ایم، برای آموزش شبکه‌های عصبی به صورت مؤثر باید دو کار انجام دهیم:

* کار با تنسورها، مثلاً ضرب، جمع و محاسبه برخی از توابع مانند سیگموید یا سافت‌مکس
* محاسبه گرادیان‌ها برای تمام عبارات، به منظور انجام بهینه‌سازی نزول گرادیان

در حالی که کتابخانه `numpy` می‌تواند بخش اول را انجام دهد، ما به مکانیزمی برای محاسبه گرادیان‌ها نیاز داریم. در چارچوبی که در بخش قبلی توسعه داده‌ایم، مجبور بودیم همه توابع مشتق را به صورت دستی درون روش `backward` که بک‌پراپگیشن را انجام می‌دهد، برنامه‌ریزی کنیم. ایده‌آل این است که یک چارچوب به ما امکان محاسبه گرادیان‌های *هر عبارت* که می‌توانیم تعریف کنیم را بدهد.

یک نکته مهم دیگر این است که بتوانیم محاسبات را روی GPU یا هر واحد محاسباتی تخصصی دیگر مانند TPU انجام دهیم. آموزش شبکه‌های عصبی عمیق به *محاسبات زیادی* نیاز دارد و توانایی موازی‌سازی این محاسبات روی GPU‌ها بسیار مهم است.

> ✅ اصطلاح 'موازی‌سازی' به معنای توزیع محاسبات بر روی چندین دستگاه است.

در حال حاضر، دو چارچوب عصبی محبوب: TensorFlow و PyTorch هستند. هر دو API سطح پایین برای کار با تنسورها روی CPU و GPU ارائه می‌دهند. بر روی API سطح پایین، یک API سطح بالا نیز وجود دارد که به ترتیب Keras و PyTorch Lightning نامیده می‌شود.

API سطح پایین | TensorFlow| PyTorch
--------------|-------------------------------------|--------------------------------
API سطح بالا| Keras| Pytorch

**API‌های سطح پایین** در هر دو چارچوب به شما اجازه می‌دهند تا **گراف‌های محاسباتی** ایجاد کنید. این گراف تعریف می‌کند که چگونه خروجی (معمولاً تابع زیان) با پارامترهای ورودی داده شده محاسبه شود و می‌تواند برای محاسبه روی GPU ارسال شود، اگر موجود باشد. توابعی وجود دارند که این گراف محاسباتی را تفکیک کرده و گرادیان‌ها را محاسبه می‌کنند، که سپس می‌توانند برای بهینه‌سازی پارامترهای مدل استفاده شوند.

**API‌های سطح بالا** شبکه‌های عصبی را به عنوان **توالی لایه‌ها** در نظر می‌گیرند و ساخت اکثر شبکه‌های عصبی را بسیار آسان‌تر می‌کنند. آموزش مدل معمولاً نیاز به آماده‌سازی داده‌ها و سپس فراخوانی یک تابع `fit` برای انجام کار دارد.

API سطح بالا به شما اجازه می‌دهد تا شبکه‌های عصبی معمولی را بسیار سریع بسازید بدون اینکه نگران جزئیات زیادی باشید. در عین حال، API سطح پایین کنترل بیشتری بر فرآیند آموزش ارائه می‌دهد و بنابراین در تحقیقات بسیار استفاده می‌شود، زمانی که با معماری‌های جدید شبکه عصبی سروکار دارید.

همچنین مهم است که بفهمید که می‌توانید از هر دو API با هم استفاده کنید، مثلاً می‌توانید معماری لایه شبکه خود را با استفاده از API سطح پایین توسعه دهید و سپس آن را در شبکه بزرگتری که با API سطح بالا ساخته و آموزش داده شده است استفاده کنید. یا می‌توانید یک شبکه را با استفاده از API سطح بالا به عنوان توالی لایه‌ها تعریف کنید و سپس از حلقه آموزشی سطح پایین خود برای انجام بهینه‌سازی استفاده کنید. هر دو API از همان مفاهیم پایه‌ای استفاده می‌کنند و طراحی شده‌اند که با هم خوب کار کنند.

## یادگیری

در این دوره، ما بیشتر محتوا را هم برای PyTorch و هم برای TensorFlow ارائه می‌دهیم. شما می‌توانید چارچوب مورد نظر خود را انتخاب کنید و فقط از دفترچه‌های مربوطه عبور کنید. اگر مطمئن نیستید کدام چارچوب را انتخاب کنید، برخی از بحث‌ها در اینترنت را درباره **PyTorch vs. TensorFlow** بخوانید. همچنین می‌توانید نگاهی به هر دو چارچوب بیندازید تا درک بهتری پیدا کنید.

در صورت امکان، از API‌های سطح بالا برای سادگی استفاده خواهیم کرد. با این حال، ما معتقدیم که درک نحوه عملکرد شبکه‌های عصبی از پایه بسیار مهم است، بنابراین در ابتدا با API سطح پایین و تنسورها شروع می‌کنیم. اما اگر می‌خواهید سریع شروع کنید و نمی‌خواهید زمان زیادی را صرف یادگیری این جزئیات کنید، می‌توانید آنها را رد کنید و مستقیم به دفترچه‌های API سطح بالا بروید.

## ✍️ تمرینات: چارچوب‌ها

یادگیری خود را در دفترچه‌های زیر ادامه دهید:

API سطح پایین | دفترچه TensorFlow+Keras | PyTorch
--------------|-------------------------------------|--------------------------------
API سطح بالا| Keras | *PyTorch Lightning*

پس از تسلط بر چارچوب‌ها، بیایید مفهوم بیش‌برازش را مرور کنیم.

# بیش‌برازش

بیش‌برازش یک مفهوم بسیار مهم در یادگیری ماشین است و بسیار مهم است که آن را درست درک کنیم!

به مشکل زیر در تقریب 5 نقطه (نمایش داده شده با `x` در نمودارهای زیر) توجه کنید:

!خطی | بیش‌برازش
-------------------------|--------------------------
**مدل خطی، 2 پارامتر** | **مدل غیرخطی، 7 پارامتر**
خطای آموزش = 5.3 | خطای آموزش = 0
خطای اعتبارسنجی = 5.1 | خطای اعتبارسنجی = 20

* در سمت چپ، یک تقریب خطی خوب می‌بینیم. زیرا تعداد پارامترها مناسب است، مدل ایده پشت توزیع نقاط را درست درک می‌کند.
* در سمت راست، مدل بسیار قدرتمند است. زیرا فقط 5 نقطه داریم و مدل دارای 7 پارامتر است، می‌تواند به گونه‌ای تنظیم شود که از همه نقاط عبور کند، و خطای آموزش را به 0 برساند. با این حال، این مانع از فهم مدل از الگوی صحیح پشت داده‌ها می‌شود، بنابراین خطای اعتبارسنجی بسیار بالا است.

بسیار مهم است که تعادل صحیح بین غنای مدل (تعداد پارامترها) و تعداد نمونه‌های آموزشی را برقرار کنیم.

## چرا بیش‌برازش رخ می‌دهد

  * داده آموزشی کافی نیست
  * مدل بسیار قدرتمند
  * نویز زیاد در داده‌های ورودی

## چگونه بیش‌برازش را تشخیص دهیم

همانطور که از نمودار بالا می‌بینید، بیش‌برازش را می‌توان با خطای آموزشی بسیار کم و خطای اعتبارسنجی بالا تشخیص داد. معمولاً در طول آموزش می‌بینیم که هر دو خطای آموزشی و اعتبارسنجی شروع به کاهش می‌کنند، و سپس در یک نقطه خطای اعتبارسنجی ممکن است متوقف شود و شروع به افزایش کند. این نشانه‌ای از بیش‌برازش است و نشان‌دهنده این است که احتمالاً باید در این نقطه آموزش را متوقف کنیم (یا حداقل یک عکس فوری از مدل بگیریم).

بیش‌برازش

## چگونه بیش‌برازش را جلوگیری کنیم

اگر می‌بینید که بیش‌برازش رخ می‌دهد، می‌توانید یکی از کارهای زیر را انجام دهید:

 * مقدار داده آموزشی را افزایش دهید
 * پیچیدگی مدل را کاهش دهید
 * از تکنیک‌های تنظیم استفاده کنید، مانند Dropout که بعداً به آن خواهیم پرداخت.

## بیش‌برازش و تعادل اریبی-واریانس

بیش‌برازش در واقع یک مورد از یک مشکل عمومی‌تر در آمار به نام تعادل اریبی-واریانس است. اگر منابع احتمالی خطا در مدل خود را در نظر بگیریم، می‌توانیم دو نوع خطا را ببینیم:

* **خطاهای اریبی** ناشی از عدم توانایی الگوریتم ما در درک رابطه بین داده‌های آموزشی به درستی است. این می‌تواند ناشی از این باشد که مدل ما به اندازه کافی قدرتمند نیست (**کم‌برازش**).
* **خطاهای واریانس**، که ناشی از مدل در تقریب نویز در داده‌های ورودی به جای رابطه معنادار است (**بیش‌برازش**).

در طول آموزش، خطای اریبی کاهش می‌یابد (همانطور که مدل ما یاد می‌گیرد داده‌ها را تقریب کند) و خطای واریانس افزایش می‌یابد. مهم است که آموزش را متوقف کنیم - یا به صورت دستی (زمانی که بیش‌برازش را تشخیص می‌دهیم) یا به صورت خودکار (با معرفی تنظیم) - تا از بیش‌برازش جلوگیری کنیم.

## نتیجه‌گیری

در این درس، شما تفاوت‌های بین API‌های مختلف برای دو چارچوب محبوب AI، TensorFlow و PyTorch را یاد گرفتید. علاوه بر این، شما درباره یک موضوع بسیار مهم، بیش‌برازش، یاد گرفتید.

## 🚀 چالش

در دفترچه‌های همراه، در پایین 'وظایف'ی پیدا خواهید کرد؛ دفترچه‌ها را مرور کنید و وظایف را کامل کنید.

## مرور و مطالعه شخصی

تحقیقی درباره موضوعات زیر انجام دهید:

- TensorFlow
- PyTorch
- بیش‌برازش

از خودتان بپرسید:

- تفاوت بین TensorFlow و PyTorch چیست؟
- تفاوت بین بیش‌برازش و کم‌برازش چیست؟

## تکلیف

در این آزمایشگاه، از شما خواسته می‌شود تا دو مشکل طبقه‌بندی را با استفاده از شبکه‌های کاملاً متصل تک‌لایه و چندلایه با استفاده از PyTorch یا TensorFlow حل کنید.

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما برای دقت تلاش می‌کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان مادری آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حیاتی، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما مسئولیتی در قبال هرگونه سوء تفاهم یا تفسیر نادرست ناشی از استفاده از این ترجمه نداریم.