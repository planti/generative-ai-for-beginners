<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:29:28+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "mo"
}
-->
# مصادر للتعلم الذاتي

تم بناء الدرس باستخدام عدد من الموارد الأساسية من OpenAI وAzure OpenAI كمراجع للمصطلحات والدروس. إليك قائمة غير شاملة، لرحلات التعلم الذاتي الخاصة بك.

## 1. الموارد الأساسية

| العنوان/الرابط                                                                                                                                                                                                                   | الوصف                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Fine-tuning with OpenAI Models](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                       | يحسن التعديل الدقيق على التعلم القليل من الأمثلة من خلال التدريب على العديد من الأمثلة التي يمكن أن تتناسب مع النص الموجه، مما يوفر لك التكاليف، ويحسن جودة الاستجابة، ويمكّن الطلبات ذات زمن الانتقال المنخفض. **احصل على نظرة عامة عن التعديل الدقيق من OpenAI.**                                                                                    |
| [What is Fine-Tuning with Azure OpenAI?](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                   | فهم **ما هو التعديل الدقيق (المفهوم)**، ولماذا يجب عليك النظر فيه (المشكلة المحفزة)، وما البيانات التي يجب استخدامها (التدريب) وقياس الجودة.                                                                                                                                                                           |
| [Customize a model with fine-tuning](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst) | تتيح لك خدمة Azure OpenAI تخصيص نماذجنا لمجموعات البيانات الشخصية الخاصة بك باستخدام التعديل الدقيق. تعرف على **كيفية التعديل الدقيق (العملية)** لاختيار النماذج باستخدام Azure AI Studio أو Python SDK أو REST API.                                                                                                                                |
| [Recommendations for LLM fine-tuning](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                    | قد لا تؤدي النماذج اللغوية الكبيرة بشكل جيد في مجالات محددة أو مهام أو مجموعات بيانات، أو قد تنتج مخرجات غير دقيقة أو مضللة. **متى يجب أن تنظر في التعديل الدقيق** كحل محتمل لهذا؟                                                                                                                                  |
| [Continuous Fine Tuning](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)             | التعديل الدقيق المستمر هو عملية تكرارية لاختيار نموذج تم تعديله بالفعل كنموذج أساسي و**تعديله بشكل أكبر** على مجموعات جديدة من أمثلة التدريب.                                                                                                                                                     |
| [Fine-tuning and function calling](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                       | يمكن أن يحسن التعديل الدقيق لنموذجك **مع أمثلة استدعاء الدوال** من مخرجات النموذج عن طريق الحصول على مخرجات أكثر دقة واتساقًا - مع استجابات مهيكلة بشكل مشابه وتوفير في التكاليف.                                                                                                                                        |
| [Fine-tuning Models: Azure OpenAI Guidance](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                                        | انظر إلى هذه الجدول لفهم **ما النماذج التي يمكن تعديلها** في Azure OpenAI، وفي أي المناطق تتوفر. تحقق من حدود الرموز وتواريخ انتهاء صلاحية بيانات التدريب إذا لزم الأمر.                                                                                                                            |
| [To Fine Tune or Not To Fine Tune? That is the Question](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                      | تناقش هذه الحلقة التي تبلغ مدتها 30 دقيقة **أكتوبر 2023** من عرض AI الفوائد والعيوب والرؤى العملية التي تساعدك على اتخاذ هذا القرار.                                                                                                                                                                                        |
| [Getting Started With LLM Fine-Tuning](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                             | يقدم هذا المورد من **AI Playbook** متطلبات البيانات والتنسيق والتحديات/القيود التي يجب أن تعرفها عند التعديل الدقيق.                                                                                                                                                                         |
| **Tutorial**: [Azure OpenAI GPT3.5 Turbo Fine-Tuning](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                                  | تعلم كيفية إنشاء مجموعة بيانات للتعديل الدقيق، التحضير للتعديل الدقيق، إنشاء وظيفة تعديل دقيق، ونشر النموذج المعدل على Azure.                                                                                                                                                                                    |
| **Tutorial**: [Fine-tune a Llama 2 model in Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                                      | يتيح لك Azure AI Studio تخصيص النماذج اللغوية الكبيرة لمجموعات البيانات الشخصية الخاصة بك _باستخدام سير عمل يستند إلى واجهة المستخدم مناسب للمطورين منخفضي الكود_. انظر هذا المثال.                                                                                                                                                               |
| **Tutorial**:[Fine-tune Hugging Face models for a single GPU on Azure](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)               | يصف هذا المقال كيفية تعديل نموذج Hugging Face باستخدام مكتبة المحولات Hugging Face على وحدة معالجة رسومات واحدة مع Azure DataBricks + مكتبات Hugging Face Trainer.                                                                                                                                                |
| **Training:** [Fine-tune a foundation model with Azure Machine Learning](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)         | يقدم كتالوج النماذج في Azure Machine Learning العديد من النماذج مفتوحة المصدر التي يمكنك تعديلها لتناسب مهمتك المحددة. جرب هذا الوحدة [من مسار التعلم AzureML Generative AI](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst). |
| **Tutorial:** [Azure OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                | يتيح لك التعديل الدقيق لنماذج GPT-3.5 أو GPT-4 على Microsoft Azure باستخدام W&B تتبع وتحليل مفصل لأداء النموذج. يمتد هذا الدليل من مفاهيم دليل التعديل الدقيق من OpenAI مع خطوات وميزات محددة لـ Azure OpenAI.                                                                         |
|                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                               |

## 2. الموارد الثانوية

تلتقط هذه القسم موارد إضافية تستحق الاستكشاف، ولكن لم يكن لدينا الوقت لتغطيتها في هذا الدرس. قد يتم تغطيتها في درس مستقبلي، أو كخيار واجب ثانوي، في وقت لاحق. في الوقت الحالي، استخدمها لبناء خبرتك ومعرفتك حول هذا الموضوع.

| العنوان/الرابط                                                                                                                                                                                                            | الوصف                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI Cookbook**: [Data preparation and analysis for chat model fine-tuning](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                                      | يعمل هذا الدفتر كأداة لمعالجة وتحليل مجموعة بيانات الدردشة المستخدمة لتعديل نموذج الدردشة. يتحقق من أخطاء التنسيق، يوفر إحصائيات أساسية، ويقدر عدد الرموز لتكاليف التعديل الدقيق. انظر: [طريقة التعديل الدقيق لـ gpt-3.5-turbo](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst).                                                                                                                                                                   |
| **OpenAI Cookbook**: [Fine-Tuning for Retrieval Augmented Generation (RAG) with Qdrant](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst) | يهدف هذا الدفتر إلى المرور بمثال شامل لكيفية تعديل نماذج OpenAI لتوليد البيانات المعززة (RAG). سنقوم أيضًا بدمج Qdrant والتعلم من عدد قليل من الأمثلة لتعزيز أداء النموذج وتقليل الاختلاقات.                                                                                                                                                                                                                                                                |
| **OpenAI Cookbook**: [Fine-tuning GPT with Weights & Biases](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                             | Weights & Biases (W&B) هي منصة مطوري الذكاء الاصطناعي، مع أدوات لتدريب النماذج، تعديل النماذج، والاستفادة من النماذج الأساسية. اقرأ دليلهم [OpenAI Fine-Tuning](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst) أولاً، ثم جرب تمرين Cookbook.                                                                                                                                                                                                                  |
| **Community Tutorial** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - fine-tuning for Small Language Models                                                   | تعرف على [Phi-2](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst)، النموذج الصغير الجديد من Microsoft، القوي بشكل مذهل ولكنه مضغوط. سيرشدك هذا الدليل خلال عملية تعديل Phi-2، موضحًا كيفية بناء مجموعة بيانات فريدة وتعديل النموذج باستخدام QLoRA.                                                                                                                                                                       |
| **Hugging Face Tutorial** [How to Fine-Tune LLMs in 2024 with Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | تقدم هذه المقالة الإرشادية كيفية تعديل النماذج اللغوية الكبيرة المفتوحة باستخدام Hugging Face TRL وTransformers وdatasets في عام 2024. تقوم بتحديد حالة استخدام، إعداد بيئة تطوير، إعداد مجموعة بيانات، تعديل النموذج، اختباره وتقييمه، ثم نشره في الإنتاج.                                                                                                                                                                                                                                                                |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                            | يقدم تدريبًا ونشرًا أسرع وأسهل [لنماذج التعلم الآلي الحديثة](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst). يحتوي المستودع على دروس تعليمية متوافقة مع Colab مع إرشادات فيديو على YouTube، للتعديل الدقيق. **يعكس التحديث الأخير [المحلي أولاً](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst)**. اقرأ [وثائق AutoTrain](https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst) |
|                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |

I'm sorry, but I'm unable to provide a translation into "mo" as it is not a recognized language code for translation purposes. If "mo" refers to a specific language, could you please clarify which language it is?