<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:48:04+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "hu"
}
-->
# Önálló Tanulási Erőforrások

A lecke az OpenAI és az Azure OpenAI számos alapvető forrásának felhasználásával készült, amelyek referenciaként szolgáltak a terminológiához és a bemutatókhoz. Íme egy nem teljes lista, hogy saját tanulási utazásaitokhoz használhassátok.

## 1. Elsődleges Erőforrások

| Cím/Link                                                                                                                                                                                                                   | Leírás                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Finomhangolás OpenAI Modellekkel](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                       | A finomhangolás javítja a kevés példás tanulást azáltal, hogy sokkal több példán tanul, mint amennyit a promptba lehet illeszteni, ezzel költségeket takarít meg, javítja a válaszok minőségét, és lehetővé teszi az alacsonyabb késleltetésű kéréseket. **Szerezzen áttekintést az OpenAI finomhangolásáról.**                                                                                    |
| [Mi az a finomhangolás az Azure OpenAI-val?](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                   | Értsd meg, **mi a finomhangolás (fogalom)**, miért érdemes megfontolni (motiváló probléma), milyen adatokat használj (képzés) és a minőség mérését                                                                                                                                                                           |
| [Egy modell testreszabása finomhangolással](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst) | Az Azure OpenAI Szolgáltatás lehetővé teszi, hogy modelljeinket személyes adatbázisokra szabja finomhangolással. Tanulja meg, **hogyan finomhangoljon (folyamat)** kiválasztott modelleket az Azure AI Stúdió, Python SDK vagy REST API használatával.                                                                                                                                |
| [Ajánlások LLM finomhangoláshoz](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                    | Az LLM-ek nem biztos, hogy jól teljesítenek bizonyos területeken, feladatokon vagy adatkészleteken, vagy pontatlan vagy félrevezető kimeneteket hozhatnak létre. **Mikor érdemes megfontolni a finomhangolást** mint lehetséges megoldást erre?                                                                                                                                  |
| [Folyamatos finomhangolás](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)             | A folyamatos finomhangolás az a folyamat, amely során egy már finomhangolt modellt alapmodellként választunk, és **tovább finomhangoljuk** új képzési példák halmazán.                                                                                                                                                     |
| [Finomhangolás és függvényhívás](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                       | A modell finomhangolása **függvényhívási példákkal** javíthatja a modell kimenetét azáltal, hogy pontosabb és következetesebb kimeneteket eredményez - hasonló formátumú válaszokkal és költségmegtakarítással                                                                                                                                        |
| [Finomhangoló modellek: Azure OpenAI útmutató](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                                        | Nézze meg ezt a táblázatot, hogy megértse, **milyen modellek finomhangolhatók** az Azure OpenAI-ban, és mely régiókban érhetők el. Nézze meg a token korlátokat és a képzési adatok lejárati dátumait, ha szükséges.                                                                                                                            |
| [Finomhangolni vagy nem finomhangolni? Ez itt a kérdés](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                      | Az AI Show **2023 októberi** 30 perces epizódja tárgyalja az előnyöket, hátrányokat és gyakorlati betekintéseket, amelyek segítenek ebben a döntésben.                                                                                                                                                                                        |
| [Kezdő lépések az LLM finomhangolással](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                             | Ez az **AI Playbook** forrás végigvezeti Önt az adatkövetelményeken, formázáson, hiperparaméter finomhangoláson és azokon a kihívásokon/korlátokon, amelyeket ismernie kell.                                                                                                                                                                         |
| **Bemutató**: [Azure OpenAI GPT3.5 Turbo finomhangolás](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                                  | Tanulja meg, hogyan hozzon létre egy minta finomhangolási adatbázist, hogyan készüljön fel a finomhangolásra, hogyan hozzon létre finomhangolási munkát, és hogyan telepítse a finomhangolt modellt az Azure-ra.                                                                                                                                                                                    |
| **Bemutató**: [Llama 2 modell finomhangolása az Azure AI Stúdióban](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                                      | Az Azure AI Stúdió lehetővé teszi, hogy nagy nyelvi modelleket személyes adatbázisokra szabjon _egy UI-alapú munkafolyamat segítségével, amely alacsony kódú fejlesztők számára megfelelő_. Nézze meg ezt a példát.                                                                                                                                                               |
| **Bemutató**: [Hugging Face modellek finomhangolása egyetlen GPU-ra az Azure-on](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)               | Ez a cikk leírja, hogyan lehet finomhangolni egy Hugging Face modellt a Hugging Face transformers könyvtárral egyetlen GPU-val az Azure DataBricks + Hugging Face Trainer könyvtárak segítségével                                                                                                                                                |
| **Képzés:** [Alapmodell finomhangolása az Azure Machine Learning segítségével](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)         | Az Azure Machine Learning modellkatalógusa számos nyílt forráskódú modellt kínál, amelyeket az Ön specifikus feladatához finomhangolhat. Próbálja ki ezt a modult [az AzureML Generatív AI Tanulási Útvonalból](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst) |
| **Bemutató:** [Azure OpenAI finomhangolás](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                | A GPT-3.5 vagy GPT-4 modellek finomhangolása a Microsoft Azure-on a W&B segítségével lehetővé teszi a modell teljesítményének részletes nyomon követését és elemzését. Ez az útmutató az OpenAI Finomhangolási útmutatóból származó koncepciókat bővíti az Azure OpenAI-ra vonatkozó specifikus lépésekkel és funkciókkal.                                                                         |
|                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                               |

## 2. Másodlagos Erőforrások

Ez a szakasz további erőforrásokat tartalmaz, amelyek érdemesek lehetnek a felfedezésre, de amelyekre ebben a leckében nem volt időnk kitérni. Ezeket egy jövőbeli leckében, vagy egy másodlagos feladatként, egy későbbi időpontban lehet lefedni. Egyelőre használjátok őket a saját szakértelmetek és tudásotok bővítésére ebben a témában.

| Cím/Link                                                                                                                                                                                                            | Leírás                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI Cookbook**: [Adatelőkészítés és elemzés csevegő modell finomhangoláshoz](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                                      | Ez a jegyzetfüzet eszközként szolgál a csevegési adatkészlet előfeldolgozásához és elemzéséhez, amelyet egy csevegő modell finomhangolásához használnak. Ellenőrzi a formátumhibákat, alapvető statisztikákat biztosít, és becsléseket készít a finomhangolási költségek token számaira. Lásd: [Finomhangolási módszer a gpt-3.5-turbo számára](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst).                                                                                                                                                                   |
| **OpenAI Cookbook**: [Finomhangolás Visszakeresés Augmentált Generálás (RAG) Qdranttal](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst) | Ennek a jegyzetfüzetnek a célja, hogy átfogó példát mutasson be arra, hogyan lehet finomhangolni az OpenAI modelleket a Visszakeresés Augmentált Generálás (RAG) számára. Integrálni fogjuk a Qdrantot és a Kevés Példás Tanulást is, hogy növeljük a modell teljesítményét és csökkentsük a téves információkat.                                                                                                                                                                                                                                                                |
| **OpenAI Cookbook**: [GPT finomhangolása Weights & Biases segítségével](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                             | A Weights & Biases (W&B) az AI fejlesztői platform, eszközökkel a modellek képzéséhez, finomhangolásához és alapmodellek kihasználásához. Olvassa el a [OpenAI Finomhangolás](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst) útmutatót először, majd próbálja ki a Cookbook gyakorlatot.                                                                                                                                                                                                                  |
| **Közösségi Bemutató** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - finomhangolás kis nyelvi modellekhez                                                   | Ismerje meg [Phi-2](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst), a Microsoft új kis modelljét, amely meglepően erős, mégis kompakt. Ez a bemutató végigvezeti Önt a Phi-2 finomhangolásán, bemutatva, hogyan építsen egyedi adatkészletet és hogyan finomhangolja a modellt QLoRA segítségével.                                                                                                                                                                       |
| **Hugging Face Bemutató** [Hogyan finomhangoljunk LLM-eket 2024-ben a Hugging Face segítségével](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | Ez a blogbejegyzés végigvezeti Önt, hogyan finomhangoljon nyitott LLM-eket a Hugging Face TRL, Transformers & adatkészletek segítségével 2024-ben. Meghatároz egy felhasználási esetet, beállít egy fejlesztői környezetet, előkészít egy adatkészletet, finomhangolja a modellt, teszteli-értékeli, majd telepíti a gyártásba.                                                                                                                                                                                                                                                                |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                            | Gyorsabb és könnyebb képzést és telepítést biztosít [csúcstechnológiájú gépi tanulási modellekhez](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst). A repó Colab-barát bemutatókat tartalmaz YouTube videó útmutatással, a finomhangoláshoz. **Tükrözi a legújabb [helyi-először](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst) frissítést**. Olvassa el az [AutoTrain dokumentációt](https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst) |
|                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |

**Felelősségkizárás**:  
Ezt a dokumentumot az [Co-op Translator](https://github.com/Azure/co-op-translator) AI fordítószolgáltatással fordították le. Bár törekszünk a pontosságra, kérjük, vegye figyelembe, hogy az automatikus fordítások hibákat vagy pontatlanságokat tartalmazhatnak. Az eredeti dokumentum az anyanyelvén tekintendő a hiteles forrásnak. Kritikus információk esetén javasolt a professzionális emberi fordítás igénybevétele. Nem vállalunk felelősséget a fordítás használatából eredő félreértésekért vagy félreértelmezésekért.