<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "13084c6321a2092841b9a081b29497ba",
  "translation_date": "2025-05-19T14:40:34+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "th"
}
-->
# การใช้ Generative AI อย่างมีความรับผิดชอบ

> _คลิกที่ภาพด้านบนเพื่อดูวิดีโอของบทเรียนนี้_

AI และ Generative AI เป็นสิ่งที่น่าสนใจมาก แต่เราต้องพิจารณาว่าจะใช้อย่างไรให้มีความรับผิดชอบ คุณต้องคำนึงถึงวิธีการทำให้ผลลัพธ์มีความยุติธรรม ไม่เป็นอันตราย และอื่นๆ บทนี้มีเป้าหมายเพื่อให้คุณเข้าใจถึงสิ่งที่ต้องพิจารณา และวิธีการก้าวไปข้างหน้าเพื่อปรับปรุงการใช้ AI ของคุณ

## บทนำ

บทเรียนนี้จะครอบคลุมถึง:

- ทำไมคุณควรให้ความสำคัญกับ AI ที่มีความรับผิดชอบเมื่อสร้างแอปพลิเคชัน Generative AI
- หลักการสำคัญของ AI ที่มีความรับผิดชอบและความสัมพันธ์กับ Generative AI
- วิธีการนำหลักการของ AI ที่มีความรับผิดชอบไปปฏิบัติผ่านกลยุทธ์และเครื่องมือ

## เป้าหมายการเรียนรู้

หลังจากจบบทเรียนนี้ คุณจะรู้ว่า:

- ความสำคัญของ AI ที่มีความรับผิดชอบเมื่อสร้างแอปพลิเคชัน Generative AI
- เมื่อใดควรคิดและประยุกต์ใช้หลักการสำคัญของ AI ที่มีความรับผิดชอบเมื่อสร้างแอปพลิเคชัน Generative AI
- เครื่องมือและกลยุทธ์ที่มีอยู่เพื่อใช้แนวคิดของ AI ที่มีความรับผิดชอบ

## หลักการของ AI ที่มีความรับผิดชอบ

ความตื่นเต้นใน Generative AI ไม่เคยสูงเท่านี้มาก่อน ความตื่นเต้นนี้นำพานักพัฒนาใหม่ๆ ความสนใจ และการลงทุนมากมายเข้ามา แม้ว่านี่จะเป็นสิ่งที่ดีสำหรับผู้ที่ต้องการสร้างผลิตภัณฑ์และบริษัทโดยใช้ Generative AI แต่ก็สำคัญที่เราต้องดำเนินการอย่างมีความรับผิดชอบ

ตลอดหลักสูตรนี้ เรามุ่งเน้นไปที่การสร้างสตาร์ทอัพและผลิตภัณฑ์การศึกษา AI ของเรา เราจะใช้หลักการของ AI ที่มีความรับผิดชอบ: ความยุติธรรม, การรวมกลุ่ม, ความน่าเชื่อถือ/ความปลอดภัย, ความปลอดภัยและความเป็นส่วนตัว, ความโปร่งใส และความรับผิดชอบ ด้วยหลักการเหล่านี้ เราจะสำรวจว่าพวกเขาเกี่ยวข้องกับการใช้ Generative AI ในผลิตภัณฑ์ของเราอย่างไร

## ทำไมคุณควรให้ความสำคัญกับ AI ที่มีความรับผิดชอบ

เมื่อสร้างผลิตภัณฑ์ การใช้วิธีการที่มีผู้ใช้เป็นศูนย์กลางโดยคำนึงถึงผลประโยชน์สูงสุดของผู้ใช้จะนำไปสู่ผลลัพธ์ที่ดีที่สุด

ความพิเศษของ Generative AI คือความสามารถในการสร้างคำตอบ ข้อมูล คำแนะนำ และเนื้อหาที่เป็นประโยชน์สำหรับผู้ใช้ ซึ่งสามารถทำได้โดยไม่ต้องใช้ขั้นตอนด้วยตนเองมากมาย ซึ่งอาจนำไปสู่ผลลัพธ์ที่น่าประทับใจมาก แต่หากไม่มีการวางแผนและกลยุทธ์ที่เหมาะสม อาจนำไปสู่ผลลัพธ์ที่เป็นอันตรายต่อผู้ใช้ ผลิตภัณฑ์ และสังคมโดยรวมได้

ลองดูผลลัพธ์ที่อาจเป็นอันตรายบางส่วน:

### การสร้างข้อมูลเท็จ

การสร้างข้อมูลเท็จเป็นคำที่ใช้เมื่อ LLM สร้างเนื้อหาที่ไร้สาระหรือบางสิ่งที่เรารู้ว่าเป็นข้อมูลที่ผิดพลาดจากแหล่งข้อมูลอื่น

ลองนึกภาพว่าเราสร้างฟีเจอร์สำหรับสตาร์ทอัพของเราที่ให้นักเรียนถามคำถามทางประวัติศาสตร์กับโมเดล นักเรียนถามคำถาม `Who was the sole survivor of Titanic?`

โมเดลสร้างคำตอบเช่นนี้:

นี่เป็นคำตอบที่มั่นใจและละเอียด แต่โชคไม่ดีที่ไม่ถูกต้อง แม้จะมีการค้นคว้าเพียงเล็กน้อย ก็จะพบว่ามีผู้รอดชีวิตจากภัยพิบัติไททานิคมากกว่าหนึ่งคน สำหรับนักเรียนที่เพิ่งเริ่มต้นค้นคว้าหัวข้อนี้ คำตอบนี้อาจน่าเชื่อพอที่จะไม่ถูกตั้งคำถามและถูกปฏิบัติเหมือนเป็นข้อเท็จจริง ผลที่ตามมาคือระบบ AI อาจไม่น่าเชื่อถือและส่งผลกระทบต่อชื่อเสียงของสตาร์ทอัพของเรา

แม้ว่าแต่ละการปรับปรุงของ LLM จะมีการปรับปรุงประสิทธิภาพในการลดการสร้างข้อมูลเท็จ แต่เรายังต้องตระหนักถึงข้อจำกัดเหล่านี้ในฐานะผู้สร้างแอปพลิเคชันและผู้ใช้

### เนื้อหาที่เป็นอันตราย

เราได้พูดถึงในส่วนก่อนหน้าว่าเมื่อ LLM สร้างคำตอบที่ไม่ถูกต้องหรือไร้สาระ อีกความเสี่ยงที่เราต้องระวังคือเมื่อโมเดลตอบกลับด้วยเนื้อหาที่เป็นอันตราย

เนื้อหาที่เป็นอันตรายสามารถนิยามได้ว่า:

- ให้คำแนะนำหรือส่งเสริมการทำร้ายตนเองหรือกลุ่มคนบางกลุ่ม
- เนื้อหาที่เกลียดชังหรือดูถูก
- ชี้แนะการวางแผนโจมตีหรือการกระทำที่รุนแรง
- ให้คำแนะนำในการค้นหาเนื้อหาที่ผิดกฎหมายหรือกระทำการที่ผิดกฎหมาย
- แสดงเนื้อหาที่มีลักษณะทางเพศอย่างโจ่งแจ้ง

สำหรับสตาร์ทอัพของเรา เราต้องแน่ใจว่าเรามีเครื่องมือและกลยุทธ์ที่เหมาะสมเพื่อป้องกันไม่ให้เนื้อหาประเภทนี้ถูกเห็นโดยนักเรียน

### ขาดความยุติธรรม

ความยุติธรรมหมายถึง "การทำให้แน่ใจว่าระบบ AI ปราศจากอคติและการเลือกปฏิบัติ และปฏิบัติต่อทุกคนอย่างยุติธรรมและเท่าเทียม" ในโลกของ Generative AI เราต้องการให้แน่ใจว่ามุมมองที่กีดกันของกลุ่มที่ถูกกดขี่ไม่ได้รับการเสริมสร้างโดยผลลัพธ์ของโมเดล

ผลลัพธ์ประเภทนี้ไม่เพียงแต่ทำลายประสบการณ์การใช้ผลิตภัณฑ์ที่ดีสำหรับผู้ใช้ของเรา แต่ยังทำให้เกิดอันตรายต่อสังคมในวงกว้าง ในฐานะผู้สร้างแอปพลิเคชัน เราควรคำนึงถึงกลุ่มผู้ใช้ที่หลากหลายและกว้างขวางเสมอเมื่อสร้างโซลูชันด้วย Generative AI

## วิธีใช้ Generative AI อย่างมีความรับผิดชอบ

ตอนนี้ที่เราได้ระบุถึงความสำคัญของ Generative AI ที่มีความรับผิดชอบแล้ว มาดู 4 ขั้นตอนที่เราสามารถทำเพื่อสร้างโซลูชัน AI ของเราอย่างมีความรับผิดชอบ:

### วัดผลอันตรายที่อาจเกิดขึ้น

ในการทดสอบซอฟต์แวร์ เราทดสอบการกระทำที่คาดหวังของผู้ใช้บนแอปพลิเคชัน ในทำนองเดียวกัน การทดสอบชุดคำถามที่หลากหลายที่ผู้ใช้น่าจะใช้เป็นวิธีที่ดีในการวัดผลอันตรายที่อาจเกิดขึ้น

เนื่องจากสตาร์ทอัพของเรากำลังสร้างผลิตภัณฑ์การศึกษา จะเป็นการดีที่จะเตรียมรายการคำถามที่เกี่ยวข้องกับการศึกษา ซึ่งอาจครอบคลุมวิชาหนึ่ง ข้อเท็จจริงทางประวัติศาสตร์ และคำถามเกี่ยวกับชีวิตนักเรียน

### ลดผลอันตรายที่อาจเกิดขึ้น

ถึงเวลาหาวิธีที่เราสามารถป้องกันหรือลดผลอันตรายที่อาจเกิดจากโมเดลและคำตอบของมันได้ เราสามารถดูเรื่องนี้ใน 4 ชั้นต่างๆ:

- **โมเดล**. การเลือกโมเดลที่เหมาะสมสำหรับกรณีการใช้งานที่เหมาะสม โมเดลที่ใหญ่กว่าและซับซ้อนกว่าเช่น GPT-4 อาจมีความเสี่ยงที่จะสร้างเนื้อหาที่เป็นอันตรายมากขึ้นเมื่อใช้กับกรณีการใช้งานที่เล็กกว่าและเฉพาะเจาะจงมากขึ้น การใช้ข้อมูลการฝึกอบรมของคุณเพื่อปรับแต่งก็ช่วยลดความเสี่ยงของเนื้อหาที่เป็นอันตรายได้เช่นกัน

- **ระบบความปลอดภัย**. ระบบความปลอดภัยคือชุดเครื่องมือและการกำหนดค่าบนแพลตฟอร์มที่ให้บริการโมเดลที่ช่วยลดอันตราย ตัวอย่างเช่น ระบบกรองเนื้อหาบนบริการ Azure OpenAI ระบบควรตรวจจับการโจมตีเจลเบรคและกิจกรรมที่ไม่ต้องการเช่นการร้องขอจากบอท

- **Metaprompt**. Metaprompt และ grounding เป็นวิธีที่เราสามารถกำหนดทิศทางหรือจำกัดโมเดลตามพฤติกรรมและข้อมูลบางอย่าง ซึ่งอาจใช้การป้อนข้อมูลระบบเพื่อกำหนดขอบเขตของโมเดล นอกจากนี้ยังสามารถใช้เทคนิคเช่น Retrieval Augmented Generation (RAG) เพื่อให้โมเดลดึงข้อมูลจากแหล่งที่เชื่อถือได้เท่านั้น

- **ประสบการณ์ผู้ใช้**. ชั้นสุดท้ายคือที่ที่ผู้ใช้โต้ตอบกับโมเดลผ่านอินเทอร์เฟซของแอปพลิเคชันของเรา ในวิธีนี้เราสามารถออกแบบ UI/UX เพื่อจำกัดประเภทของข้อมูลที่ผู้ใช้สามารถส่งไปยังโมเดลได้ รวมถึงข้อความหรือภาพที่แสดงให้ผู้ใช้เห็น เมื่อเผยแพร่แอปพลิเคชัน AI เราต้องโปร่งใสเกี่ยวกับสิ่งที่แอปพลิเคชัน Generative AI ของเราสามารถและไม่สามารถทำได้

- **ประเมินโมเดล**. การทำงานกับ LLM อาจเป็นเรื่องท้าทายเพราะเราไม่ได้ควบคุมข้อมูลที่โมเดลได้รับการฝึกอบรมเสมอไป แต่เราควรประเมินประสิทธิภาพและผลลัพธ์ของโมเดลเสมอ การวัดความถูกต้อง ความคล้ายคลึง ความน่าเชื่อถือ และความเกี่ยวข้องของผลลัพธ์ยังคงสำคัญ ช่วยให้เกิดความโปร่งใสและความเชื่อถือจากผู้มีส่วนได้ส่วนเสียและผู้ใช้

### ดำเนินการโซลูชัน Generative AI ที่มีความรับผิดชอบ

การสร้างแนวทางการปฏิบัติในการดำเนินงานรอบแอปพลิเคชัน AI ของคุณเป็นขั้นตอนสุดท้าย ซึ่งรวมถึงการทำงานร่วมกับส่วนอื่นๆ ของสตาร์ทอัพของเรา เช่น ฝ่ายกฎหมายและความปลอดภัยเพื่อให้แน่ใจว่าเราปฏิบัติตามนโยบายกฎระเบียบทั้งหมด ก่อนการเปิดตัว เราต้องการสร้างแผนเกี่ยวกับการส่งมอบ การจัดการเหตุการณ์ และการย้อนกลับเพื่อป้องกันอันตรายต่อผู้ใช้ของเราจากการเติบโต

## เครื่องมือ

แม้ว่างานของการพัฒนาโซลูชัน AI ที่มีความรับผิดชอบอาจดูเหมือนมาก แต่มันก็คุ้มค่ากับความพยายาม ในขณะที่ Generative AI เติบโต เครื่องมือเพิ่มเติมที่ช่วยให้นักพัฒนารวมความรับผิดชอบเข้ากับการทำงานของพวกเขาได้อย่างมีประสิทธิภาพจะพัฒนาขึ้น ตัวอย่างเช่น [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) สามารถช่วยตรวจจับเนื้อหาและภาพที่เป็นอันตรายผ่านการร้องขอ API

## ตรวจสอบความรู้

มีสิ่งใดบ้างที่คุณต้องใส่ใจเพื่อให้แน่ใจว่าการใช้ AI อย่างมีความรับผิดชอบ?

1. คำตอบถูกต้อง
1. การใช้งานที่เป็นอันตราย การที่ AI ไม่ถูกใช้ในทางอาชญากรรม
1. ทำให้แน่ใจว่า AI ปราศจากอคติและการเลือกปฏิบัติ

ตอบ: ข้อ 2 และ 3 ถูกต้อง AI ที่มีความรับผิดชอบช่วยให้คุณพิจารณาวิธีการลดผลกระทบที่เป็นอันตรายและอคติและอื่นๆ

## 🚀 ความท้าทาย

ศึกษาข้อมูลเกี่ยวกับ [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) และดูว่าคุณสามารถนำมาใช้ในงานของคุณได้อย่างไร

## ทำได้ดีมาก, เรียนรู้ต่อไป

หลังจากจบบทเรียนนี้ ตรวจสอบ [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) ของเราเพื่อเพิ่มพูนความรู้เกี่ยวกับ Generative AI ของคุณ!

ไปที่บทเรียนที่ 4 ที่เราจะดู [หลักการพื้นฐานของการสร้าง Prompt](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**คำปฏิเสธความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามเพื่อความถูกต้อง แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่ถูกต้อง เอกสารต้นฉบับในภาษาต้นทางควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลสำคัญ ขอแนะนำให้ใช้บริการแปลภาษามนุษย์มืออาชีพ เราไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความผิดที่เกิดจากการใช้การแปลนี้