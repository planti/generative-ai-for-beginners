<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a45c318dc6ebc2604f35b8b829f93af2",
  "translation_date": "2025-05-19T15:37:25+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "th"
}
-->
# พื้นฐานการสร้าง Prompt

## บทนำ
โมดูลนี้ครอบคลุมแนวคิดและเทคนิคสำคัญในการสร้าง prompt ที่มีประสิทธิภาพสำหรับโมเดล AI สร้างสรรค์ การเขียน prompt ให้ LLM มีความสำคัญมาก การสร้าง prompt อย่างละเอียดสามารถทำให้ได้คำตอบที่มีคุณภาพดีขึ้น แต่คำว่า _prompt_ และ _prompt engineering_ หมายถึงอะไร? และเราจะปรับปรุง prompt _input_ ที่ส่งไปยัง LLM ได้อย่างไร? คำถามเหล่านี้เราจะพยายามตอบในบทนี้และบทถัดไป

_Generative AI_ สามารถสร้างเนื้อหาใหม่ (เช่น ข้อความ รูปภาพ เสียง โค้ด ฯลฯ) เพื่อตอบสนองต่อคำขอของผู้ใช้ โดยใช้ _Large Language Models_ เช่น GPT ของ OpenAI ซึ่งได้รับการฝึกฝนให้ใช้ภาษาธรรมชาติและโค้ด

ผู้ใช้สามารถโต้ตอบกับโมเดลเหล่านี้ได้โดยใช้รูปแบบที่คุ้นเคย เช่น การแชท โดยไม่จำเป็นต้องมีความรู้ทางเทคนิคหรือการฝึกอบรม โมเดลเหล่านี้อิงตาม _prompt_ - ผู้ใช้ส่งข้อความ (prompt) และได้รับคำตอบจาก AI (completion) จากนั้นสามารถ "แชทกับ AI" อย่างต่อเนื่องในบทสนทนาแบบหลายรอบ ปรับปรุง prompt จนกว่าคำตอบจะตรงกับความคาดหวัง

"Prompts" กลายเป็น _อินเทอร์เฟซการเขียนโปรแกรม_ หลักสำหรับแอปพลิเคชัน AI สร้างสรรค์ โดยบอกโมเดลว่าจะทำอะไรและมีผลต่อคุณภาพของคำตอบที่ส่งกลับ "Prompt Engineering" เป็นสาขาการศึกษาที่เติบโตอย่างรวดเร็วซึ่งมุ่งเน้นที่ _การออกแบบและการปรับปรุง_ prompt เพื่อให้คำตอบที่มีคุณภาพและสม่ำเสมอในระดับใหญ่

## เป้าหมายการเรียนรู้

ในบทเรียนนี้ เราจะเรียนรู้ว่า Prompt Engineering คืออะไร ทำไมถึงมีความสำคัญ และเราจะสร้าง prompt ที่มีประสิทธิภาพมากขึ้นสำหรับโมเดลและวัตถุประสงค์ของแอปพลิเคชันได้อย่างไร เราจะเข้าใจแนวคิดหลักและแนวทางปฏิบัติที่ดีที่สุดสำหรับการสร้าง prompt - และเรียนรู้เกี่ยวกับสภาพแวดล้อม "sandbox" ของ Jupyter Notebooks ที่เราสามารถเห็นแนวคิดเหล่านี้ประยุกต์ใช้กับตัวอย่างจริง

เมื่อสิ้นสุดบทเรียนนี้ เราจะสามารถ:

1. อธิบายว่า prompt engineering คืออะไรและทำไมถึงมีความสำคัญ
2. อธิบายองค์ประกอบของ prompt และวิธีการใช้งาน
3. เรียนรู้แนวทางปฏิบัติและเทคนิคที่ดีที่สุดสำหรับ prompt engineering
4. ประยุกต์ใช้เทคนิคที่เรียนรู้กับตัวอย่างจริง โดยใช้ endpoint ของ OpenAI

## คำศัพท์สำคัญ

Prompt Engineering: การออกแบบและปรับปรุง input เพื่อชี้นำโมเดล AI ให้ผลิต output ที่ต้องการ
Tokenization: กระบวนการแปลงข้อความเป็นหน่วยย่อยที่เรียกว่า token ที่โมเดลสามารถเข้าใจและประมวลผลได้
Instruction-Tuned LLMs: โมเดลภาษาขนาดใหญ่ (LLMs) ที่ได้รับการปรับแต่งด้วยคำสั่งเฉพาะเพื่อปรับปรุงความถูกต้องและความเกี่ยวข้องของคำตอบ

## Sandbox การเรียนรู้

Prompt engineering ปัจจุบันเป็นศิลปะมากกว่าวิทยาศาสตร์ วิธีที่ดีที่สุดในการปรับปรุงสัญชาตญาณของเราคือ _ฝึกฝนมากขึ้น_ และใช้วิธีการลองผิดลองถูกที่ผสมผสานความเชี่ยวชาญในโดเมนแอปพลิเคชันเข้ากับเทคนิคที่แนะนำและการปรับปรุงเฉพาะโมเดล

Jupyter Notebook ที่มาพร้อมกับบทเรียนนี้มีสภาพแวดล้อม _sandbox_ ที่คุณสามารถลองใช้สิ่งที่เรียนรู้ - ขณะไปหรือเป็นส่วนหนึ่งของการท้าทายโค้ดในตอนท้าย ในการดำเนินการแบบฝึกหัด คุณจะต้อง:

1. **คีย์ API ของ Azure OpenAI** - endpoint ของบริการสำหรับ LLM ที่ปรับใช้
2. **Runtime ของ Python** - ที่ Notebook สามารถดำเนินการได้
3. **ตัวแปร Env ท้องถิ่น** - _ทำตามขั้นตอน [SETUP](./../00-course-setup/SETUP.md?WT.mc_id=academic-105485-koreyst) เพื่อเตรียมตัว_

Notebook มาพร้อมกับแบบฝึกหัด _starter_ - แต่คุณได้รับการสนับสนุนให้เพิ่มส่วน _Markdown_ (คำอธิบาย) และ _Code_ (คำขอ prompt) ของคุณเองเพื่อทดลองใช้ตัวอย่างหรือไอเดียเพิ่มเติม - และสร้างสัญชาตญาณของคุณสำหรับการออกแบบ prompt

## คู่มือภาพประกอบ

ต้องการภาพรวมของสิ่งที่บทเรียนนี้ครอบคลุมก่อนที่คุณจะเริ่มต้นหรือไม่? ดูคู่มือภาพประกอบนี้ ซึ่งให้ความรู้สึกเกี่ยวกับหัวข้อหลักที่ครอบคลุมและประเด็นสำคัญสำหรับคุณที่จะคิดในแต่ละหัวข้อ แผนที่บทเรียนจะพาคุณจากการทำความเข้าใจแนวคิดและความท้าทายหลักไปจนถึงการแก้ไขด้วยเทคนิคการสร้าง prompt และแนวทางปฏิบัติที่ดีที่สุด โปรดทราบว่าหัวข้อ "Advanced Techniques" ในคู่มือนี้อ้างถึงเนื้อหาที่ครอบคลุมในบท _ถัดไป_ ของหลักสูตรนี้

## สตาร์ทอัพของเรา

ตอนนี้ มาพูดถึงว่า _หัวข้อนี้_ เกี่ยวข้องกับภารกิจสตาร์ทอัพของเราในการ [นำ AI นวัตกรรมสู่การศึกษา](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst) อย่างไร เราต้องการสร้างแอปพลิเคชันการเรียนรู้เฉพาะบุคคลที่ขับเคลื่อนด้วย AI - ดังนั้นมาคิดเกี่ยวกับวิธีที่ผู้ใช้แอปพลิเคชันของเราอาจ "ออกแบบ" prompt:

- **ผู้ดูแลระบบ** อาจขอให้ AI _วิเคราะห์ข้อมูลหลักสูตรเพื่อระบุช่องว่างในการครอบคลุม_ AI สามารถสรุปผลลัพธ์หรือแสดงผลด้วยโค้ด
- **ครูผู้สอน** อาจขอให้ AI _สร้างแผนการสอนสำหรับกลุ่มเป้าหมายและหัวข้อ_ AI สามารถสร้างแผนเฉพาะบุคคลในรูปแบบที่ระบุ
- **นักเรียน** อาจขอให้ AI _สอนพวกเขาในวิชาที่ยาก_ AI สามารถแนะนำบทเรียน ตัวอย่าง และคำแนะนำที่ปรับให้เหมาะกับระดับของนักเรียนได้

นี่เป็นเพียงส่วนเล็กๆ ของภูเขาน้ำแข็ง ลองดู [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - ไลบรารี prompt แบบโอเพนซอร์สที่ดูแลโดยผู้เชี่ยวชาญด้านการศึกษา - เพื่อให้เห็นถึงความเป็นไปได้ในวงกว้าง! _ลองใช้ prompt บางส่วนใน sandbox หรือใช้ OpenAI Playground เพื่อดูว่าเกิดอะไรขึ้น!_

## Prompt Engineering คืออะไร?

เราเริ่มบทเรียนนี้ด้วยการกำหนด **Prompt Engineering** ว่าเป็นกระบวนการ _ออกแบบและปรับปรุง_ ข้อความ input (prompt) เพื่อให้คำตอบที่มีคุณภาพและสม่ำเสมอ (completions) สำหรับวัตถุประสงค์ของแอปพลิเคชันและโมเดลที่กำหนด เราสามารถคิดว่านี่เป็นกระบวนการ 2 ขั้นตอน:

- _ออกแบบ_ prompt เริ่มต้นสำหรับโมเดลและวัตถุประสงค์ที่กำหนด
- _ปรับปรุง_ prompt อย่างต่อเนื่องเพื่อปรับปรุงคุณภาพของคำตอบ

นี่เป็นกระบวนการลองผิดลองถูกที่จำเป็นซึ่งต้องใช้สัญชาตญาณและความพยายามของผู้ใช้เพื่อให้ได้ผลลัพธ์ที่ดีที่สุด แล้วทำไมมันถึงสำคัญ? เพื่อที่จะตอบคำถามนั้น เราจำเป็นต้องเข้าใจสามแนวคิด:

- _Tokenization_ = วิธีที่โมเดล "เห็น" prompt
- _Base LLMs_ = วิธีที่โมเดลพื้นฐาน "ประมวลผล" prompt
- _Instruction-Tuned LLMs_ = วิธีที่โมเดลสามารถเห็น "งาน"

### Tokenization

LLM เห็น prompt เป็น _ลำดับของ token_ ซึ่งโมเดลต่างๆ (หรือเวอร์ชันของโมเดล) สามารถ tokenize prompt เดียวกันในรูปแบบต่างๆ ได้ เนื่องจาก LLMs ได้รับการฝึกฝนบน token (และไม่ใช่ข้อความดิบ) วิธีที่ prompt ถูก tokenize มีผลโดยตรงต่อคุณภาพของคำตอบที่สร้างขึ้น

เพื่อให้เข้าใจว่าการ tokenize ทำงานอย่างไร ลองใช้เครื่องมือเช่น [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) ที่แสดงด้านล่าง คัดลอก prompt ของคุณ - และดูว่าได้รับการแปลงเป็น token อย่างไร โดยให้ความสนใจกับวิธีการจัดการอักขระช่องว่างและเครื่องหมายวรรคตอน โปรดทราบว่าตัวอย่างนี้แสดงโมเดล LLM รุ่นเก่า (GPT-3) - ดังนั้นการลองใช้โมเดลใหม่อาจให้ผลลัพธ์ที่แตกต่างออกไป

### แนวคิด: โมเดลพื้นฐาน

เมื่อ prompt ถูก tokenize ฟังก์ชันหลักของ ["Base LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (หรือโมเดลพื้นฐาน) คือการทำนาย token ในลำดับนั้น เนื่องจาก LLMs ได้รับการฝึกฝนบนชุดข้อมูลข้อความขนาดใหญ่ พวกเขามีความรู้สึกที่ดีเกี่ยวกับความสัมพันธ์ทางสถิติระหว่าง token และสามารถทำนายได้ด้วยความมั่นใจบางอย่าง โปรดทราบว่าพวกเขาไม่เข้าใจ _ความหมาย_ ของคำใน prompt หรือ token; พวกเขาแค่เห็นรูปแบบที่พวกเขาสามารถ "ทำให้เสร็จ" ด้วยการทำนายครั้งต่อไป พวกเขาสามารถทำนายลำดับต่อไปจนกว่าจะถูกยกเลิกโดยการแทรกแซงของผู้ใช้หรือเงื่อนไขที่กำหนดไว้ล่วงหน้า

ต้องการดูว่าการทำให้เสร็จด้วย prompt ทำงานอย่างไร? ป้อน prompt ข้างต้นใน Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) ด้วยการตั้งค่าเริ่มต้น ระบบถูกกำหนดค่าให้ปฏิบัติต่อ prompt เป็นคำขอข้อมูล - ดังนั้นคุณควรเห็นการทำให้เสร็จที่ตอบสนองบริบทนี้

แต่ถ้าผู้ใช้ต้องการเห็นบางสิ่งที่เฉพาะเจาะจงซึ่งตรงตามเกณฑ์หรือวัตถุประสงค์ของงาน? นี่คือที่ _instruction-tuned_ LLMs เข้ามาในภาพ

### แนวคิด: Instruction Tuned LLMs

[Instruction Tuned LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) เริ่มต้นด้วยโมเดลพื้นฐานและปรับแต่งด้วยตัวอย่างหรือคู่ input/output (เช่น "ข้อความ" หลายรอบ) ที่สามารถมีคำแนะนำที่ชัดเจน - และการตอบสนองจาก AI พยายามทำตามคำแนะนำนั้น

นี่ใช้เทคนิคเช่น Reinforcement Learning with Human Feedback (RLHF) ที่สามารถฝึกโมเดลให้ _ทำตามคำแนะนำ_ และ _เรียนรู้จากคำติชม_ เพื่อให้มันสร้างคำตอบที่เหมาะสมกับการใช้งานจริงและเกี่ยวข้องกับวัตถุประสงค์ของผู้ใช้มากขึ้น

ลองทำดู - กลับไปที่ prompt ข้างต้น แต่ตอนนี้เปลี่ยน _ข้อความระบบ_ เพื่อให้คำแนะนำต่อไปนี้เป็นบริบท:

> _สรุปเนื้อหาที่คุณได้รับสำหรับนักเรียนชั้นประถมศึกษาปีที่สอง ให้ผลลัพธ์เป็นหนึ่งย่อหน้าพร้อม 3-5 bullet points_

ดูว่าผลลัพธ์ถูกปรับให้สะท้อนถึงเป้าหมายและรูปแบบที่ต้องการหรือไม่? ครูผู้สอนสามารถใช้คำตอบนี้ในสไลด์สำหรับชั้นเรียนได้โดยตรง

## ทำไมเราต้องการ Prompt Engineering?

ตอนนี้เรารู้แล้วว่า prompt ถูกประมวลผลโดย LLMs อย่างไร มาพูดถึง _ทำไม_ เราต้องการ prompt engineering คำตอบอยู่ที่ข้อเท็จจริงที่ว่า LLMs ปัจจุบันมีความท้าทายหลายประการที่ทำให้ _การทำให้เสร็จที่เชื่อถือได้และสม่ำเสมอ_ ยากที่จะบรรลุผลโดยไม่ต้องใช้ความพยายามในการสร้างและปรับปรุง prompt ตัวอย่างเช่น:

1. **การตอบสนองของโมเดลมีความสุ่ม** _prompt เดียวกัน_ อาจผลิตคำตอบที่แตกต่างกันกับโมเดลหรือเวอร์ชันโมเดลต่างๆ และอาจผลิตผลลัพธ์ที่แตกต่างกันแม้กับ _โมเดลเดียวกัน_ ในเวลาที่ต่างกัน _เทคนิคการสร้าง prompt สามารถช่วยลดความแปรปรวนเหล่านี้โดยการให้ guardrails ที่ดีกว่า_

2. **โมเดลสามารถสร้างคำตอบ** โมเดลได้รับการฝึกฝนด้วยชุดข้อมูล _ใหญ่แต่มีขอบเขตจำกัด_ หมายความว่าพวกเขาขาดความรู้เกี่ยวกับแนวคิดที่อยู่นอกเหนือขอบเขตการฝึกฝน ส่งผลให้พวกเขาสามารถสร้างคำตอบที่ไม่ถูกต้อง จินตนาการ หรือขัดแย้งกับข้อเท็จจริงที่ทราบ _เทคนิคการสร้าง prompt ช่วยให้ผู้ใช้ระบุและลดการสร้างเช่นนี้ เช่น โดยการขอ AI สำหรับการอ้างอิงหรือเหตุผล_

3. **ความสามารถของโมเดลจะแตกต่างกัน** โมเดลใหม่หรือเจเนอเรชันโมเดลใหม่จะมีความสามารถที่หลากหลายมากขึ้น แต่ก็มีข้อบกพร่องและการแลกเปลี่ยนในด้านค่าใช้จ่ายและความซับซ้อน _การสร้าง prompt สามารถช่วยพัฒนาแนวทางปฏิบัติและกระบวนการที่ดีที่สุดที่ยกเว้นความแตกต่างและปรับให้เข้ากับความต้องการเฉพาะโมเดลในวิธีที่สามารถขยายได้และราบรื่น_

ลองดูใน OpenAI หรือ Azure OpenAI Playground:

- ใช้ prompt เดียวกันกับการปรับใช้ LLM ต่างๆ (เช่น OpenAI, Azure OpenAI, Hugging Face) - คุณเห็นความแปรปรวนหรือไม่?
- ใช้ prompt เดียวกันซ้ำๆ กับการปรับใช้ LLM _เดียวกัน_ (เช่น Azure OpenAI Playground) - ความแปรปรวนเหล่านี้แตกต่างกันอย่างไร?

### ตัวอย่างการสร้างคำตอบ

ในหลักสูตรนี้ เราใช้คำว่า **"การสร้างคำตอบ"** เพื่ออ้างถึงปรากฏการณ์ที่ LLMs บางครั้งสร้างข้อมูลที่ไม่ถูกต้องตามข้อเท็จจริงเนื่องจากข้อจำกัดในการฝึกฝนหรือข้อจำกัดอื่นๆ คุณอาจเคยได้ยินว่าเรียกว่า _"การหลอน"_ ในบทความหรือเอกสารวิจัยที่เป็นที่นิยม อย่างไรก็ตาม เราขอแนะนำอย่างยิ่งให้ใช้คำว่า _"การสร้างคำตอบ"_ เพื่อไม่ให้เกิดการมอบลักษณะมนุษย์ให้กับผลลัพธ์ที่เกิดจากเครื่องจักร นอกจากนี้ยังเสริมสร้าง [แนวทางปฏิบัติ AI ที่รับผิดชอบ](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) จากมุมมองของคำศัพท์ โดยการลบคำที่อาจถือว่าเป็นการดูหมิ่นหรือไม่รวมในบางบริบท

ต้องการเข้าใจว่าการสร้างคำตอบทำงานอย่างไร? คิดถึง prompt ที่สั่งให้ AI สร้างเนื้อหาสำหรับหัวข้อที่ไม่มีอยู่จริง (เพื่อให้แน่ใจว่าไม่พบในชุดข้อมูลการฝึกฝน) ตัวอย่างเช่น ฉันลองใช้ prompt นี้:

> **Prompt:** สร้างแผนการสอนเกี่ยวกับสงครามดาวอังคารในปี 2076

การค้นหาเว็บแสดงให้ฉันเห็นว่ามีเรื่องราวสมมติ (เช่น ซีรีส์โทรทัศน์หรือหนังสือ) เกี่ยวกับสงครามดาวอังคาร - แต่ไม่มีในปี 2076 ความรู้ทั่วไปยังบอกเราว่า 2076 _อยู่ในอนาคต_ ดังนั้นจึงไม่สามารถเชื่อมโยงกับเหตุการณ์จริงได้

แล้วจะเกิดอะไรขึ้นเมื่อเรารัน prompt นี้กับผู้ให้บริการ LLM ต่างๆ?

> **คำตอบ 1**: OpenAI Playground (GPT-35)

> **คำตอบ 2**: Azure OpenAI Playground (GPT-35)

> **คำตอบ 3**: : Hugging Face Chat Playground (LLama-2)

ตามที่คาดไว้ โมเดลแต่ละตัว (หรือเวอร์ชันโมเดล) สร้างคำตอบที่แตกต่างกันเล็กน้อยเนื่องจากพฤติกรรมสุ่มและความสามารถของโมเดลที่แตกต่างกัน ตัวอย่างเช่น โมเดลหนึ่งมุ่งเป้าไปที่นักเรียนระดับ
ในที่สุดแล้ว คุณค่าที่แท้จริงของเทมเพลตอยู่ที่ความสามารถในการสร้างและเผยแพร่ _ไลบรารีคำถาม_ สำหรับโดเมนแอปพลิเคชันแนวตั้ง - โดยที่เทมเพลตคำถามถูก _ปรับแต่ง_ เพื่อสะท้อนบริบทเฉพาะของแอปพลิเคชันหรือตัวอย่างที่ทำให้คำตอบมีความเกี่ยวข้องและแม่นยำมากขึ้นสำหรับกลุ่มผู้ใช้ที่มุ่งหมาย ไดเร็กทอรี [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) เป็นตัวอย่างที่ดีของแนวทางนี้ โดยรวบรวมไลบรารีของคำถามสำหรับโดเมนการศึกษา โดยเน้นวัตถุประสงค์สำคัญ เช่น การวางแผนการสอน การออกแบบหลักสูตร การติวเตอร์นักเรียน เป็นต้น

## เนื้อหาสนับสนุน

ถ้าเราคิดถึงการสร้างคำถามเป็นการมีคำแนะนำ (งาน) และเป้าหมาย (เนื้อหาหลัก) แล้ว _เนื้อหารอง_ ก็เหมือนบริบทเพิ่มเติมที่เรามอบให้เพื่อ **ส่งผลต่อผลลัพธ์ในบางวิธี** อาจเป็นการปรับแต่งพารามิเตอร์ คำแนะนำในการจัดรูปแบบ การจำแนกหัวข้อ เป็นต้น ที่สามารถช่วยให้โมเดล _ปรับแต่ง_ คำตอบให้เหมาะสมกับวัตถุประสงค์หรือความคาดหวังของผู้ใช้ที่ต้องการ

ตัวอย่าง: เมื่อมีแคตตาล็อกหลักสูตรที่มีเมทาดาทามากมาย (ชื่อ, คำอธิบาย, ระดับ, แท็กเมทาดาทา, ผู้สอน เป็นต้น) เกี่ยวกับหลักสูตรทั้งหมดที่มีในหลักสูตร:

- เราสามารถกำหนดคำแนะนำให้ "สรุปแคตตาล็อกหลักสูตรสำหรับฤดูใบไม้ร่วงปี 2023"
- เราสามารถใช้เนื้อหาหลักเพื่อให้ตัวอย่างของผลลัพธ์ที่ต้องการ
- เราสามารถใช้เนื้อหารองเพื่อระบุ 5 "แท็ก" ที่สนใจมากที่สุด

ตอนนี้ โมเดลสามารถให้สรุปในรูปแบบที่แสดงโดยตัวอย่างไม่กี่ตัวอย่าง - แต่ถ้าผลลัพธ์มีหลายแท็ก ก็สามารถจัดลำดับความสำคัญของ 5 แท็กที่ระบุในเนื้อหารองได้

---

<!--
LESSON TEMPLATE:
หน่วยนี้ควรครอบคลุมแนวคิดหลัก #1
เสริมสร้างแนวคิดด้วยตัวอย่างและการอ้างอิง

CONCEPT #3:
เทคนิคการออกแบบคำถาม
มีเทคนิคพื้นฐานอะไรบ้างสำหรับการออกแบบคำถาม?
แสดงตัวอย่างด้วยการฝึกหัดบางอย่าง
-->

## แนวทางปฏิบัติที่ดีที่สุดในการออกแบบคำถาม

ตอนนี้ที่เรารู้วิธีการ _สร้าง_ คำถามแล้ว เราสามารถเริ่มคิดเกี่ยวกับวิธีการ _ออกแบบ_ ให้สะท้อนถึงแนวทางปฏิบัติที่ดีที่สุด เราสามารถคิดเกี่ยวกับเรื่องนี้ในสองส่วน - การมี _ทัศนคติ_ ที่ถูกต้องและการใช้ _เทคนิค_ ที่ถูกต้อง

### ทัศนคติในการออกแบบคำถาม

การออกแบบคำถามเป็นกระบวนการทดลองและปรับปรุง ดังนั้นควรจำสามปัจจัยกว้างๆ ไว้ในใจ:

1. **ความเข้าใจในโดเมนสำคัญ** ความแม่นยำและความเกี่ยวข้องของคำตอบเป็นผลมาจาก _โดเมน_ ที่แอปพลิเคชันหรือผู้ใช้ดำเนินการ ใช้สัญชาตญาณและความเชี่ยวชาญในโดเมนของคุณเพื่อ **ปรับแต่งเทคนิค** ต่อไป ตัวอย่างเช่น กำหนด _บุคลิกภาพเฉพาะโดเมน_ ในคำถามระบบของคุณ หรือใช้ _เทมเพลตเฉพาะโดเมน_ ในคำถามผู้ใช้ของคุณ มอบเนื้อหารองที่สะท้อนบริบทเฉพาะโดเมน หรือใช้ _คำแนะนำและตัวอย่างเฉพาะโดเมน_ เพื่อชี้นำโมเดลไปสู่รูปแบบการใช้งานที่คุ้นเคย

2. **ความเข้าใจในโมเดลสำคัญ** เรารู้ว่าโมเดลมีลักษณะสุ่มตามธรรมชาติ แต่การใช้งานโมเดลสามารถแตกต่างกันไปตามชุดข้อมูลการฝึกอบรมที่ใช้ (ความรู้ที่ฝึกมาแล้ว), ความสามารถที่ให้ (เช่น ผ่าน API หรือ SDK) และประเภทของเนื้อหาที่ได้รับการปรับแต่ง (เช่น โค้ด vs. รูปภาพ vs. ข้อความ) เข้าใจจุดแข็งและข้อจำกัดของโมเดลที่คุณใช้ และใช้ความรู้นั้นเพื่อ _จัดลำดับความสำคัญของงาน_ หรือสร้าง _เทมเพลตที่ปรับแต่ง_ ที่ได้รับการปรับแต่งสำหรับความสามารถของโมเดล

3. **การทำซ้ำและการตรวจสอบสำคัญ** โมเดลกำลังพัฒนาอย่างรวดเร็ว และเทคนิคสำหรับการออกแบบคำถามก็เช่นกัน ในฐานะผู้เชี่ยวชาญในโดเมน คุณอาจมีบริบทหรือเกณฑ์อื่นๆ _แอปพลิเคชันเฉพาะของคุณ_ ที่อาจไม่ใช้กับชุมชนที่กว้างขึ้น ใช้เครื่องมือและเทคนิคการออกแบบคำถามเพื่อ "เริ่มต้น" การสร้างคำถาม จากนั้นทำซ้ำและตรวจสอบผลลัพธ์โดยใช้สัญชาตญาณและความเชี่ยวชาญในโดเมนของคุณ บันทึกข้อมูลเชิงลึกของคุณและสร้าง **ฐานความรู้** (เช่น ไลบรารีคำถาม) ที่สามารถใช้เป็นฐานใหม่โดยผู้อื่น สำหรับการทำซ้ำที่เร็วขึ้นในอนาคต

## แนวทางปฏิบัติที่ดีที่สุด

ตอนนี้มาดูแนวทางปฏิบัติที่ดีที่สุดที่แนะนำโดยผู้เชี่ยวชาญ [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) และ [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst)

| อะไร                                | ทำไม                                                                                                                                                                                                                                               |
| :---------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| ประเมินโมเดลล่าสุด                 | การสร้างโมเดลใหม่มักจะมีคุณสมบัติและคุณภาพที่ดีขึ้น - แต่ก็อาจมีค่าใช้จ่ายสูงขึ้นด้วย ประเมินผลกระทบ แล้วตัดสินใจการย้าย                                                                                                              |
| แยกคำแนะนำและบริบท                 | ตรวจสอบว่าโมเดล/ผู้ให้บริการของคุณกำหนด _ตัวแบ่ง_ เพื่อแยกคำแนะนำ เนื้อหาหลักและเนื้อหารองให้ชัดเจนขึ้น ซึ่งจะช่วยให้โมเดลกำหนดน้ำหนักได้อย่างแม่นยำมากขึ้นกับโทเคน                                                               |
| ระบุให้ชัดเจนและชัดเจน            | ให้รายละเอียดเพิ่มเติมเกี่ยวกับบริบทที่ต้องการ ผลลัพธ์ ความยาว รูปแบบ สไตล์ เป็นต้น ซึ่งจะปรับปรุงทั้งคุณภาพและความสม่ำเสมอของคำตอบ เก็บสูตรไว้ในเทมเพลตที่ใช้ซ้ำได้                                                            |
| ใช้คำอธิบายและตัวอย่าง             | โมเดลอาจตอบสนองได้ดีขึ้นต่อวิธีการ "แสดงและบอก" เริ่มต้นด้วย `zero-shot` approach where you give it an instruction (but no examples) then try `few-shot` as a refinement, providing a few examples of the desired output. Use analogies. |
| Use cues to jumpstart completions | Nudge it towards a desired outcome by giving it some leading words or phrases that it can use as a starting point for the response.                                                                                                               |
| Double Down                       | Sometimes you may need to repeat yourself to the model. Give instructions before and after your primary content, use an instruction and a cue, etc. Iterate & validate to see what works.                                                         |
| Order Matters                     | The order in which you present information to the model may impact the output, even in the learning examples, thanks to recency bias. Try different options to see what works best.                                                               |
| Give the model an “out”           | Give the model a _fallback_ completion response it can provide if it cannot complete the task for any reason. This can reduce chances of models generating false or fabricated responses.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

As with any best practice, remember that _your mileage may vary_ based on the model, the task and the domain. Use these as a starting point, and iterate to find what works best for you. Constantly re-evaluate your prompt engineering process as new models and tools become available, with a focus on process scalability and response quality.

<!--
LESSON TEMPLATE:
This unit should provide a code challenge if applicable

CHALLENGE:
Link to a Jupyter Notebook with only the code comments in the instructions (code sections are empty).

SOLUTION:
Link to a copy of that Notebook with the prompts filled in and run, showing what one example could be.
-->

## Assignment

Congratulations! You made it to the end of the lesson! It's time to put some of those concepts and techniques to the test with real examples!

For our assignment, we'll be using a Jupyter Notebook with exercises you can complete interactively. You can also extend the Notebook with your own Markdown and Code cells to explore ideas and techniques on your own.

### To get started, fork the repo, then

- (Recommended) Launch GitHub Codespaces
- (Alternatively) Clone the repo to your local device and use it with Docker Desktop
- (Alternatively) Open the Notebook with your preferred Notebook runtime environment.

### Next, configure your environment variables

- Copy the `.env.copy` file in repo root to `.env` and fill in the `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` and `AZURE_OPENAI_DEPLOYMENT` ค่ากลับไปที่ [ส่วน Learning Sandbox](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) เพื่อเรียนรู้วิธีการ

### ต่อไปเปิด Jupyter Notebook

- เลือกเคอร์เนลรันไทม์ หากใช้ตัวเลือก 1 หรือ 2 ให้เลือกเคอร์เนล Python 3.10.x ที่มีอยู่ในคอนเทนเนอร์สำหรับการพัฒนา

คุณพร้อมที่จะทำการฝึกหัดแล้ว โปรดทราบว่าไม่มีคำตอบ _ถูกและผิด_ ที่นี่ - เพียงแค่สำรวจตัวเลือกโดยการทดลองและสร้างสัญชาตญาณสำหรับสิ่งที่ทำงานได้สำหรับโมเดลและโดเมนแอปพลิเคชันที่กำหนด

_ด้วยเหตุนี้จึงไม่มีส่วนโซลูชันโค้ดในบทเรียนนี้ แต่ Notebook จะมีเซลล์ Markdown ที่มีชื่อว่า "My Solution:" ที่แสดงตัวอย่างผลลัพธ์หนึ่งเพื่ออ้างอิง_

 <!--
LESSON TEMPLATE:
สรุปส่วนนี้ด้วยสรุปและทรัพยากรสำหรับการเรียนรู้ด้วยตนเอง
-->

## การตรวจสอบความรู้

ข้อใดต่อไปนี้เป็นคำถามที่ดีตามแนวทางปฏิบัติที่ดีที่สุดที่สมเหตุสมผลบางอย่าง?

1. แสดงภาพรถสีแดงให้ฉันดู
2. แสดงภาพรถสีแดงยี่ห้อ Volvo รุ่น XC90 จอดอยู่ริมหน้าผาโดยมีพระอาทิตย์ตก
3. แสดงภาพรถสีแดงยี่ห้อ Volvo รุ่น XC90

A: 2, เป็นคำถามที่ดีที่สุดเนื่องจากให้รายละเอียดเกี่ยวกับ "อะไร" และเข้าไปในรายละเอียด (ไม่ใช่แค่รถใดๆ แต่เป็นยี่ห้อและรุ่นเฉพาะ) และยังอธิบายสภาพแวดล้อมโดยรวม 3 เป็นคำถามที่ดีที่สุดถัดไปเนื่องจากยังมีคำอธิบายมากมาย

## 🚀 ความท้าทาย

ลองใช้เทคนิค "คำใบ้" กับคำถาม: เติมประโยค "แสดงภาพรถสีแดงยี่ห้อ Volvo และ " คำตอบเป็นอย่างไร และคุณจะปรับปรุงมันได้อย่างไร?

## งานที่ยอดเยี่ยม! ดำเนินการเรียนรู้ของคุณต่อไป

ต้องการเรียนรู้เพิ่มเติมเกี่ยวกับแนวคิดการออกแบบคำถามที่แตกต่างกันหรือไม่? ไปที่ [หน้าการเรียนรู้ต่อเนื่อง](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) เพื่อค้นหาทรัพยากรที่ยอดเยี่ยมอื่นๆ ในหัวข้อนี้

ไปที่บทเรียนที่ 5 ซึ่งเราจะดูที่ [เทคนิคการออกแบบคำถามขั้นสูง](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามให้มีความถูกต้อง แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่ถูกต้อง เอกสารต้นฉบับในภาษาต้นฉบับควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลสำคัญ แนะนำให้ใช้บริการแปลภาษามนุษย์ที่มีความเชี่ยวชาญ เราไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความผิดที่เกิดจากการใช้การแปลนี้