<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5466bcedc3c75aa35476270362f626a",
  "translation_date": "2025-05-20T01:59:23+00:00",
  "source_file": "15-rag-and-vector-databases/data/frameworks.md",
  "language_code": "th"
}
-->
# เฟรมเวิร์กของเครือข่ายประสาท

อย่างที่เราได้เรียนรู้ไปแล้ว ว่าเพื่อที่จะฝึกเครือข่ายประสาทได้อย่างมีประสิทธิภาพ เราต้องทำสองสิ่งนี้:

* ดำเนินการบนเทนเซอร์ เช่น การคูณ การบวก และคำนวณฟังก์ชันบางอย่าง เช่น sigmoid หรือ softmax
* คำนวณกราดิเอนต์ของทุกนิพจน์ เพื่อทำการปรับปรุงแบบ gradient descent

ในขณะที่ไลบรารี `numpy` สามารถทำส่วนแรกได้ เราต้องการกลไกบางอย่างในการคำนวณกราดิเอนต์ ในเฟรมเวิร์กที่เราได้พัฒนาในส่วนก่อนหน้า เราต้องเขียนโปรแกรมฟังก์ชันอนุพันธ์ทั้งหมดด้วยตนเองภายในเมธอด `backward` ซึ่งทำการถ่ายโอนย้อนกลับ อุดมคติแล้ว เฟรมเวิร์กควรให้โอกาสเราคำนวณกราดิเอนต์ของ *นิพจน์ใดๆ* ที่เราสามารถกำหนดได้

อีกสิ่งที่สำคัญคือการสามารถทำการคำนวณบน GPU หรือหน่วยคำนวณเฉพาะทางอื่นๆ เช่น TPU การฝึกฝนเครือข่ายประสาทลึกต้องการการคำนวณ *จำนวนมาก* และการสามารถทำให้การคำนวณเหล่านั้นขนานกันบน GPU เป็นสิ่งที่สำคัญมาก

> ✅ คำว่า 'parallelize' หมายถึงการกระจายการคำนวณไปยังหลายอุปกรณ์

ปัจจุบัน เฟรมเวิร์กเครือข่ายประสาทที่ได้รับความนิยมที่สุดสองตัวคือ: TensorFlow และ PyTorch ทั้งสองมี API ระดับต่ำเพื่อทำงานกับเทนเซอร์ทั้งบน CPU และ GPU บน API ระดับต่ำยังมี API ระดับสูงที่เรียกว่า Keras และ PyTorch Lightning ตามลำดับ

API ระดับต่ำ | TensorFlow | PyTorch
--------------|-------------------------------------|--------------------------------
API ระดับสูง | Keras | Pytorch

**API ระดับต่ำ** ในทั้งสองเฟรมเวิร์กช่วยให้คุณสร้างสิ่งที่เรียกว่า **กราฟการคำนวณ** กราฟนี้กำหนดวิธีการคำนวณผลลัพธ์ (ปกติคือฟังก์ชันการสูญเสีย) ด้วยพารามิเตอร์อินพุตที่กำหนด และสามารถส่งไปคำนวณบน GPU ได้หากมี ฟังก์ชันมีเพื่อแตกต่างกราฟการคำนวณนี้และคำนวณกราดิเอนต์ ซึ่งสามารถใช้ในการปรับปรุงพารามิเตอร์ของโมเดลได้

**API ระดับสูง** มองว่าเครือข่ายประสาทเป็น **ลำดับของชั้น** และทำให้การสร้างเครือข่ายประสาทส่วนใหญ่เป็นเรื่องง่ายขึ้น การฝึกฝนโมเดลปกติจะต้องเตรียมข้อมูลและเรียกใช้ฟังก์ชัน `fit` เพื่อทำงานนั้น

API ระดับสูงช่วยให้คุณสร้างเครือข่ายประสาททั่วไปได้อย่างรวดเร็วโดยไม่ต้องกังวลเกี่ยวกับรายละเอียดมากมาย ในขณะเดียวกัน API ระดับต่ำให้การควบคุมมากขึ้นในกระบวนการฝึกฝน และดังนั้นจึงใช้มากในงานวิจัยเมื่อคุณต้องจัดการกับสถาปัตยกรรมเครือข่ายประสาทใหม่

สิ่งสำคัญคือการเข้าใจว่าคุณสามารถใช้ทั้งสอง API ร่วมกันได้ เช่น คุณสามารถพัฒนาสถาปัตยกรรมชั้นเครือข่ายของคุณเองโดยใช้ API ระดับต่ำ จากนั้นใช้มันภายในเครือข่ายที่ใหญ่กว่าที่สร้างและฝึกฝนด้วย API ระดับสูง หรือคุณสามารถกำหนดเครือข่ายโดยใช้ API ระดับสูงเป็นลำดับของชั้น จากนั้นใช้ลูปการฝึกฝนระดับต่ำของคุณเองเพื่อทำการปรับปรุง ทั้งสอง API ใช้แนวคิดพื้นฐานเดียวกันและออกแบบมาให้ทำงานร่วมกันได้ดี

## การเรียนรู้

ในคอร์สนี้ เรามีเนื้อหาสำหรับทั้ง PyTorch และ TensorFlow คุณสามารถเลือกเฟรมเวิร์กที่คุณชอบและผ่านโน้ตบุ๊กที่สอดคล้องกันได้ หากคุณไม่แน่ใจว่าจะเลือกเฟรมเวิร์กไหน ลองอ่านการสนทนาบนอินเทอร์เน็ตเกี่ยวกับ **PyTorch vs. TensorFlow** คุณยังสามารถดูทั้งสองเฟรมเวิร์กเพื่อทำความเข้าใจได้ดีขึ้น

ที่ไหนที่เป็นไปได้ เราจะใช้ API ระดับสูงเพื่อความเรียบง่าย อย่างไรก็ตาม เราเชื่อว่าสำคัญที่จะเข้าใจว่าเครือข่ายประสาททำงานอย่างไรจากพื้นฐาน ดังนั้นในตอนเริ่มต้นเราจะเริ่มต้นด้วยการทำงานกับ API ระดับต่ำและเทนเซอร์ อย่างไรก็ตาม หากคุณต้องการเริ่มต้นเร็วและไม่ต้องการใช้เวลามากในการเรียนรู้รายละเอียดเหล่านี้ คุณสามารถข้ามส่วนเหล่านั้นและไปยังโน้ตบุ๊ก API ระดับสูงได้เลย

## ✍️ แบบฝึกหัด: เฟรมเวิร์ก

เรียนรู้ต่อในโน้ตบุ๊กต่อไปนี้:

API ระดับต่ำ | โน้ตบุ๊ก TensorFlow+Keras | PyTorch
--------------|-------------------------------------|--------------------------------
API ระดับสูง | Keras | *PyTorch Lightning*

หลังจากเชี่ยวชาญเฟรมเวิร์กแล้ว มาทบทวนแนวคิดของ overfitting กัน

# Overfitting

Overfitting เป็นแนวคิดที่สำคัญมากในแมชชีนเลิร์นนิง และมันสำคัญมากที่จะเข้าใจมันอย่างถูกต้อง!

พิจารณาปัญหาต่อไปนี้ในการประมาณจุด 5 จุด (แสดงโดย `x` ในกราฟด้านล่าง):

!linear | overfit
-------------------------|--------------------------
**โมเดลเชิงเส้น, 2 พารามิเตอร์** | **โมเดลไม่เชิงเส้น, 7 พารามิเตอร์**
ข้อผิดพลาดในการฝึก = 5.3 | ข้อผิดพลาดในการฝึก = 0
ข้อผิดพลาดในการตรวจสอบ = 5.1 | ข้อผิดพลาดในการตรวจสอบ = 20

* ทางซ้าย เราเห็นการประมาณเส้นตรงที่ดี เนื่องจากจำนวนพารามิเตอร์เหมาะสม โมเดลเข้าใจแนวคิดเบื้องหลังการกระจายจุดได้ถูกต้อง
* ทางขวา โมเดลทรงพลังเกินไป เนื่องจากเรามีเพียง 5 จุดและโมเดลมี 7 พารามิเตอร์ มันสามารถปรับในลักษณะที่ผ่านทุกจุด ทำให้ข้อผิดพลาดในการฝึกเป็น 0 อย่างไรก็ตาม นี่ทำให้โมเดลไม่เข้าใจรูปแบบที่ถูกต้องเบื้องหลังข้อมูล ทำให้ข้อผิดพลาดในการตรวจสอบสูงมาก

สิ่งสำคัญคือการหาสมดุลที่ถูกต้องระหว่างความหลากหลายของโมเดล (จำนวนพารามิเตอร์) และจำนวนตัวอย่างการฝึก

## ทำไม overfitting ถึงเกิดขึ้น

  * ข้อมูลการฝึกไม่เพียงพอ
  * โมเดลทรงพลังเกินไป
  * เสียงรบกวนมากเกินไปในข้อมูลอินพุต

## วิธีตรวจจับ overfitting

จากกราฟด้านบน คุณสามารถเห็นว่า overfitting สามารถตรวจจับได้จากข้อผิดพลาดในการฝึกที่ต่ำมาก และข้อผิดพลาดในการตรวจสอบที่สูง โดยปกติในระหว่างการฝึกเราจะเห็นทั้งข้อผิดพลาดในการฝึกและการตรวจสอบเริ่มลดลง และจากนั้นในบางจุดข้อผิดพลาดในการตรวจสอบอาจหยุดลดลงและเริ่มเพิ่มขึ้น นี่จะเป็นสัญญาณของ overfitting และเป็นตัวบ่งชี้ว่าเราควรหยุดการฝึกที่จุดนี้ (หรืออย่างน้อยทำสแน็ปช็อตของโมเดล)

## วิธีป้องกัน overfitting

หากคุณเห็นว่า overfitting เกิดขึ้น คุณสามารถทำสิ่งใดสิ่งหนึ่งต่อไปนี้:

 * เพิ่มจำนวนข้อมูลการฝึก
 * ลดความซับซ้อนของโมเดล
 * ใช้เทคนิคการปรับปกติบางอย่าง เช่น Dropout ซึ่งเราจะพิจารณาภายหลัง

## Overfitting และ Bias-Variance Tradeoff

Overfitting เป็นกรณีของปัญหาทั่วไปในสถิติที่เรียกว่า Bias-Variance Tradeoff หากเราพิจารณาแหล่งที่มาของข้อผิดพลาดในโมเดลของเรา เราสามารถเห็นข้อผิดพลาดสองประเภท:

* **ข้อผิดพลาดแบบไบแอส** เกิดจากอัลกอริธึมของเราไม่สามารถจับความสัมพันธ์ระหว่างข้อมูลการฝึกได้อย่างถูกต้อง อาจเกิดจากข้อเท็จจริงที่ว่าโมเดลของเราไม่ทรงพลังพอ (**underfitting**)
* **ข้อผิดพลาดแบบแปรปรวน** ซึ่งเกิดจากโมเดลประมาณเสียงรบกวนในข้อมูลอินพุตแทนที่จะเป็นความสัมพันธ์ที่มีความหมาย (**overfitting**)

ในระหว่างการฝึก ข้อผิดพลาดแบบไบแอสลดลง (เมื่อโมเดลของเราเรียนรู้ที่จะประมาณข้อมูล) และข้อผิดพลาดแบบแปรปรวนเพิ่มขึ้น สิ่งสำคัญคือต้องหยุดการฝึก - ทั้งด้วยตนเอง (เมื่อเราตรวจพบ overfitting) หรืออัตโนมัติ (โดยการใช้การปรับปกติ) - เพื่อป้องกัน overfitting

## สรุป

ในบทเรียนนี้ คุณได้เรียนรู้เกี่ยวกับความแตกต่างระหว่าง API ต่างๆ สำหรับสองเฟรมเวิร์ก AI ที่ได้รับความนิยมมากที่สุด, TensorFlow และ PyTorch นอกจากนี้คุณยังได้เรียนรู้เกี่ยวกับหัวข้อที่สำคัญมาก, overfitting

## 🚀 ความท้าทาย

ในโน้ตบุ๊กที่แนบมาคุณจะพบ 'งาน' ที่ด้านล่าง; ทำงานผ่านโน้ตบุ๊กและทำงานให้เสร็จ

## ทบทวนและศึกษาด้วยตนเอง

ทำการค้นคว้าในหัวข้อต่อไปนี้:

- TensorFlow
- PyTorch
- Overfitting

ถามตัวเองด้วยคำถามต่อไปนี้:

- อะไรคือความแตกต่างระหว่าง TensorFlow และ PyTorch?
- อะไรคือความแตกต่างระหว่าง overfitting และ underfitting?

## การมอบหมาย

ในห้องทดลองนี้ คุณถูกขอให้แก้ปัญหาการจำแนกสองปัญหาโดยใช้เครือข่ายที่เชื่อมต่อเต็มรูปแบบแบบชั้นเดียวและหลายชั้นโดยใช้ PyTorch หรือ TensorFlow

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามอย่างเต็มที่เพื่อความถูกต้อง แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่ถูกต้อง เอกสารต้นฉบับในภาษาต้นทางควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลสำคัญ แนะนำให้ใช้บริการแปลภาษามนุษย์มืออาชีพ เราไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความผิดที่เกิดจากการใช้การแปลนี้