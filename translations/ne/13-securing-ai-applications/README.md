<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f3cac698e9eea47dd563633bd82daf8c",
  "translation_date": "2025-05-19T22:36:12+00:00",
  "source_file": "13-securing-ai-applications/README.md",
  "language_code": "ne"
}
-->
# तपाईंको जेनेरेटिभ एआई अनुप्रयोगहरूलाई सुरक्षित गर्नुहोस्

## परिचय

यो पाठले समेट्नेछ:

- एआई प्रणालीहरूको सन्दर्भमा सुरक्षा।
- एआई प्रणालीहरूमा सामान्य जोखिमहरू र खतराहरू।
- एआई प्रणालीहरूलाई सुरक्षित गर्ने विधिहरू र विचारहरू।

## सिक्ने लक्ष्यहरू

यो पाठ पूरा गरेपछि, तपाईंलाई निम्न विषयहरूको समझ हुनेछ:

- एआई प्रणालीहरूमा खतराहरू र जोखिमहरू।
- एआई प्रणालीहरूलाई सुरक्षित गर्ने सामान्य विधिहरू र अभ्यासहरू।
- कसरी सुरक्षा परीक्षण कार्यान्वयनले अप्रत्याशित परिणामहरू र प्रयोगकर्ता विश्वासको क्षयलाई रोक्न सक्छ।

## जेनेरेटिभ एआईको सन्दर्भमा सुरक्षा के अर्थ हो?

जसरी कृत्रिम बुद्धिमत्ता (AI) र मेसिन लर्निङ (ML) प्रविधिहरूले हाम्रो जीवनलाई आकार दिन्छन्, ग्राहकको डाटा मात्र नभई एआई प्रणालीहरूलाई पनि सुरक्षित गर्नु महत्त्वपूर्ण छ। एआई/एमएल उच्च मूल्य निर्णय-निर्माण प्रक्रियाहरूमा प्रयोग गरिन्छ जहाँ गलत निर्णयले गम्भीर परिणामहरू निम्त्याउन सक्छ।

यहाँ विचार गर्नुपर्ने मुख्य बिन्दुहरू छन्:

- **एआई/एमएलको प्रभाव**: एआई/एमएलको दैनिक जीवनमा महत्त्वपूर्ण प्रभाव छ र तसर्थ तिनीहरूलाई सुरक्षित राख्न आवश्यक छ।
- **सुरक्षा चुनौतीहरू**: एआई/एमएलको यो प्रभावलाई उचित ध्यान दिन आवश्यक छ ताकि एआई-आधारित उत्पादनहरूलाई ट्रोलहरू वा संगठित समूहहरूबाट जटिल आक्रमणबाट सुरक्षित गर्न सकिन्छ।
- **रणनीतिक समस्याहरू**: टेक उद्योगले दीर्घकालीन ग्राहक सुरक्षा र डाटा सुरक्षाको सुनिश्चित गर्न रणनीतिक चुनौतीहरूलाई सक्रिय रूपमा सम्बोधन गर्नुपर्छ।

थप रूपमा, मेसिन लर्निङ मोडेलहरू प्रायः हानिकारक इनपुट र सामान्य अनौठो डाटाबीच भिन्नता गर्न असमर्थ हुन्छन्। प्रशिक्षण डाटाको महत्त्वपूर्ण स्रोत असंरचित, अनियमित, सार्वजनिक डेटासेटबाट व्युत्पन्न हुन्छ, जुन तेस्रो-पक्ष योगदानको लागि खुला हुन्छ। आक्रमणकर्ताहरूलाई डेटासेटहरूलाई सम्झौता गर्न आवश्यक छैन जब तिनीहरूमा योगदान गर्न स्वतन्त्र हुन्छन्। समयसँगै, कम-विश्वास हानिकारक डाटा उच्च-विश्वास विश्वसनीय डाटा बन्न सक्छ यदि डाटा संरचना/फर्म्याट सही रहन्छ भने।

त्यसैले यो महत्वपूर्ण छ कि तपाईंको मोडेलहरूले निर्णयहरू गर्न प्रयोग गर्ने डाटा स्टोरहरूको अखण्डता र सुरक्षा सुनिश्चित गर्नुहोस्।

## एआईको खतराहरू र जोखिमहरूको समझ

एआई र सम्बन्धित प्रणालीहरूको सन्दर्भमा, डाटा विषाक्तता आजको सबैभन्दा महत्त्वपूर्ण सुरक्षा खतरा हो। डाटा विषाक्तता तब हुन्छ जब कसैले जानबुझेर एआईलाई प्रशिक्षण दिन प्रयोग गरिएको जानकारीलाई परिवर्तन गर्छ, जसले गर्दा यसले गल्ती गर्छ। यो मानकीकृत पत्ता लगाउने र न्यूनीकरण विधिहरूको अभावका कारण हुन्छ, जसमा प्रशिक्षणको लागि अविश्वसनीय वा असंरचित सार्वजनिक डेटासेटहरूमा हाम्रो निर्भरता जोडिन्छ। डाटा अखण्डता कायम राख्न र त्रुटिपूर्ण प्रशिक्षण प्रक्रिया रोक्न, तपाईंको डाटाको उत्पत्ति र वंशावलीलाई ट्र्याक गर्नु महत्त्वपूर्ण छ। अन्यथा, पुरानो भनाइ "फोहोर भित्र, फोहोर बाहिर" सत्य हुन्छ, जसले मोडेल प्रदर्शनलाई सम्झौता गराउँछ।

यहाँ डाटा विषाक्तताले तपाईंको मोडेलहरूलाई कसरी प्रभावित गर्न सक्छ भन्ने उदाहरणहरू छन्:

1. **लेबल फ्लिपिङ**: द्विआधारी वर्गीकरण कार्यमा, एक विरोधीले जानबुझेर प्रशिक्षण डाटाको सानो उपसमूहको लेबलहरू उल्टाउँछ। उदाहरणका लागि, हानिरहित नमूनाहरूलाई हानिकारक भनेर लेबल गरिन्छ, जसले मोडेललाई गलत संघहरू सिक्न प्रेरित गर्छ।\
   **उदाहरण**: स्प्याम फिल्टरले हेरफेर गरिएका लेबलहरूको कारण वैध इमेलहरूलाई स्प्यामको रूपमा गलत वर्गीकरण गर्छ।
2. **फिचर विषाक्तता**: एक आक्रमणकर्ताले प्रशिक्षण डाटामा पूर्वाग्रह वा मोडेललाई भ्रमित गर्न सुविधाहरूलाई सूक्ष्म रूपमा परिमार्जन गर्छ।\
   **उदाहरण**: सिफारिस प्रणालीहरूलाई हेरफेर गर्न उत्पादन विवरणहरूमा असान्दर्भिक कुञ्जीशब्दहरू थप्दै।
3. **डाटा इन्जेक्सन**: मोडेलको व्यवहारलाई प्रभाव पार्न प्रशिक्षण सेटमा हानिकारक डाटा इंजेक्ट गर्दै।\
   **उदाहरण**: भावना विश्लेषण परिणामहरूलाई विकृत गर्न नक्कली प्रयोगकर्ता समीक्षाहरू परिचय गर्दै।
4. **ब्याकडोर आक्रमणहरू**: एक विरोधीले प्रशिक्षण डाटामा लुकेको ढाँचा (ब्याकडोर) सम्मिलित गर्छ। मोडेलले यो ढाँचालाई चिन्न सिक्छ र ट्रिगर हुँदा हानिकारक व्यवहार गर्छ।\
   **उदाहरण**: ब्याकडोर गरिएका छविहरूको साथ प्रशिक्षित अनुहार पहिचान प्रणालीले विशेष व्यक्तिलाई गलत पहिचान गर्छ।

MITRE Corporation ले [ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems)](https://atlas.mitre.org/?WT.mc_id=academic-105485-koreyst) सिर्जना गरेको छ, वास्तविक-विश्व आक्रमणमा विरोधीहरूले प्रयोग गर्ने रणनीति र प्रविधिहरूको ज्ञान आधार।

> एआई-सक्षम प्रणालीहरूमा कमजोर पक्षहरूको संख्या बढ्दै छ, किनकि एआईको समावेशले परम्परागत साइबर-आक्रमणहरू भन्दा बाहिर विद्यमान प्रणालीहरूको आक्रमण सतहलाई बढाउँछ। हामीले ATLAS विकास गरेका छौं ताकि यो अद्वितीय र विकसित कमजोर पक्षहरूको बारेमा जागरूकता बढाउन सकियोस्, किनकि विश्वव्यापी समुदायले विभिन्न प्रणालीहरूमा एआईलाई बढ्दै गइरहेको छ। ATLAS MITRE ATT&CK® फ्रेमवर्कको मोडेलमा आधारित छ र यसको रणनीति, प्रविधिहरू, र प्रक्रियाहरू ATT&CK मा भएका प्रविधिहरूसँग पूरक छन्।

जसरी MITRE ATT&CK® फ्रेमवर्क परम्परागत साइबर सुरक्षामा उन्नत खतरा अनुकरण परिदृश्यहरू योजनाका लागि व्यापक रूपमा प्रयोग गरिन्छ, ATLAS ले उदाउँदो आक्रमणहरूको बचावटको लागि तयार हुन र बुझ्न मद्दत गर्न सजिलै खोज्न मिल्ने सेट TTPs प्रदान गर्छ।

थप रूपमा, ओपन वेब एप्लिकेशन सुरक्षा परियोजना (OWASP) ले [LLMहरूलाई प्रयोग गर्ने अनुप्रयोगहरूमा फेला पर्ने सबैभन्दा महत्त्वपूर्ण कमजोर पक्षहरूको "[टप 10 सूची](https://llmtop10.com/?WT.mc_id=academic-105485-koreyst)" सिर्जना गरेको छ। सूचीले उल्लेखित डाटा विषाक्तता जस्ता खतराहरूको जोखिमहरू र अन्य जस्तै:

- **प्रम्प्ट इन्जेक्सन**: एक प्रविधि जहाँ आक्रमणकर्ताहरूले ठूलो भाषा मोडेल (LLM)लाई सावधानीपूर्वक तयार गरिएका इनपुटहरू मार्फत हेरफेर गर्छन्, जसले यसलाई यसको इच्छित व्यवहार बाहिर काम गर्न प्रेरित गर्छ।
- **सप्लाई चेन कमजोर पक्षहरू**: LLM द्वारा प्रयोग गरिएका अनुप्रयोगहरू बनाउने कम्पोनेन्टहरू र सफ्टवेयर, जस्तै पायथन मोड्युलहरू वा बाह्य डेटासेटहरू, आफैंमा सम्झौता गर्न सकिन्छ जसले अप्रत्याशित परिणामहरू, परिचय गरिएका पूर्वाग्रहहरू र आधारभूत पूर्वाधारमा कमजोर पक्षहरू निम्त्याउन सक्छ।
- **अधिक निर्भरता**: LLMहरू भ्रमित हुन सक्छन् र गलत वा असुरक्षित परिणामहरू प्रदान गर्न प्रवृत्त भएका छन्। केही दस्तावेज गरिएको परिस्थितिहरूमा, मानिसहरूले अनुचित वास्तविक-विश्व नकारात्मक परिणामहरू निम्त्याउने अनुहारमा परिणामहरू लिएका छन्।

माइक्रोसफ्ट क्लाउड एडभोकेट रोड ट्रेन्टले [Must Learn AI Security](https://github.com/rod-trent/OpenAISecurity/tree/main/Must_Learn/Book_Version?WT.mc_id=academic-105485-koreyst) नामक निःशुल्क ईबुक लेखेका छन्, जसले यी र अन्य उदीयमान एआई खतराहरूमा गहिरो रूपमा प्रवेश गर्छ र यी परिदृश्यहरूलाई कसरी राम्रोसँग सामना गर्ने भन्ने विस्तृत मार्गदर्शन प्रदान गर्छ।

## एआई प्रणालीहरू र LLMहरूको लागि सुरक्षा परीक्षण

कृत्रिम बुद्धिमत्ता (AI) विभिन्न डोमेनहरू र उद्योगहरूलाई रूपान्तरण गर्दैछ, समाजको लागि नयाँ सम्भावनाहरू र फाइदाहरू प्रदान गर्दै। तथापि, एआईले डाटा गोपनीयता, पूर्वाग्रह, व्याख्यात्मकताको कमी, र संभावित दुरुपयोग जस्ता महत्त्वपूर्ण चुनौतीहरू र जोखिमहरू पनि प्रस्तुत गर्दछ। त्यसैले, यो सुनिश्चित गर्नु महत्त्वपूर्ण छ कि एआई प्रणालीहरू सुरक्षित र जिम्मेवार छन्, जसको अर्थ तिनीहरूले नैतिक र कानुनी मापदण्डहरू पालना गर्छन् र प्रयोगकर्ता र साझेदारहरूद्वारा विश्वास गर्न सकिन्छ।

सुरक्षा परीक्षण भनेको एआई प्रणाली वा LLM को सुरक्षा मूल्यांकन गर्ने प्रक्रिया हो, तिनीहरूको कमजोर पक्षहरू पहिचान गरेर र शोषण गरेर। यो विकासकर्ताहरू, प्रयोगकर्ताहरू, वा तेस्रो-पक्ष लेखा परीक्षकहरूद्वारा परीक्षणको उद्देश्य र दायरा अनुसार प्रदर्शन गर्न सकिन्छ। एआई प्रणालीहरू र LLMहरूको लागि सबैभन्दा सामान्य सुरक्षा परीक्षण विधिहरू केही छन्:

- **डाटा स्यानिटाइजेशन**: यो प्रशिक्षण डाटा वा एआई प्रणाली वा LLM को इनपुटबाट संवेदनशील वा निजी जानकारी हटाउने वा गुमनाम गर्ने प्रक्रिया हो। डाटा स्यानिटाइजेशनले गोपनीय वा व्यक्तिगत डाटाको जोखिम घटाएर डाटा चुहावट र हानिकारक हेरफेर रोक्न मद्दत गर्न सक्छ।
- **विरोधी परीक्षण**: यो एआई प्रणाली वा LLM को इनपुट वा आउटपुटमा विरोधी उदाहरणहरू उत्पन्न गर्ने र लागू गर्ने प्रक्रिया हो ताकि यसको विरोधी आक्रमणहरूको विरुद्धमा मजबूती र लचकता मूल्यांकन गर्न सकियोस्। विरोधी परीक्षणले एआई प्रणाली वा LLM को कमजोर पक्षहरू र कमजोरीहरू पहिचान गर्न र न्यूनीकरण गर्न मद्दत गर्न सक्छ जुन आक्रमणकर्ताहरूले शोषण गर्न सक्छन्।
- **मोडेल प्रमाणीकरण**: यो एआई प्रणाली वा LLM को मोडेल प्यारामिटरहरू वा वास्तुकलाको सहीता र पूर्णता प्रमाणीकरण गर्ने प्रक्रिया हो। मोडेल प्रमाणीकरणले मोडेल चोरी पत्ता लगाउन र रोक्न मद्दत गर्न सक्छ।
- **आउटपुट प्रमाणीकरण**: यो एआई प्रणाली वा LLM को आउटपुटको गुणस्तर र विश्वसनीयता प्रमाणीकरण गर्ने प्रक्रिया हो। आउटपुट प्रमाणीकरणले आउटपुटलाई सुसंगत र सही बनाउन सुनिश्चित गरेर हानिकारक हेरफेर पत्ता लगाउन र सुधार गर्न मद्दत गर्न सक्छ।

OpenAI, एआई प्रणालीहरूमा अग्रणी,ले आफ्नो रेड टीमिङ नेटवर्क पहलको भागको रूपमा _सुरक्षा मूल्यांकन_ को श्रृंखला स्थापना गरेको छ, जसले एआई प्रणालीहरूलाई परीक्षण गर्न र एआई सुरक्षामा योगदान गर्नको लागि।

> मूल्यांकनहरू सरल Q&A परीक्षणहरूदेखि अधिक जटिल सिमुलेशनसम्म हुन सक्छ। ठोस उदाहरणका रूपमा, यहाँ एआई व्यवहारहरूलाई विभिन्न कोणबाट मूल्यांकन गर्न OpenAI द्वारा विकसित नमूना मूल्यांकनहरू छन्:

#### मनोविज्ञान

- [MakeMeSay](https://github.com/openai/evals/tree/main/evals/elsuite/make_me_say/readme.md?WT.mc_id=academic-105485-koreyst): एआई प्रणालीले अर्को एआई प्रणालीलाई गोप्य शब्द भन्न कत्तिको राम्रोसँग धोका दिन सक्छ?
- [MakeMePay](https://github.com/openai/evals/tree/main/evals/elsuite/make_me_pay/readme.md?WT.mc_id=academic-105485-koreyst): एआई प्रणालीले अर्को एआई प्रणालीलाई पैसा दान गर्न कत्तिको राम्रोसँग मनाउन सक्छ?
- [Ballot Proposal](https://github.com/openai/evals/tree/main/evals/elsuite/ballots/readme.md?WT.mc_id=academic-105485-koreyst): एआई प्रणालीले अर्को एआई प्रणालीको राजनीतिक प्रस्तावको समर्थनलाई कत्तिको राम्रोसँग प्रभाव पार्न सक्छ?

#### स्टेगानोग्राफी (लुकेको सन्देश)

- [Steganography](https://github.com/openai/evals/tree/main/evals/elsuite/steganography/readme.md?WT.mc_id=academic-105485-koreyst): एआई प्रणालीले अर्को एआई प्रणालीद्वारा पक्रिन नपरी गोप्य सन्देशहरू कसरी राम्रोसँग पास गर्न सक्छ?
- [Text Compression](https://github.com/openai/evals/tree/main/evals/elsuite/text_compression/readme.md?WT.mc_id=academic-105485-koreyst): एआई प्रणालीले गोप्य सन्देशहरू लुकाउन सक्षम बनाउन सन्देशहरू कसरी राम्रोसँग संकुचित र विस्तार गर्न सक्छ?
- [Schelling Point](https://github.com/openai/evals/blob/main/evals/elsuite/schelling_point/README.md?WT.mc_id=academic-105485-koreyst): एआई प्रणालीले अर्को एआई प्रणालीसँग कसरी राम्रोसँग समन्वय गर्न सक्छ, प्रत्यक्ष सञ्चार बिना?

### एआई सुरक्षा

हामीले एआई प्रणालीहरूलाई हानिकारक आक्रमणहरू, दुरुपयोग, वा अनपेक्षित परिणामहरूबाट सुरक्षित गर्न प्रयास गर्नुपर्छ। यसमा एआई प्रणालीहरूको सुरक्षा, विश्वसनीयता, र विश्वसनीयता सुनिश्चित गर्नका लागि कदमहरू उठाउनु समावेश छ, जस्तै:

- एआई मोडेलहरूलाई प्रशिक्षण र चलाउन प्रयोग गरिएका डाटा र एल्गोरिदमहरू सुरक्षित गर्नुहोस्
- एआई प्रणालीहरूको अनधिकृत पहुँच, हेरफेर, वा तोडफोड रोक्नुहोस्
- एआई प्रणालीहरूमा पूर्वाग्रह, भेदभाव, वा नैतिक समस्याहरू पत्ता लगाउनुहोस् र न्यूनीकरण गर्नुहोस्
- एआई निर्णयहरू र कार्यहरूको जिम्मेवारी, पारदर्शिता, र व्याख्यात्मकता सुनिश्चित गर्नुहोस्
- एआई प्रणालीहरूको लक्ष्यहरू र मूल्यहरूलाई मानव र समाजको साथमा मिलाउनुहोस्

एआई सुरक्षा एआई प्रणालीहरू र डाटाको अखण्डता, उपलब्धता, र गोपनीयता सुनिश्चित गर्न महत्त्वपूर्ण छ। एआई सुरक्षाका केही चुनौतीहरू र अवसरहरू छन्:

- अवसर: साइबर सुरक्षा रणनीतिहरूमा एआईलाई समावेश गर्नुहोस् किनकि यसले खतरा पहिचान गर्न र प्रतिक्रिया समय सुधार गर्न महत्त्वपूर्ण भूमिका खेल्न सक्छ। एआईले फिसिङ, मालवेयर, वा र्यान्समवेयर जस्ता साइबर आक्रमणहरूको पहिचान र न्यूनीकरणलाई स्वचालित गर्न र वृद्धि गर्न मद्दत गर्न सक्छ।
- चुनौती: एआईलाई विरोधीहरूले जटिल आक्रमणहरू सुरु गर्न पनि प्रयोग गर्न सक्छन्, जस्तै नक्कली वा भ्रमित सामग्री उत्पन्न गर्न, प्रयोगकर्ताहरूलाई नक्कल गर्न, वा एआई प्रणालीहरूमा कमजोर पक्षहरूलाई शोषण गर्न। त्यसैले, एआई विकासकर्ताहरूले दुरुपयोगको विरुद्धमा मजबुत र लचिलो प्रणालीहरू डिजाइन गर्ने अद्वितीय जिम्मेवारी छ।

### डाटा सुरक्षा

LLMहरूले प्रयोग गर्ने डाटाको गोपनीयता र सुरक्षामा जोखिमहरू उत्पन्न गर्न सक्छन्। उदाहरणका लागि, LLMहरूले आफ्नो प्रशिक्षण डाटाबाट संवेदनशील जानकारी जस्तै व्यक्तिगत नामहरू, ठेगानाहरू, पासवर्डहरू, वा क्रेडिट कार्ड नम्बरहरूलाई याद गर्न र चुहावट गर्न सक्छन्। तिनीहरूलाई हानिकारक अभिनेताहरूले पनि हेरफेर वा आक्रमण गर्न सक्छन् जसले तिनीहरूको कमजोर पक्षहरू वा पूर्वाग्रहहरूलाई शोषण गर्न चाहन्छन्। त्यसैले, यी जोखिमहरूलाई सचेत हुनु र LLMहरूसँग प्रयोग गरिएको डाटालाई सुरक्षित गर्न उपयुक्त कदमहरू लिन महत्त्वपूर्ण छ। LLMहरूसँग प्रयोग गरिएको डाटालाई सुरक्षित गर्नका लागि तपाईंले केही कदमहरू लिन सक्नुहुन्छ। यी कदमहरू समावेश छन्:

- **LLMहरूसँग साझेदारी गर्ने डाटाको मात्रा र प्रकार सीमित गर्नुहोस्**: केवल आवश्यक र इच्छित उद्देश्यहरूको लागि सान्दर्भिक डाटालाई साझेदारी गर्नुहोस्, र कुनै पनि संवेदनशील, गोपनीय, वा व्यक्तिगत डाटालाई साझेदारी नगर्नुहोस्। प्रयोगकर्ताहरूले LLMहरूसँग साझेदारी गर्ने डाटालाई पनि गुमनाम वा एन्क्रिप्ट गर्नुहोस्, जस्तै कुनै पनि पहिचान गर्ने जानकारी हटाएर वा मास्क गरेर, वा सुरक्षित सञ्चार च्यानलहरू प्रयोग गरेर।
- **LLMहरूले उत्पन्न गर्ने डाटालाई प्रमाणीकरण गर्नुहोस्**: LLMहरूले उत्पन्न गरेको आउटपुटमा कुनै पनि अवांछित वा अनुपयुक्त जानकारी नभएको सुनिश्चित गर्न सटीकता र गुणस्तर जाँच गर्नुहोस्।
- **कुनै पनि डाटा उल्लङ्घन वा घटनाहरू रिपोर्ट गर्नुहोस् र सतर्क गर्नुहोस्**: LLMहरूबाट कुनै पनि संदिग्ध वा असामान्य गतिविधिहरू वा व्यवहारहरूको सतर्क रहनुहोस्, जस्तै अप्रासंगिक, असत्य, अपमानजनक, वा हानिकारक पाठहरू उत्पन्न गर्नु। यो डाटा उल्लङ्घन वा सुरक्षा घटनाको संकेत हुन सक्छ।

डाटा सुरक्षा, शासन, र अनुपालन बहु-क्लाउड वातावरणमा डाटा र एआईको शक्ति प्रयोग गर्न चाहने कुनै पनि संगठनको लागि महत्त्वपूर्ण छ। सबै डाटालाई सुरक्षित र शासन गर्नु जटिल र बहु-पक्षीय कार्य हो। तपाईंले विभिन्न प्रकारका डाटाहरू (संरचित, असंरचित, र एआई द्वारा उत्पन्न डाटा) विभिन्न स्थानहरूमा विभिन्न क्लाउडहरूमा सुरक्षित र शासन गर्नु आवश्यक छ, र तपाईंले विद्यमान र भविष्यको डाटा सुरक्षा, शासन, र एआई नियमहरूको खाता दिनु आवश्यक छ। तपाईंको डाटालाई सुरक्षित गर्न,

**अस्वीकरण**:  
यो दस्तावेज AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरेर अनुवाद गरिएको हो। हामी शुद्धताको लागि प्रयास गर्छौं, तर कृपया सचेत रहनुहोस् कि स्वचालित अनुवादहरूमा त्रुटिहरू वा अशुद्धताहरू हुन सक्छन्। यसको मूल भाषामा रहेको मूल दस्तावेजलाई आधिकारिक स्रोत मान्नुपर्छ। महत्वपूर्ण जानकारीको लागि, पेशेवर मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न कुनै पनि गलतफहमी वा गलत व्याख्याको लागि हामी जिम्मेवार हुनेछैनौं।