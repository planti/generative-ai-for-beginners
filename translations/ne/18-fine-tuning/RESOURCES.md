<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c2f423d1402f71ca3869ec135bb77d16",
  "translation_date": "2025-05-20T08:35:24+00:00",
  "source_file": "18-fine-tuning/RESOURCES.md",
  "language_code": "ne"
}
-->
# आत्म-निर्देशित सिकाइका लागि स्रोतहरू

यो पाठलाई OpenAI र Azure OpenAI का विभिन्न मुख्य स्रोतहरूलाई सन्दर्भको रूपमा प्रयोग गरेर निर्माण गरिएको थियो। यहाँ तपाईँको आफ्नै आत्म-निर्देशित सिकाइ यात्राहरूको लागि केही स्रोतहरूको सूची प्रस्तुत गरिएको छ।

## १. प्राथमिक स्रोतहरू

| शीर्षक/लिंक                                                                                                                                                                                                                   | विवरण                                                                                                                                                                                                                                                                                                                   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [OpenAI मोडेलहरूमा फाइन-ट्यूनिङ](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                                       | फाइन-ट्यूनिङले थोरै उदाहरणहरूको साथ सिकाइलाई सुधार गर्दछ, जसले धेरै उदाहरणहरूमा प्रशिक्षण दिन्छ। यसले लागत बचत, प्रतिक्रिया गुणस्तर सुधार, र कम-ढिलाइ अनुरोध सक्षम गर्दछ। **OpenAI बाट फाइन-ट्यूनिङको एक झलक प्राप्त गर्नुहोस्।**                                                                                    |
| [Azure OpenAI संग फाइन-ट्यूनिङ के हो?](https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst)                   | **फाइन-ट्यूनिङ के हो (अवधारणा)** बुझ्नुहोस्, किन यसलाई हेर्नु पर्छ (प्रेरणादायक समस्या), कुन डाटाको प्रयोग गर्ने (प्रशिक्षण) र गुणस्तर मापन गर्ने                                                                                                                                                                           |
| [फाइन-ट्यूनिङको साथ मोडेल अनुकूलन गर्नुहोस्](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst) | Azure OpenAI सेवा तपाईंको व्यक्तिगत डेटासेटहरूमा हाम्रो मोडेलहरूलाई फाइन-ट्यूनिङको प्रयोग गरेर अनुकूलन गर्न अनुमति दिन्छ। Azure AI स्टुडियो, Python SDK वा REST API प्रयोग गरेर **कसरी फाइन-ट्यून गर्ने (प्रक्रिया)** चयन मोडेलहरू सिक्नुहोस्।                                                                                                                                |
| [LLM फाइन-ट्यूनिङको लागि सिफारिसहरू](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                    | LLMsले विशेष डोमेनहरू, कार्यहरू, वा डेटासेटहरूमा राम्रो प्रदर्शन नगर्न सक्छन्, वा गलत वा भ्रामक आउटपुट उत्पादन गर्न सक्छन्। **कहिले फाइन-ट्यूनिङलाई विचार गर्नुहुन्छ** यसलाई सम्भावित समाधानको रूपमा?                                                                                                                                  |
| [निरन्तर फाइन-ट्यूनिङ](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst)             | निरन्तर फाइन-ट्यूनिङ भनेको पहिले नै फाइन-ट्यून गरिएको मोडेललाई आधार मोडेलको रूपमा चयन गर्ने र नयाँ प्रशिक्षण उदाहरणहरूको सेटमा **अझै फाइन-ट्यूनिङ गर्ने** पुनरावृत्त प्रक्रिया हो।                                                                                                                                                     |
| [फाइन-ट्यूनिङ र फङ्सन कलिङ](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst)                                                                       | फङ्सन कलिङ उदाहरणहरूको साथ तपाईंको मोडेललाई **फाइन-ट्यूनिङ गर्दा** मोडेलको आउटपुटलाई अधिक सही र सुसंगत बनाउने - समान रूपमा स्वरूपित प्रतिक्रियाहरू र लागत बचत गर्न सकिन्छ                                                                                                                                        |
| [फाइन-ट्यूनिङ मोडेलहरू: Azure OpenAI मार्गदर्शन](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst)                                                        | Azure OpenAI मा **कुन मोडेलहरू फाइन-ट्यून गर्न सकिन्छ** र कुन क्षेत्रहरूमा उपलब्ध छन् भनेर बुझ्नको लागि यो तालिका हेर्नुहोस्। यदि आवश्यक छ भने तिनीहरूको टोकन सीमाहरू र प्रशिक्षण डाटा समाप्त मितिहरू हेर्नुहोस्।                                                                                                                            |
| [फाइन-ट्यून गर्ने वा नगर्ने? यो नै प्रश्न हो](https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst)                                      | AI शोको यो ३०-मिनेट **अक्टोबर २०२३** एपिसोडले तपाईंलाई यो निर्णय गर्न मद्दत गर्ने लाभहरू, बेफाइदाहरू र व्यावहारिक अन्तरदृष्टिहरू छलफल गर्दछ।                                                                                                                                                                                        |
| [LLM फाइन-ट्यूनिङको साथ सुरु गर्दै](https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst)                                             | यो **AI प्लेबुक** स्रोतले डाटा आवश्यकताहरू, स्वरूपण, हाइपरप्यारामिटर फाइन-ट्यूनिङ र चुनौतीहरू/सीमाहरूमा मार्गदर्शन गर्दछ जुन तपाईंलाई थाहा हुनुपर्छ।                                                                                                                                                                         |
| **ट्यूटोरियल**: [Azure OpenAI GPT3.5 टर्बो फाइन-ट्यूनिङ](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst)                                  | नमूना फाइन-ट्यूनिङ डेटासेट सिर्जना गर्न, फाइन-ट्यूनिङको लागि तयार गर्न, फाइन-ट्यूनिङ काम सिर्जना गर्न, र Azure मा फाइन-ट्यून गरिएको मोडेललाई परिनियोजन गर्न सिक्नुहोस्।                                                                                                                                                                                    |
| **ट्यूटोरियल**: [Azure AI स्टुडियोमा Llama 2 मोडेल फाइन-ट्यून गर्नुहोस्](https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst)                                                      | Azure AI स्टुडियोले तपाईंलाई ठूलो भाषा मोडेलहरूलाई तपाईंको व्यक्तिगत डेटासेटहरूमा _कम-कोड विकासकर्ताहरूको लागि उपयुक्त UI-आधारित कार्यप्रवाह प्रयोग गरेर_ अनुकूलन गर्न अनुमति दिन्छ। यो उदाहरण हेर्नुहोस्।                                                                                                                                                               |
| **ट्यूटोरियल**:[Azure मा एकल GPU को लागि Hugging Face मोडेलहरू फाइन-ट्यून गर्नुहोस्](https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst)               | यो लेखले Hugging Face ट्रान्सफॉर्मर लाइब्रेरीको साथ Hugging Face मोडेललाई Azure DataBricks + Hugging Face Trainer लाइब्रेरीहरूको साथ एकल GPU मा फाइन-ट्यून गर्ने विधि वर्णन गर्दछ।                                                                                                                                                |
| **प्रशिक्षण:** [Azure Machine Learningको साथ फाउन्डेशन मोडेल फाइन-ट्यून गर्नुहोस्](https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst)         | Azure Machine Learning मा मोडेल क्याटलगले तपाईंको विशेष कार्यको लागि फाइन-ट्यून गर्न सकिने धेरै ओपन सोर्स मोडेलहरू प्रदान गर्दछ। [AzureML जेनेरेटिव AI लर्निङ पथ](https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst) बाट यो मोड्युल प्रयास गर्नुहोस्। |
| **ट्यूटोरियल:** [Azure OpenAI फाइन-ट्यूनिङ](https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst)                                                                                | W&B प्रयोग गरेर Microsoft Azure मा GPT-3.5 वा GPT-4 मोडेलहरू फाइन-ट्यूनिङ गर्दा मोडेलको प्रदर्शनको विस्तृत ट्र्याकिङ र विश्लेषणको लागि अनुमति दिन्छ। यस मार्गदर्शकले Azure OpenAI को लागि विशिष्ट चरणहरू र सुविधाहरूको साथ OpenAI फाइन-ट्यूनिङ मार्गदर्शकका अवधारणाहरू विस्तार गर्दछ।                                                                         |
|                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                               |

## २. द्वितीयक स्रोतहरू

यो खण्डले अतिरिक्त स्रोतहरू समेट्छ जुन अन्वेषण गर्न योग्य छन्, तर हामीले यो पाठमा समेट्न समय पाएका थिएनौं। तिनीहरू भविष्यको पाठमा समेटिन सक्छन्, वा एक द्वितीयक असाइनमेन्ट विकल्पको रूपमा, पछि। अहिलेको लागि, यस विषयको वरिपरि आफ्नो विशेषज्ञता र ज्ञान निर्माण गर्न प्रयोग गर्नुहोस्।

| शीर्षक/लिंक                                                                                                                                                                                                            | विवरण                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenAI कुकबुक**: [च्याट मोडेल फाइन-ट्यूनिङको लागि डाटा तयारी र विश्लेषण](https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst)                                      | यो नोटबुकले च्याट मोडेललाई फाइन-ट्यूनिङ गर्न प्रयोग गरिएको च्याट डेटासेटलाई पूर्वप्रक्रिया र विश्लेषण गर्नको लागि उपकरणको रूपमा सेवा दिन्छ। यसले स्वरूप त्रुटिहरू जाँच गर्दछ, आधारभूत तथ्याङ्कहरू प्रदान गर्दछ, र फाइन-ट्यूनिङ लागतहरूको लागि टोकन गणना अनुमान गर्दछ। हेर्नुहोस्: [gpt-3.5-turbo को लागि फाइन-ट्यूनिङ विधि](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst)।                                                                                                                                                                   |
| **OpenAI कुकबुक**: [Qdrant संग Retrieval Augmented Generation (RAG) को लागि फाइन-ट्यूनिङ](https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst) | यस नोटबुकको उद्देश्य Retrieval Augmented Generation (RAG) को लागि OpenAI मोडेलहरूलाई कसरी फाइन-ट्यून गर्ने भन्ने व्यापक उदाहरणको माध्यमबाट हिँड्न हो। हामी मोडेलको प्रदर्शन बढाउन र निर्माणहरू घटाउन Qdrant र Few-Shot Learning लाई पनि एकीकृत गर्दैछौं।                                                                                                                                                                                                                                                                |
| **OpenAI कुकबुक**: [Weights & Biases संग GPT फाइन-ट्यूनिङ](https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst)                                             | Weights & Biases (W&B) AI विकासकर्ता प्लेटफर्म हो, मोडेलहरू प्रशिक्षण गर्ने, फाइन-ट्यून गर्ने, र फाउन्डेशन मोडेलहरूलाई उपयोग गर्ने उपकरणहरू सहित। पहिलो [OpenAI फाइन-ट्यूनिङ](https://docs.wandb.ai/guides/integrations/openai-fine-tuning/?WT.mc_id=academic-105485-koreyst) मार्गदर्शक पढ्नुहोस्, त्यसपछि कुकबुक अभ्यास प्रयास गर्नुहोस्।                                                                                                                                                                                                                  |
| **समुदाय ट्यूटोरियल** [Phinetuning 2.0](https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst) - साना भाषा मोडेलहरूको लागि फाइन-ट्यूनिङ                                                   | [Phi-2](https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst) सँग भेट्नुहोस्, Microsoft को नयाँ सानो मोडेल, उल्लेखनीय शक्तिशाली तर कम्प्याक्ट। यो ट्यूटोरियलले तपाईंलाई QLoRA प्रयोग गरेर अनौंठो डेटासेट निर्माण गर्ने र मोडेललाई फाइन-ट्यून गर्ने विधि देखाउँदै Phi-2 लाई फाइन-ट्यून गर्न मार्गदर्शन गर्नेछ।                                                                                                                                                                       |
| **Hugging Face ट्यूटोरियल** [२०२४ मा Hugging Face संग LLMs फाइन-ट्यून कसरी गर्ने](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | यो ब्लग पोस्टले तपाईंलाई Hugging Face TRL, ट्रान्सफॉर्मरहरू & २०२४ मा डेटासेटहरू प्रयोग गरेर खुला LLMs कसरी फाइन-ट्यून गर्ने भनेर हिँडाउँछ। तपाईंले प्रयोग केस परिभाषित गर्नुहुन्छ, विकास वातावरण सेटअप गर्नुहोस्, डेटासेट तयार गर्नुहोस्, मोडेल फाइन-ट्यून गर्नुहोस्, परीक्षण-मूल्याङ्कन गर्नुहोस्, त्यसपछि उत्पादनमा परिनियोजन गर्नुहोस्।                                                                                                                                                                                                                                                                |
| **Hugging Face: [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst)**                                                                                            | [अत्याधुनिक मेसिन लर्निङ मोडेलहरू](https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst) को छिटो र सजिलो प्रशिक्षण र परिनियोजन ल्याउँछ। रेपोमा फाइन-ट्यूनिङको लागि YouTube भिडियो मार्गदर्शनको साथ Colab-अनुकूल ट्यूटोरियलहरू छन्। **भर्खरैको [स्थानीय-पहिलो](https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst) अपडेटलाई प्रतिबिम्बित गर्दछ**। [AutoTrain दस्तावेज](https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst) पढ्नुहोस्। |
|                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |

**अस्वीकरण**:  
यो दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरी अनुवाद गरिएको हो। हामी यथार्थताको लागि प्रयास गर्दछौं, कृपया सचेत रहनुहोस् कि स्वचालित अनुवादहरूमा त्रुटिहरू वा असमानताहरू हुन सक्छन्। यसको मूल भाषा मा रहेको दस्तावेजलाई आधिकारिक स्रोत मानिनु पर्छ। महत्वपूर्ण जानकारीको लागि, पेशेवर मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न कुनै पनि गलतफहमी वा गलत व्याख्याको लागि हामी उत्तरदायी छैनौं।