<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5466bcedc3c75aa35476270362f626a",
  "translation_date": "2025-05-20T01:55:08+00:00",
  "source_file": "15-rag-and-vector-databases/data/frameworks.md",
  "language_code": "ne"
}
-->
# न्यूरल नेटवर्क फ्रेमवर्कहरू

जस्तो कि हामीले पहिले नै सिकेका छौं, न्यूरल नेटवर्कलाई प्रभावकारी रूपमा प्रशिक्षण गर्न हामीले दुई कुराहरू गर्नुपर्छ:

* टेन्सरहरूमा सञ्चालन गर्न, जस्तै गुणा गर्नु, थप्नु, र केही फंक्शनहरू गणना गर्नु जस्तै सिग्मोइड वा सफ्टम्याक्स
* सबै अभिव्यक्तिहरूको ग्रेडियेन्टहरू गणना गर्न, ग्रेडियेन्ट डिसेन्ट अप्टिमाइजेसन गर्नको लागि

जबकि `numpy` लाइब्रेरीले पहिलो भाग गर्न सक्छ, हामीलाई ग्रेडियेन्टहरू गणना गर्न केही मेकानिजम चाहिन्छ। हाम्रो फ्रेमवर्कमा जुन हामीले अघिल्लो सेक्सनमा विकास गरेका थियौं, हामीले सबै डेरिभेटिभ फंक्शनहरू `backward` मेथड भित्र म्यानुअली प्रोग्राम गर्नुपरेको थियो, जसले ब्याकप्रोपेगेसन गर्छ। आदर्श रूपमा, एक फ्रेमवर्कले हामीलाई *कुनै पनि अभिव्यक्ति* को ग्रेडियेन्टहरू गणना गर्ने अवसर दिनुपर्छ जुन हामी परिभाषित गर्न सक्छौं।

अर्को महत्वपूर्ण कुरा GPU वा कुनै अन्य विशेष कम्प्युट युनिटहरू, जस्तै TPU मा गणनाहरू गर्न सक्षम हुनु हो। डीप न्यूरल नेटवर्क प्रशिक्षणले *धेरै* गणनाहरू आवश्यक पार्छ, र GPUहरूमा ती गणनाहरूलाई समानान्तर बनाउनु अत्यन्त महत्वपूर्ण छ।

> ✅ 'समानान्तर बनाउनु' भन्ने शब्दले गणनाहरूलाई धेरै उपकरणहरूमा वितरण गर्नलाई जनाउँछ।

वर्तमानमा, दुई सबैभन्दा लोकप्रिय न्यूरल फ्रेमवर्कहरू छन्: TensorFlow र PyTorch। दुवैले CPU र GPU मा टेन्सरहरूसँग सञ्चालन गर्न लो-लेभल API प्रदान गर्छन्। लो-लेभल APIको माथि, उच्च-स्तरीय API पनि छ, क्रमशः Keras र PyTorch Lightning भनिन्छ।

**लो-लेभल APIहरू** दुबै फ्रेमवर्कहरूमा तथाकथित **गणनात्मक ग्राफहरू** निर्माण गर्न अनुमति दिन्छ। यस ग्राफले दिएको इनपुट प्यारामिटरहरूसँग आउटपुट (सामान्यतया हानि फंक्शन) कसरी गणना गर्ने परिभाषित गर्छ, र यदि उपलब्ध छ भने GPUमा गणनाका लागि धकेल्न सकिन्छ। यस गणनात्मक ग्राफलाई फरक पार्न र ग्रेडियेन्टहरू गणना गर्न फंक्शनहरू छन्, जुन त्यसपछि मोडल प्यारामिटरहरूलाई अप्टिमाइज गर्न प्रयोग गर्न सकिन्छ।

**उच्च-स्तरीय APIहरू** प्रायः न्यूरल नेटवर्कहरूलाई **तहहरूको अनुक्रम** को रूपमा विचार गर्छन्, र अधिकांश न्यूरल नेटवर्कहरू निर्माण गर्न सजिलो बनाउँछ। मोडल प्रशिक्षण सामान्यतया डाटा तयार पार्न आवश्यक हुन्छ र त्यसपछि काम गर्न `fit` फंक्शनलाई कल गर्नुहोस्।

उच्च-स्तरीय APIले तपाईलाई सामान्य न्यूरल नेटवर्कहरू धेरै छिटो निर्माण गर्न अनुमति दिन्छ धेरै विवरणहरूको चिन्ता नगरी। एकै समयमा, लो-लेभल APIले प्रशिक्षण प्रक्रियामा धेरै नियन्त्रण प्रदान गर्दछ, र यसैले अनुसन्धानमा धेरै प्रयोग गरिन्छ, जब तपाई नयाँ न्यूरल नेटवर्क आर्किटेक्चरहरूसँग व्यवहार गर्दै हुनुहुन्छ।

यो पनि बुझ्न महत्त्वपूर्ण छ कि तपाई दुबै APIहरू सँगै प्रयोग गर्न सक्नुहुन्छ, जस्तै तपाई आफ्नो नेटवर्क तह आर्किटेक्चर लो-लेभल API प्रयोग गरेर विकास गर्न सक्नुहुन्छ, र त्यसपछि उच्च-स्तरीय APIको साथ निर्माण गरिएको ठूलो नेटवर्क भित्र प्रयोग गर्नुहोस्। वा तपाई उच्च-स्तरीय API प्रयोग गरेर तहहरूको अनुक्रमको रूपमा नेटवर्क परिभाषित गर्न सक्नुहुन्छ, र त्यसपछि तपाईको आफ्नै लो-लेभल प्रशिक्षण लूप प्रयोग गरेर अप्टिमाइजेसन गर्न सक्नुहुन्छ। दुबै APIहरूले समान आधारभूत अवधारणाहरू प्रयोग गर्छन्, र तिनीहरू सँगै राम्रोसँग काम गर्न डिजाइन गरिएको छ।

## सिकाइ

यस कोर्समा, हामीले अधिकांश सामग्री PyTorch र TensorFlow दुबैको लागि प्रदान गरेका छौं। तपाईले आफ्नो मनपर्ने फ्रेमवर्क छनोट गर्न सक्नुहुन्छ र सम्बन्धित नोटबुकहरू मात्र हेर्न सक्नुहुन्छ। यदि तपाईलाई कुन फ्रेमवर्क छनोट गर्ने निश्चित छैन भने, **PyTorch vs. TensorFlow** सम्बन्धी इन्टरनेटमा केही छलफलहरू पढ्नुहोस्। तपाईले दुबै फ्रेमवर्कहरूलाई राम्रोसँग बुझ्न पनि हेर्न सक्नुहुन्छ।

जहाँ सम्भव छ, हामी सरलताका लागि उच्च-स्तरीय APIहरू प्रयोग गर्नेछौं। तर, हामी विश्वास गर्छौं कि न्यूरल नेटवर्कहरू जमीनदेखि कसरी काम गर्छन् भन्ने बुझ्न महत्त्वपूर्ण छ, त्यसैले सुरुमा हामी लो-लेभल API र टेन्सरहरूसँग काम गरेर सुरु गर्छौं। तर, यदि तपाई छिटो अघि बढ्न चाहनुहुन्छ र यी विवरणहरू सिक्न धेरै समय खर्च गर्न चाहनुहुन्न भने, तपाई ती छोड्न सक्नुहुन्छ र उच्च-स्तरीय API नोटबुकहरूमा सिधै जान सक्नुहुन्छ।

## ✍️ अभ्यासहरू: फ्रेमवर्कहरू

तपाईको सिकाइलाई निम्न नोटबुकहरूमा जारी राख्नुहोस्:

**लो-लेभल API** | TensorFlow+Keras नोटबुक | PyTorch
-----------------|-------------------------------------|-------------------------------
**उच्च-स्तरीय API** | Keras | *PyTorch Lightning*

फ्रेमवर्कहरूमा पारंगत भएपछि, ओभरफिटिङको धारणा पुन: स्मरण गरौं।

# ओभरफिटिङ

ओभरफिटिङ मशीन लर्निंगमा अत्यन्त महत्वपूर्ण अवधारणा हो, र यसलाई सही प्राप्त गर्नु अत्यन्त महत्त्वपूर्ण छ!

5 बिन्दुहरूलाई नजिक पार्ने निम्न समस्यालाई विचार गर्नुहोस् (ग्राफहरूमा `x` द्वारा प्रतिनिधित्व गरिएको):

!linear | overfit
-------------------------|--------------------------
**रेखीय मोडल, 2 प्यारामिटरहरू** | **गैर-रेखीय मोडल, 7 प्यारामिटरहरू**
प्रशिक्षण त्रुटि = 5.3 | प्रशिक्षण त्रुटि = 0
मान्यकरण त्रुटि = 5.1 | मान्यकरण त्रुटि = 20

* बायाँतिर, हामी राम्रो सीधा रेखा नजिक पार्न देख्छौं। किनभने प्यारामिटरहरूको संख्या उपयुक्त छ, मोडलले बिन्दु वितरणको पछाडिको विचारलाई सही रूपमा प्राप्त गर्छ।
* दायाँतिर, मोडल धेरै शक्तिशाली छ। किनभने हामीसँग केवल 5 बिन्दुहरू छन् र मोडलसँग 7 प्यारामिटरहरू छन्, यसले सबै बिन्दुहरू पार गर्न समायोजन गर्न सक्छ, प्रशिक्षण त्रुटि 0 बनाउन। तर, यसले मोडललाई डाटाको पछाडिको सही ढाँचा बुझ्नबाट रोक्छ, त्यसैले मान्यकरण त्रुटि धेरै उच्च छ।

मोडलको समृद्धि (प्यारामिटरहरूको संख्या) र प्रशिक्षण नमूनाहरूको संख्या बीच सही सन्तुलन कायम राख्नु अत्यन्त महत्त्वपूर्ण छ।

## किन ओभरफिटिङ हुन्छ

  * पर्याप्त प्रशिक्षण डाटा छैन
  * अत्यधिक शक्तिशाली मोडल
  * इनपुट डाटामा धेरै शोर

## ओभरफिटिङ कसरी पत्ता लगाउने

जस्तो कि तपाई माथिको ग्राफबाट देख्न सक्नुहुन्छ, ओभरफिटिङलाई धेरै कम प्रशिक्षण त्रुटि र उच्च मान्यकरण त्रुटिबाट पत्ता लगाउन सकिन्छ। सामान्यतया प्रशिक्षणको क्रममा हामीले देख्नेछौं कि प्रशिक्षण र मान्यकरण त्रुटिहरू दुबै घट्न थाल्छन्, र त्यसपछि केही बिन्दुमा मान्यकरण त्रुटि घट्न रोक्न सक्छ र बढ्न सुरु गर्न सक्छ। यो ओभरफिटिङको संकेत हुनेछ, र यो बिन्दुमा प्रशिक्षण रोक्नुपर्छ भन्ने संकेत (वा कम्तिमा मोडलको स्न्यापशट बनाउन)।

ओभरफिटिङ

## ओभरफिटिङलाई कसरी रोक्ने

यदि तपाई देख्न सक्नुहुन्छ कि ओभरफिटिङ हुन्छ, तपाई निम्न मध्ये कुनै एक गर्न सक्नुहुन्छ:

 * प्रशिक्षण डाटाको मात्रा बढाउनुहोस्
 * मोडलको जटिलता घटाउनुहोस्
 * केही नियमितीकरण प्रविधि प्रयोग गर्नुहोस्, जस्तै ड्रपआउट, जुन हामी पछि विचार गर्नेछौं।

## ओभरफिटिङ र बायस-भेरियन्स ट्रेडअफ

ओभरफिटिङ वास्तवमा स्ट्याटिस्टिक्समा एक अधिक सामान्य समस्याको मामला हो जसलाई बायस-भेरियन्स ट्रेडअफ भनिन्छ। यदि हामी हाम्रो मोडलमा त्रुटिको सम्भावित स्रोतहरूलाई विचार गर्छौं भने, हामी दुई प्रकारका त्रुटिहरू देख्न सक्छौं:

* **बायस त्रुटिहरू** हाम्रो एल्गोरिदमले प्रशिक्षण डाटाबीचको सम्बन्धलाई सही रूपमा कब्जा गर्न नसक्दा उत्पन्न हुन्छ। यसले हाम्रो मोडल पर्याप्त शक्तिशाली छैन भन्ने तथ्यबाट उत्पन्न हुन सक्छ (**अन्डरफिटिङ**).
* **भेरियन्स त्रुटिहरू**, जुन इनपुट डाटामा शोरलाई अर्थपूर्ण सम्बन्धको सट्टा नजिक पार्दा मोडलले उत्पन्न गर्छ (**ओभरफिटिङ**).

प्रशिक्षणको क्रममा, बायस त्रुटि घट्छ (जसरी हाम्रो मोडलले डाटालाई नजिक पार्न सिक्छ), र भेरियन्स त्रुटि बढ्छ। ओभरफिटिङ रोक्नको लागि प्रशिक्षण रोक्न महत्त्वपूर्ण छ - या त म्यानुअली (जब हामी ओभरफिटिङ पत्ता लगाउँछौं) वा स्वचालित रूपमा (नियमितीकरणलाई परिचय गरेर)।

## निष्कर्ष

यस पाठमा, तपाईले दुई सबैभन्दा लोकप्रिय AI फ्रेमवर्कहरू, TensorFlow र PyTorchका विभिन्न APIहरूको बीचको भिन्नताहरूको बारेमा सिक्नुभयो। साथै, तपाईले एक अत्यन्त महत्वपूर्ण विषय, ओभरफिटिङको बारेमा पनि सिक्नुभयो।

## 🚀 चुनौती

संगत नोटबुकहरूमा, तपाईले 'कार्यहरू' तल भेट्टाउनुहुनेछ; नोटबुकहरूमा काम गर्नुहोस् र कार्यहरू पूरा गर्नुहोस्।

## समीक्षा र आत्म अध्ययन

निम्न विषयहरूमा केही अनुसन्धान गर्नुहोस्:

- TensorFlow
- PyTorch
- ओभरफिटिङ

आफूलाई निम्न प्रश्नहरू सोध्नुहोस्:

- TensorFlow र PyTorchको बीचमा के फरक छ?
- ओभरफिटिङ र अन्डरफिटिङको बीचमा के फरक छ?

## असाइनमेन्ट

यस प्रयोगशालामा, तपाईलाई PyTorch वा TensorFlow प्रयोग गरेर एकल- र बहु-तह पूर्णतया जडित नेटवर्कहरू प्रयोग गरेर दुई वर्गीकरण समस्याहरू समाधान गर्न भनिएको छ।

**अस्वीकरण**:  
यो दस्तावेज AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरी अनुवाद गरिएको हो। हामी शुद्धताको लागि प्रयास गर्छौं, तर कृपया सचेत रहनुहोस् कि स्वचालित अनुवादहरूमा त्रुटिहरू वा अशुद्धताहरू हुन सक्छन्। यसको मूल भाषामा रहेको मूल दस्तावेजलाई प्राधिकृत स्रोतको रूपमा मान्नुपर्छ। महत्वपूर्ण जानकारीको लागि, व्यावसायिक मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न हुने कुनै पनि गलतफहमी वा गलत व्याख्याको लागि हामी जिम्मेवार हुनेछैनौं।